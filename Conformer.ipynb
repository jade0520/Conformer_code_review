{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Conformer.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "SojZ-mou8usw",
        "qShDCVqS8-9_"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPtDGLuACTaVpnO3qI5d0xb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jade0520/Conformer_code_review/blob/main/Conformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paper Link\n",
        "[Conformer pdf] https://arxiv.org/pdf/2005.08100.pdf?ref=https://githubhelp.com  \n",
        "[Trasformer pdf] https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\n",
        "\n"
      ],
      "metadata": {
        "id": "X7oJBVqZEtd3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Activation"
      ],
      "metadata": {
        "id": "SojZ-mou8usw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbGeUGWa6ZzK"
      },
      "outputs": [],
      "source": [
        "# Activation\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "\n",
        "\n",
        "class Swish(nn.Module):\n",
        "    \"\"\"\n",
        "    Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU on deep networks applied\n",
        "    to a variety of challenging domains such as Image classification and Machine translation.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(Swish, self).__init__()\n",
        "    \n",
        "    def forward(self, inputs: Tensor) -> Tensor:\n",
        "        return inputs * inputs.sigmoid()\n",
        "\n",
        "\n",
        "class GLU(nn.Module):\n",
        "    \"\"\"\n",
        "    The gating mechanism is called Gated Linear Units (GLU), which was first introduced for natural language processing\n",
        "    in the paper “Language Modeling with Gated Convolutional Networks”\n",
        "    \"\"\"\n",
        "    def __init__(self, dim: int) -> None:\n",
        "        super(GLU, self).__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, inputs: Tensor) -> Tensor:\n",
        "        outputs, gate = inputs.chunk(2, dim=self.dim) # chunk : https://pytorch.org/docs/stable/generated/torch.chunk.html\n",
        "        return outputs * gate.sigmoid()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# embedding"
      ],
      "metadata": {
        "id": "qShDCVqS8-9_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAq8AAACpCAYAAAAFp9SpAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFxEAABcRAcom8z8AAN4cSURBVHhe7J0FQFbJGobZNlZde+3Otbu7u7u7u1EUEVuwEEVssVtRsUU6BFGkpLu74X/u/Ii7BiC66+51d557z73yn5ozZ8587/dNqSCRSCQSiUQikXwlSPEqkUgkEolEIvlqkOJVIpFIJBKJRPLVIMWrRCKRSCQSieSrQYpXiUQikUgkEslXgxSvEolEIpFIJJKvBileJRKJRCKRSCRfDVK8SiQSiUQikUi+GqR4lUgkEolEIpF8NUjxKpFIJBKJRCL5apDiVSKRSCQSiUTy1SDFq0QikUgkEonkq0GKV4lEIpFIJBLJV4MUrxKJRCKRSCSSrwYpXiUSiUQikUgkXw1SvEokEolEIpFIvhqkeJVIJBKJRCKRfDVI8SqRSCQSiUQi+WqQ4lUikUgkEolE8tUgxatEIpFIJBKJ5KtBileJRCKRSCQSyVeDFK8SiUQikUgkkq8GKV4lEolEIpFIJF8NUrxKJBKJRCKRSL4apHiVSCQSiUQikXw1SPEqkUgkEolEIvlqkOJVIpFIJBKJRPLVIMWrRCKRSCQSieSrQYpXiUQikUgkEslXgxSvEolEIpFIJJKvBileJRKJRCKR/IdRQFociQnRhMelEJec+bPk/xYpXiUSiUQikfx3SYkm2WY/hkc1WW5gz3WntMwdkv9XpHiVSCQSiUTyDxFHYrgXns7PcbB7hv1zN175RxL5SfoxlaRYcU5wCBHRCcSnZ8RSc016tDOOG7uwoFdjmqjdRcfhU26eTkpMIP7PzbC6d4PrV69x6fw9nth5EpgCUgZ/GaR4lUgkEolE8jcj5GVqNPG+Vjw1Os7RXZvZuFaddeu12HnkCpetPXGNUiD030cQRyS44fzoEucPnuTSExec4jN+zSXxxHneQG9Ac/o17MLEU8+4H/Mp0jeFWE9jHmrPYWnX36hfqSoVKg5mwsYbmEZDUuZRkr8WKV4lEolEIpH8vYTb42F8lGN7d7Bpy2526RxAd682u9TnsmTyYAYPn8oE9XMctw7HLycFmBZGmusBji7qTqdmAxi+5RbXQyExc/dHSX5B4ONVjGvRjWZt1qJvG0JI5q7ckUZSqCtOt3XRHVKNJt+roPJNNzqvMMI6ThkTlnwJpHiVSCQSiUTyN5FKelIAvnf3Y6A+m0WqWmgcvc99Ozdeub/A+ZE+x1f1pU/VYpQs14G2C89y7GkkUWnKBvosSAshzXEPR5b1pXvXiUza85C7YbmPeKZ7ncFGqz3tOk6k+dwnmPp/Zqw01QP77UOZVq0kJRqvZKK+BwGyz8AXQ4pXiUQikUgkfxOhxPvc4OiqecwYuZzN5y0xDYgiKiGV1LRkUmIDCXh6ngtzmtGjeB6KVu5Fv+33MQqFhMwrvEsKxHnh62yLpeVznnuFEy5+ylLofkAywTc1ODqwEm1GqjLqcgye8Z/SZeANQqUmmHNjeRd6lqtExaEHWH0/nvjMvZK/HileJRKJ5GsgKZoETwe8fHzxElYx6XNs7H+I9JRoAhyf42z7Au/IBOIyf5f8w6S5EG6myvyudSlTfiD9Nppg5Pe+1BQC9/YcNNp+y88/FKHIkF2st04k7C9tgxcXU7hgvGM6k6rUof/ig+gFQnTuVO97RJDuoY/WsNrU/LU+DZdf5+CrDEn7r0ORmkCivytBft74Jyvl/z+DFK8SiUTy/05iKIG2d3hw8hiXHz7FJgriPsvI/lcQQj/AmPObNrFZ9QCGTqEEZ+6R/MOkOBP+ZDkr+5SlcNHGlBtuwM7HMe8OsFJEwnMN9k8sRJGCeVHpsI7p16IIeCf0mkJqfAThwcEEhkQRlZj+STMMZNzDX5998wdSt+p4Zu00xkn8/HHBmZZx34ggfwICAvEPjSUq8iURj5ewpHMFylTsxkBdc+7GZB7+L0MhnOjYl3ewuXORS0+csBUvJeuI+JdFileJRCL5fyY1gmjzg5zdtJg5qkfRveuBX7L4WUZesyflOUHGaszs0Z/2PTQ5YhtEWOYuyT9MehgJHle5uHkmMyYuZJaOKYZuye8286eHg/1adMfn55dCeVDpos4Mw1gCfx+FlSoculd4WF3m7P69aO04wrFbT3kWkZr7pvo4dyKvjGHZ8PaU63uIjYbBuYgiivtGO+NifJ7z+3ewe5cu2scfY2h4Hst9fRjdpCKl6k5lyTUXXP6t32daIikRllic2orGfDU0jxljLF5XrgfI/UVI8folUMSREmaPw6MLnDmoy/49e9Ddvx+9w4c5fPgQB/frsnfXXnT2HUBP/xD6hw5x6JA+B/UOsF93Hzo6uugePMGJi/e5b++Hd2zmdT9KMkmRr3B8eJnL+nvRU17rgLjukaMcOXqUoyItevvEfXXFfQ6K++rrZ9xXeX99/YPo6+3nwL497NmljfbOXezau0+k4wiHDgsP6+5TXobKPjySfznpKaRGhRIRE0u0sFP/eHAzLYR4l8tcWDeZGeMXMu+AJXddEv6VzZF/Jem+l7HT7kDbht2oMdiAS07RuTeuKcEEBwXjHZRAQspnKpDEQEJcrbAyvsfdO/e5Z/KMp+4RRHxWgYok2vs5z0zu8/DuPe48sMTKKeC9KOQnkBhEqJsV1iJt9+6I7Yk9T1+FE/5ZhSqKGN8XOJg+EGm7K9JmgaWjP345Gop0FEmh+DlYYWtqiZ13BEHvq8YUX8IvTmJFMxXy5C1LmUkH2emYkvFNKgVkQrg7znfOcP3kfvZqbWTtxJHMnKHG6vOu2ATnbpKsZF8TjOc2ZkzndrTZ/pRznh9512mBBNpewVBXk+2bN7Nptx779Y8I23kYPfXprB1Uhbql6lOh8zb2WwTxjwZehcBMigkjJCic4LAEknLl6aZmRJSjQwMICo8iLFFB1sVf+WMwXqZHOLJwFOMmqLHs+DPsIsX5rw/4W5Di9UuQHkyC2ynObpnMqE4tadugKjUqlqBowYIULFiAX4qVoVTVRjRo2Z4OXbrSpWtXunXtTOeO7WjbqgXNmzaladNWtOowkCFztdl21QHbgCQSPlq5xBHjfY/LmjOY2aUZ7ZvWoVbFMpQrWoQiRQqL+5aldOV61Gsu7tNJ3LdLF7p27ZJx/y5dOtOlY1vatmxM43q1qF29EhVLF6X4L79Q4Oe6NB6swX7bAAIz7ySR/KtQCIOaHELQ87s8OHOIE+cfcvOFqMD/0Y6l6aR6GmKuO5kJw2czavUN7nnE5qIe+K+TTsTDHRgMr0STTlPottMVu7CcmpTFnrRkkuNjRP1phfM9pTN/Gb0b3ngLg/xJpMQRG/CCl4/Oc/HgNratX8Nq1TWobtiF1pEbXLNwxy08kYTciNh0IUCESPOyMeTWiT3s1lRjnepqVNW2sEX3HGfvC0HrJ+p8odVyVUpF2uICHXF6fIFL+tvYriHStmo1qzV2onX4GlfM3HAJFYI9N+VLmbZID7xtb3H7pA57NdeKtKmySm0zW3TOcPquA/a+MUQLUZpd2hTp6aSnpZEuDnj3mFQSvY24uaAlPQrnpXjVEYzTNcVSeB9p4khFsjvuJmfRVdNi3+kH3DO9waVZrRjcoDX1pxly1DY3IZYwgqwPot6mMT3ajmOlcRA5rUugSAkk0vYwhxcOYUiX4YxbJ57xZSxB0RHEuZzlimp7upTNyw95u1Bn0g1uuPyTPayThe9kz8sHZzh54hZn7vng/1r154D4PhIC8Le9yb3T+py4ZcY93zSisj1NQVrCS3wfbUN9zHAGDVNnxz0vXHLnN/wlSPH6JVDEkxohKjCzG1w5qcdxnTlM7lyZQioqqIjthwrt6LpsN5uOnuCEwSkMTp3i1CkDTp48zrGjwps5tJudqpOY2rEGjSrVoHrHkQzYaMS550nkPBAyheQoT1xMbnLLQFxn90oWtq9Ancz7qhRtS42RW1ivI+5zUtzXwCDjvsr7GxicxODkMY4fPcShA7vYs2Eec3rVoO5PynN/pHCTRWw28cU/804Syb+KlEgS7PS5uLoT3ZrXp37zRYzeZot9yN9YG7+DsKTprtifWsXqvl0YMHMPW03DCJX9XD+CsoL0w+7gPOb9Vo42ozVYZZVMYLZGOJW0GOGUO5tgelkXnaXDGNelOQ1bLWLIelueBn7CcJT0EAKMRX2/egITJi1g2tqDHLx4i5tGQswY7GD36plMHDufWZpCPL6MITTztCxRRJPkfInrO+Yze9Q0pi7azs5Thly9fROjy/roaSxk4ZiJTFuhx37jwIwBfDmiCCPQRB8DtQlMmjSfqWoH0btwk5t3DDE8pc0etZlMHjeXGevPcf551Ef6B8eS4nqVmzsXMGf0VKYs2Ia2gbB1Im13rgjhr7mIRWMmMG2ZyM+H/nh8qo6LforLqelMaVCO8mU703vVVS45R4q7Kkkmxfk0xsdXs3jLBQ5bi+u/uMSZkTVo9ms9Koy7jr5NLmLssY9xPDeVHvX70Wbgfq77JuYwoC+ccEcDTszrSNfGbWgydh9bjXzwflM1pFpjsW84fUv/TJ7Sw+mw+QVmgf/gh5oWQuCTPRxf2JMefZcwcpM9TwM+Uo8p4kjyN+Hh7rks6tOFQUt02WqfkjEgK3uSIOopNnsnsXhIP/osu4SeZeTfNoBLitcvjijE8dc4t6oj1VW+EUKwDA3H7ua4r3Jdj+xJ93+C5YExTG5QiDzK82oOY+C2JzwJSs79qNk4a+4s7EKfH1T4UeUH8vXdzNy7ybmbgDnJF+972zgwSRjyX2tRo5MG+yz8Zb8xyb+T5EBi7y1Fa1ABfsnzMz+VmUI/TRue5rIJ8i8nNYxERx10Z/enXcsZLNC35JkQYDLo+jESIOaqqG8H0rJMOwauOMPN6A/rWoVw8gPthdg6f4zDekLI7d7IjhVDGdb0FwooHf3vBtN49hPMfHNpipOCibI9wpHZXenVpCWtx21G7YIjjhHpwgIkk+pvjMWJFSzt04I2rYcwRP0GF52isrEB0SR6GXJn4xBGt2lKo+5LmL3vISZCgMQrS0CsM47XtrJrYjs6t+hGxxl67DMLyliKNEuSQomxO8axed3o3bQFrcdosvqcI8/D08TVhHgPNMHqlCor+rWkbcuBDFS7wlnHyGzsTAxJPkbc3zKccW2b0rDrQmbsuY+xb5I4XmnrXHAy3MHeyR3o0qILHabqsudJAP65/YwSPPC4uppNQxvRpFEvuiwUovF57FtCP4kk+9NYXdvHgSce2IT64HN3NctblKZ85Z502vaUWx/MXPAhyU+1uLmsMfW7LqbHxpe4xWZ/Tnr4I6z3DGJQ+YKUrDuGkWd8sX27T4DiOTbHpzGs6q+UaTWHcZdDccx1V78vQQzRJls4Ma4SNWoPpsEcMx57feQFpMeRGGgmytwYxlUrQ6Mha1holoznR4u/OMD1MJfWDaZjh5lM2PIIG1Fw/o5VxaR4/eKIz85Rk50TK4hKMQ8q33aj+5LrmERl7s6WGFKCrnB6eTcaKivTb/NRrucKVj4K4mWu6tMEkn3Os290U2p+o8J3KqWoM+8we92VV84lcTb43l7CjAEjaT9Al1PWQbkXzhLJ10RqJEkvDnNh/VCG9BnJkGUG6FtFEvwPdRtICbLCfscApvfsStPpFzhgEfXuaGxJ1qQEkmq5nM3jWlOh3mLm7LfDT/z87ltUkOZ+C6sDU1kwph9dB85gyqI1bNGcLOq68hT74QdUfhxCs7kmmCtHxn0UBQnOV7i3qiM96jSmVs+NbL7thkdMyh/vLD2BpJDnuJ2ewYqedahefyyjdjzCVFTG7xt6Rfhjnh2ZwOhGNanVchKzTjlgGpxA4u/6KpWU2FcEW2izeUQzGldvR5eVlznhkp5Fv14Fia7XeLimM73qNqRG9w1sNHTB/e20KRJJCnuJ+7k5rO4r0lZ3JMM238M48sNBOIoIUxxPTGF80xrUajae6cfteBwU/1Y3CJG2OA9CrfewfUwLmlVvTacl5zjilPaRVkOxM8GT0Cfa7JranS6tBjNU7RynneIJf1tXKsT1QzwI8/fCJzqReH9DzLS60rlCWcq1W8SKR6G4fNTDi8BNfxabO1am9cw9LDZNJTLbcxKIfLgZ/QGlqZ6nLNUGbEXnZdJbASCRixFXub2xO63LVKL6YE00n6UQ8OZZ04WDkCYchPT011tqMslJiSQmpf4x4DJNvItE5W9iX5pC6QK8R5q4TArJyUniXHFMqrhO5p53Eb+nJJOSFE+8/WEeqDahTZsxNJlr/pZ4FekRxySJ+yUlifuKm71ORrrIWqEtzqxjXcuadB29hkVCvHrkRoWmvcLxnBqL2zan5+j1aJjH4JnrDuafjxSvX5qYl4ScH83SDj8KAVoIldLzGKXlgFuuJkJ+wZN9U+mbXxk5FQK0Vj8673fkfm7mfElzI9hcjYVdK5BP5Ru++bEp/Tdd47bwCHPfzz+AdO/DaC5ax9Dx57j1LDSbj0Yi+cpRJJMe7Y7XM2Me3zfBWDnoRFTAn9jj8S8iiBDr/ezoW5eObYcx8oQ7xhGZuyQ5kh75As9d3ZnVuREVR51iy4PoLOosIRBCX+D1xICLxw+ic+QSF27dw+L+FvYuqE+VQvlRyTOMFvNNcyFehfVPccFJCL95TQpTrHI/Wqs/xSTLPgGizg89x6VlbWlQpAplu2xC9X5ERjn7g2gCH25iz4AqlC/UlLpjjnLBV5F1U6zCEYstAxlV7hfK1J/OBL3nuCYqMsWIEpG2VDdcLs5nUXORtkq9aaFmzePs7EfEJa6v7kDjopUo3WE9y43C8H4nNBxDsPF29g+pRsVCjag9XJ8zXmnZDIRzxlprKOMrFKJsnUmM2fcMp7i30/Ye8U5439dGe/YwBg+czvTN17jkGJ7Z0iecjZRUkpKFwEoX7y4tDUXGhZJJeLKRQ8MqULFESxpMMuBqYDZ59TvC+iWacmHJMPpXasnorde5Gp0hQbNA3CTVixe6E5hdOR8Ffu5Ch6W3MIt66/j0ONJfbOfotFpULdmIFrOOcjH8jY2NJcH3KQ7GNzAyNuWu3UssHlzjxqG96B68yCU7P9wjwgi0u8WDI9ro6Bzl0O2X2AW8NfApPZa0QGscLO5w9dJFLp85w4W7TzH1FM+eechrYonye47lbUNuXbrCjYNL2D29Pg3aTKTVQhtMRRlSpko5kNz2wRVO6+lx5PB5Lpp64iSclNfE431TG63O9ek3YS1LzHMpXsUXFmt/iqtT6tGt/RC6aljxwOfLx16leP3CpPubYa/RnnEVVESFWILvO2uz4FIYoR+1iuKAVGvuak2k188q5FFGX2t0o8FmW655Zh6SE9FPcDszmBFNfkZFpSAqJccy96AFrqIMf+jZZYe3cIYN2LR6FxPmGmH8RymXSCRfiriHPDs2gf6/NaFxb3X2PI+Rfc1zRQrxHjc5N6oB/Zq0o+suWy76Zu76KELyBJ3k+rom1P5FiNcfh+ZOvCoSSPc6xqUl9alf5Gfyt1/O1FsxuGep6JQCwgXbo9MZXaEweYv1pd0qE54IsfK6ThZ1fpI1j7YOoP+vhfip9Hj6bnqaIfqyJo7QqyvRaluAsnlrUGe8Hqc8k4j6/fBE0n2EoFvegIZF85O39RIm3YjCNdvoxSuenZrD+CqFyVekBy2XPuaBb3Km+Bf/m/yUJ9pDGFKmID+VHE3P9TY8j84ubYmEGaqxt2MhKuStSs1R+zj+KpHIDw4XT57gQ4CpPsfXz2LSJFWWH3iC5e8tk+If4c+wd/bAWjxb/O+vQ1wo7RV2e0Yzo3ZxStabzQidF7jEClEXHk1ESAxJqVkM0kv1Je25BqtH96Z6/WWsO/eSgMxdHyKeOcGK22v70P2XouStNI9Re53wertIpIUTc20Om7uVoVT5QQzY+ADbxFQSo8JJiHiFj+15LmhMZuGceUzafpJte/ayd8kEZo0exYS1umy9+IAbZw9goDGR2eNGMWDKTjZfcMErSSkQool0MebJ6f0c1T/IAf0DHNypztpVmqjtusFNIe6VfeDTk6OIdRH2+YIeOvuOsP/gQY5sGMPSfpWo2HAcrZdZY+YTS1y4M84PznH5hD66m1ezfskcpi3ezeZzz3GKSSFJiFuv69vY1qkefcZ/ingVhJnieWQQo9q0oXo3LfY+CRCp/7JI8fpFURDrdI3L436j8w8qfPNLRUrPOcNW+3SyrY9+R7i8kTe4qNaXJt+p8K0Qr9/UFZXdPkeMcjPk3/0CFur16FpJ2c+2Ct813sKGy15ZdxlQurGKjHGc7wrbdHfiXY+ybeMBZq61wMpddhqQSL4s6aTa7+XaombUrzmAtrOv8jjk752C5uvFS4igbcxv0YCWzSey6oE/L3KdceLAYINPF6/JIUTcXMz2Lj9SMu8vFB+2nXV26WQ/Xicc92vrUK0njv2mAlX77eKIQ6RSogkiwVOPg9NrUiFPEVTqqDLpqC8B2SYhjWQLLc6MLkaNfD+Qr8NC5t4Pw/mNcE4PI/L2crS75+HXfAUpOngLarap+GfbfBaJ1y1N1jYqTAmVMlTuuR29p+G8DvqLFPoc5uic36ginlOl5jLG6nvjk3XYNYMU6z1cHF+S2vm/F8J5DjONgnnxvnCOcyfUZC/718xn6nxttC49xS4k8Y+uFOHmBD7ejPaZG2gZxxP8eyRYWLLAixyf1Zxmv1ah2lh9tlmHERzqhu0tc4wMnfCPeW/uWCUhlngf6MaEft2oOtGQo9YZPXWzIUWkz4SrK7rSofCv/NJck9lnQwh/23bHOfNiWz+m1SpNiYYrmXvaBc9wfzzu3+OFtSX2dje4ML8jI5oI52bSTlactcLEcD8XV3aiX8fONBm9i02XzHnmcJGrO6czuNUghs0/xS2/UGIi7nLngBrTJm5nyzFzXPz88HW9xbklQ5nQuS/DtxhxwSeJME9zHm2cx8ala9F66Ial8rg7Wzk+vib1Go6h7bJHGL+0x9rwHPobj3PtoT3u7g8xPrGAce270GnYRvY6RBAoypOv4TZ2dP4M8ZruSZz1elb0akLNmsOZdvwplh/5dP4sUrx+UaIIsDjAxvYVqCDE50/FGtF+xz0uhGfXTPEWouJRvNzO/uk1KK6MuqrkpVjr6cy57YdD1r383yKNWFNdLgwrTNOfxbkFmlJ09CX2m8V/6IkKYl3t8bh3Azs3LzxFxfZ7fZ/iIcTrafSPnGf9EVdeZl+LSiSSv4QIfE/PY3PnClRuvoAhu13wSPiopytREnGbZ0eG0bFONxr138cl4WznftyMqFT9j3NFrTG1PkG8pse58VJ7KHNKq1DohxJUnbaf3W4ZIx2yIYnAezvZ27ow1VV+oETTGay454s4RdS33iQ9nse63vn5IU8JVNoJIa5spcvWWCiEjdDj9pJyNCgu6nkhGjrtc/mjW0CyB867RzK/nAq/fF+MypP3stMlneBsi1MKwY902N++GDVVvqd4g8ksue2JS8YuP1JMFqM5oAB58hRDpZUms86HEJiTuHE5wv0VlWlcQqSt2iDa7XbkfuBbN09wxefBbvbNH8KQvmMYtXQ/BwxNsbC3xtr8CU8e3ef2wTUcXD6ACVuOsdY0+Y/5YMWzxZkuZUW3ipSu0JuB+2wwj/Qj9NkJDuw+w6ajznhEpr5n79KIESLx/NDqDOg6iP4nfDIm188eYQyTnvFofR+GVviVkp13MO9awlvdJCJJdNBDZ1BlahSqzq8Dj7HXygd/DzMu7jjG+YuWPHN+zIOl7RjTuB51Zp1nh00CMeEm+J7ox9BmTSnfSQutJ6HimkF4393A7KYt6TFCiElrRxyMVrNtcj+aDTvK9ttvEhqCz6GxrOxYlard1Fl84jamt3ewavAoxk7axXk/ZTxe4H4W85XN6dBuMu3nXeDunX0c3biEEUM02HroJhZPDbmuv4DJ7VrSrt9SVhsH4yEsv58Qr9qfI16Vw/WCrnBoUitaV2hIm5XX0PdQfFGnW4rXL0n6S5xuLGP8b8X5QVQGhcoPYsYpW56Kb+Kj5ijeGT+D0Sxo860QruLjz9+MdjOOcEFUyB9vvI/E49J6NBt8R2Vx7rdVutF4kzWXvTJ3v0MUrhf1MViwlKOGFtiI0vZ7XZkaTFKQOU8sn2JoE05wTPY+qkTyz5FEQpg/gZ6v8PDwxN3DAw/3V7i7e+IREEVYfDZ97RSJxIX4EeDugvurV7i88sU3OJpY8X1mXdJTSYoJJcjDFQ/nlzi/8sYzMIaY3/WNgrS4MML9PPAU93+l3NxccXF2x903nLCEDHOYA+KuKQ481hzEmGrlqNJPiJeb0blYz108XbpId7gvXuI5XF3ccPcJJjA69Y/+f8nhRAYK5/SVSIs4xs1FpM0zgKCYt475GMlRRAeIZ3NxwtnZFVc35fO54eLmjVeQyIecH+4tUkmPCSTE10O8I/GuxPvy9FDml3h3XiGERCd9htFTkGK5g8tz6lCv9TQ6qz3F4ZPmaP0c8SruGW7JnaXd6fe9Cj9/U45G8w5zyFvpgmRP2GM9jnUpnDEQN99vAxh62hlTZYGLdiT0xCDmNVbW9yX4ps9ult2OITynSIfnMYw1qtOkrDinaA9qLzbh2pulnWJtub+yFwN/EGlTKU392Xoc9FLkOGNMhOkRDHqUoIlIW94aQhSeeI6xMm0xLkScHs7i5ip8k78o3/TYwcIbUYTkJG68T2G2qTYtyou0FelC9fmPufhSWUiSSY/3wPv2eraMakjtkhUpW6UFnQcNY8iokYwcPoxhQwcxaEBvOtevSbOaTei7/hQHRb7+3psg4SWRtyYxp21Ffq08jKkH7vH42W0eGwi7t/8qux9GEvJ+lDddCHFDTWbUaUqPvivZ7RTPR3uVpAfjeX4ZW/vVp36HhYzcZoGVtz++fj74ujzC/Ng85rUuRslidSg5RJctF25gfOsQGzQvclgIfz9PC56qd2N6r5603/iUs8oufymWhN2cxLieg2gy+HjG1GTKSLLPk72sat+GgePXscHoCVc1BrKoS0sazLiBjsWbjBZl+qkGBvOaUbXWOIZPm8shndF06T6LfrOvYvWmrd79AnZbOtGz9zw6TjnAtUNTUF80ksY91Vi6QY8zZ45mTImprbmR7YeuctE5mmDxDfjc+MzIq7IOirfn4ZreDK9akcoD9rJclN1cDw7/DKR4/ZJE3cZSrw+dK+bNmCKreONVbL3rkYupqpKIc7vM2SnCg1FGTr8VH0cvdVZcEUYiQTn1Sk6IvQonLA7MZrTwxn8WlVDBpqMYecET8w8itqJiTrLi1u5NLB6xnoPXn+ElTv/9+spBLMJgRcXEEh6XSkqujZNE8neRRGKAFaYntdFZt5K16hqsXb8e9TUrWLNmPWt2X+OMqRBpH8wakERSsJ04bzf71sxj5dL5TJ62kpVal7nhFpvFN6r06l7x8v4pDqxaiOqMMUyeuZQ5m65w2T5MKX3EhxOIv/k5Lu5ay3rVVaxcLa63eA6zJ85g7upDHHjoj3uOocA4CL/BiTltaFWqKr/NOMbWF+kfn+EjPQaF/x1MLmxj3bKlLJg+kwWq2mw+9wIbZRROEUqc42UMD25EXTkpveoKls6dz5JlW9G6+hxr8bA51ymCVCEqbS5yRXs5q2ZNY/qshSxcvoKVy5cwd94aVu+6wjWnKEKz9BLeRRHuxKtbOhzdroaq2nrWqauzQV0VVdV1qG44zLE7L1DO8f7R1ql3COfVkTlsaFOWRsM3Mv1mAkGfdIHPEa+Jouzd5sTUtjQV9exPKlVps/QEp4PeEllZECkE4tneRWmuDCxU7UBLnafcUAqtYBtebe3IRKXYK/ArP43QQ/VRYg4j4QW+QiBuq0sL5ZiK79tSavh1DGyViiNN5PN9Ts/sQAtxnzwqlWi5UAjTwIzOCdkSbXmSiwN+pbUybRVb03SXFVeUBTDUHi+tbkytpBSvxfhxiA7L7icQllMe+5/HSrshbSuLtH3XkhJDrnDMWpmfwSS6HkJvenPqKO2buJeKSh4KFC5EwYI/kz9fXvLlzUOen37kO5Vv+DFvEwZuvsZNkY7fo55p3iTYaqI5ojUNqnRg+LxVrNHeyYYNuhwxeo5dRBrJ7xfq4HM83D2UZr+Npeesq1jGCucjc1f2CIfV7w7merOY0qsPPQYvZNnOA+zW0WbP7l1s1NzEpildGN25MVU6zGTw+AVs2aTOOgNLbvkL59jPihfrujKjTx86bnXgghDgpFkRbjSV8X1EGRt6ksuOytISi4+JLqs7tmXIhLWoGz7g7DIhehvXpcaYi+w0ect4e+zixvrO/FZrJIOGDmPnhi40bjeFLrMMsXmjFt0vYr+tM736LqDjhN1c3jOYxbPG0mjkSQ7efIGPt3BkPb3x9vLBLzhCONZpIi9i8PzcPq9K0gNw2TeOJfVLUarBUsbquuH3BTWDFK9fjDTSnfW4uaIK9Ut8g0qetlQdeYnLzh+Lc4QT8fws59X60rVUAfL/VJPq3ecz7/QzzEI/FrlRImrBaEOuavahyY/KqG1eyneYzar77jyLFx9TTDSxURFEhgnv0ekeNueWsGDiTLqPP42BSdBbTSKS/y4KFIq/eFMuo/OXE0Wg/VUM96xk9ZIVLFm7He19uuzV1WXf3j3s3bOHrWoaaOmc4sKLUDx/V4EKErwtcby6i31bN7Fxx2Y2r53JuDZNad16LGP22nDXN1kZS/id9NgAYdj1ubhnHctWqgkROJGJ/TrQpNkwRm6+zEkze4yvHOOczla2btvBNq2daCuXWd64hNUj29C9TVc6ThZpe+yLn9DBWYrF9CDSXHeydURtqpZqRGu165wUQijnGiONxFAnHE9v5eCGlaxSX8e6+QMY07crrfoLcbn/LDcfnuf0QW12bt3KFuWyz7u02L56CgtH9abP6BUsPmyOtVBIH/i2GSQQ6/6IR0fWsXbGBMaNmcqMRatZqbGFzTu00N6ujvqs4YwfOoKRS8XzPXzFK2Hwsox5pieQ4vEYi5Ob0FyymCWrNNm8RxcdnX3s19nL3l07xPtQQ3PPSXSMfHAO/Vhd+QZxXJI5V1cNZkD5uvRacZrDQqS9H3jLmc8Rr1HEe51j95jmGS1c36vUpNNKAy6GZfTIzJZo82Oc71+cVt8I0Va+BTU3mHJOnJPmZ4r98hYMLyR+F+L153GHWWuaQnROlb7/Wcy1GtFKiEoVlSYU6XoCfVNl+C2J1ODL6I5vSTWRtu9UqtFh6XHOC0clp4E0MdanuDykNO2UaSvTmKrrHmMgzkkVDuKL1W0ZXViIWiFe8406wKrHyUTkFNwOvIjNnma0r6pMWwMKdTqCrnGkKBvhJHld4cKO5cwaP5kpU6cwdcokJk6YwITx4xmfsYl/i78nTp7OjHnaHH3ojIf4IP/IijjSw4XTenY3O1auEmVRmx2HhTi+Yo+jX1wWdjKJ2LtLODxJiMG+Wxh3xJ+wj3psb4gk1ushd/S3sEM4x8plYXUPHeTQqWucuG6JxZ2zPDixkfVrtwgHbDv6Jy9z0zUUH3FmetBTHNW6MqtfXzpue54pXm2IujudiX1H0HLYaa46Kd9IPH5mB1Dr1IGhEzXZ8siSe3uGM79FdUq32caaa8oeqZm4bOO6ehfqt1/EhIVLOb61Oy3rdxVO2yGuvuldEHgdpx0d6dl7Pp2mHcTw8ASWT+hLnR672GMW95ZojyYh3Acnb+F4JkThfXsnO7s1ZMBkDVZYK/D5JAcwhrCLC9neqTRlyw2h15oH2IvP6uOa5fOQ4vWLEUv0XXUODcxL5fzi4y3ak9ozb3LOOpCI8HDCM7YwwsJCCQ0JIijQH38/F15ZnOHsuqGMaVaBShUaUXfwBtZccMIhPKv537JA2VfWWYuD82pR6luleC1O5ZZTWHbkMpdMTHhw14i7hpe5dlYYDdVRTG1fjupNBtFilRnXXXJrLCT/LkTZSo4m3N0ehyd3uHfnNrdu3eL27dt/2Xbr5i3u3DfBxNEfLyGU0v6slk2PJSXwLhfXjmNC1wGM3XCZEw7RhCUkkKDcYsOJdH/MA40RLJ80mvHHn3FFOeFnRsuEHy8v63BkjSo7zpvxKCKOAOeLnBxTnyZFa1G2/3G0Hka89b2lE+dugcWWBezesgc9Ox9eBRtzU3MgHUuWoHTrEXScvZml81TZpnuBc3Yh+EbHE58gtvAXBF6dwtKOJShepj2dNtzmqhAqWQY0kt2JN1nIiu5lKVW2I/20HnJXCO6c9AGKQPztr3Ng6Ua2a93GzMudYLuN6EyqQfmi5anRpifDVqozf9tFzjxywyde5E28SFeAIaY6wsDUrEH1DotZcTcQp/ej0yKP4z1uc3PDUEY3rU6NZqMZvOG6qCciCI4T11BeJ9afCPNt6E5qSN1yDWkwTodddvEEfbCWehqpoQ483zeVlUN70332IXbc8SDwzftKiCba3xyXiwtYPH0OPefc5KJtLmc3UQShcNFi89hO1KoyhtkHzHkhfs61Nsngc8RrGHEex9gyrDG/KiOVKrXoslKIv4+JV4tjXBhYgtbfCbtQqhmVVjzgpL8oE97GWMxtzKAfxe9CvBaccIR1ZqkfEa/nMNduQusM8VqXIu32se+xsmNAPMn+p9Ea1ZTSIm3fqFSn07ITXPyYeLU5xZVhpWn/vbheyYaUW2LEEaHCEv3MsF7UgqF5XovX/GP0UH3yMfF6SYjXFnSopkxbLQq2FA7UXT+RsnQUaUkkie8jNjaOuHixxcWJf8d+uInf4+KTMuY2/eB9KtJJiw8lMtATD+8AvIPFNZLEcR/ULeKHVHesNIawuHktOq6+wI6XH3MK30fUWclR4l7eeL/ywCcojND4ZBKTM+dxjQsnyt8Dbx8/fCKSiBeJUIhzEj0eYDy/OaPatqfpahOOOSeTHGuMz7kRDGnbjd967ueoVZC4ThBuRhtZ0KwBHfsuZ809e6webmbPxNbUqz+eidvuYBMuvpHocCJur+bIskH0nH+CbecNsTg3h0nN6/KbsPOLrrlg7h9EsOV+7ixvSIuWI2k2+QiXLm5g+4wONKrZjQFrz3HyhTc+Pu4EOFzlrtENjj/y5GWQcBjPC8e8ZRXaD1rCzHvROU9v9gGJJBqv59DwClQu0ZLWswwwClN8ohOZe6R4/VKkB+J2aDZr66gIESk+3mLNKDdAjfkb9rJf53VUaM/eXezS2sJWDVXWLJvLnGnjGD+0H317DWTQ+GUs33uJC5aeuIk6PNcVcaI3MbfnsHHgz+T9VjnTQFlK1+7N4MmzmL90MfPnzma2uM/Ewe3pWLMAxUUl9VPTsfQ+6o25ss6T/AdRroVthtGW6cxs34BmDepTv/5fvzVo0ZOO806y90EEcZ/k0WdBpAN+1+czv1dHGrVfhcZ1d7zfNqQproTeWcqarkWpUrMZv6kLw+Gh3CEKefAVTu/ZwvyVZ4Uz+Xqkd6rPaQ4MqU5ZlQrkabEXDcOQt0RjEH42V9k3aw1btt3EJlGpJp5irD2INnmUrSqlKNVuDjN2G3JDiHPfd5ovwsF+FVv75+Pn/KUoIQzJVmE4s1zQJ+4FYVdHM7tFcYqV78u4gxbYiONy/PajjHG8o8WiVcfYfDaUqLRY8NrK4SlF+eUH4bz+2oN2S89w9IkP3u/MU+SJ/73lTPmtOPnytaPJkodcdnnbzCQT43YTwzX9GFi5BOUrdaW36lkMXkYon+hdEk15IvKie3Hl9E4j6LXVFvOg9+W5H6E2B9g2qCVdWw9l4tFnPHqnbT2SaAc9dMc3pHKp5pTueogDT0JzV+9FPyf09FBmdG9NuS772GYU+BktSJ8jXoNFHumzYXADimYIxNp0Vz3NlQhl6CJ7YiyPc2nIr7T9QdiFEk0ov9CIY14iBR4PeTKjAf2U9kKI10KTjqJukZazeA24gMWu5rStrKzra1K4lTa7Hyj7isSS6HOcrcMbZQ74rUmX5Se5FJqzsI61Pc21EWXoqBTQxepTeu4N9N1F0fR+gtncpgwS9kIpXn8ed5DVpik5i9egy9jqtKZTdWXaqlGg6Sa23/LKsUvFlyGCtOBL7B7Tk87V+jLvuDW/dyH9HNJzGUtMDyXYVBf9/uVoXLoKZUfrs/GRFx7OZ7izvgWtypSjUL3FLD5th+MrM4x1xjKoXBF+rTGUkYfMeexujZXBCpb160Lf0UtZfOACF66c5uTG5axdosGWq448DRJi1kn8Prct3WpVpUr7CQyauwaNpUOZ1704pcs1ptIgLbSuXufinpnMbFGaatXqUr1dTwaMmcKkBRpsOPYQI+cAAnxMuKc5iOFl8lCyzkB66thwR1Rmuc+qVBQO2pyfVZXqxWpQd/ReDHzTcuz//WeQ4vWLIAp3wjPuawxnWCGVjOUG89ZoS5PJq5mrtonNG9RZr66Ouroaasp+cUsXsXjhHGbPnM60aQuZr3GUQ/c9cP8MlyU9/AWuu/oxr7YK333/PSqlu9No+FpWaWxm+7YtbN68iY0aaqxbNoUpvRvToGRJ6vRfzBKTKD7aoyE7ErwJcLbFxNwNJ9/YT/RoJTmTSHK0Fy+tbLC2fYWvKBO5rDo/ASFeg6y4v2cpywd2p0/37nT/Elu/MQxWvcChJxHE/0nxmvLqGqbLG9Ol0m9U6L4PvafvfSwx5ngaDGdih+pUajOR4YcdMVZ2u4lyIOzGUjZqbmb6MX+slXY+1Zmgu/OZ0bwI3/1UjxJDz7DP/K3J7eOMsb+lzaw5h9A87EmUQpj/GCF8VVtQI88PqOSvS/1xehxyjPtwlLlylLbFMjYNykuBoiUoOP4ga22F3srqJUbY4nOkHxPqFqNY5RHMMniKU+aurEkl0U6PRwdmMVPnDnueiV8SAkl9OJ8tvX6kYL5CFGi1mpnn/fD+4KMMJsh6JytaVyCvShWKtNuN1v3ATEMlRG6wKVZ7hjK2xnf8mLc21cce5+iLmGxEWRCu19VY8FsR8qvUosoAPU48j3g34pJghvPpMQyqXY7yjaew6EE4Gb7E7/jh/3gzy7o0olr1/nRdfItrTjG5EK8KktyNeDi7HgPadKLxGksuuH5O4fpM8eqix/qB9Sjylni9mgvxennoH+K17LxbHBGZEetxn8fT6tNH2WSvFK+TcyFeAy9gubtFpnitTuGW29l5TzmXYiwJXkfZPLQhxd4Srx+LCsfanuH6yLK/i9dfZ11Dz02c4/kYk9lNGKCctlEpXkU5Xm2amrN4FU6i7b42QrwqWwCrUKCJJlsNPb+YmMmWhOdEPZjNpN69qdZOm/3GATnmwV+GEK9h9pe4vnEGCyfPYea2q5x96o2n2wNMji5n1ZRJTFh8AB2jl7x0t+Xppa1snjmRCbM2s/mGEw7RScT6mmF1QpPtGzezVseAE+dOcezwefH/FjwLSnjd/J/oT/DDvegvHcPIwRMYPUuVNeuWs37pBKZOX8Cc7Vc5b+eD6zMj7u+czrxBnenUvgu9R81i0ppTHDf2Izg5gdTwp1geV0dz2hgmzNVE/aI9FgFJnyBexdfqvh/DFbX5rUR5Kg/cxB7nRHIzs+fnIMXrFyGGtKCrHJ7TkTqiIvpGpQBVes9jyfknGFrY8dTSDAtzM8xMTTExs8Tc+jnPXb3w8g/APyCY4PBYYpI+JVz/B4k+j7k7pyUD8wnx+lMBfuyziZkXfXAOfNNN4U1XBVfsb+iwvlcfZszQ5PCrhIxlFD9AIVKh3LJE/J4UTIT1cc7u3syKLYZctAj8+ACTfyOKVFKTE0nMaAIVH7yyOSlzV+5R9g1NJ11sf2R5FLHinV7REk6P+n5OmPvhnvg5JSMnxH1TE4gLF2XP1xsfb2+8v8Tm649vSAyR8WlZNO19GnEOZ7k+qiItf8hD4XozmXvSFtvIeOIy8l68izh3wuxOcVJnN1v33+auWwxR4oUke1vhpLsAnb267HZQ4KF8SX7XsN7cnM7lvuWbit1ptdUKQ583skkkNOg6toabWaRthM7DFPGehUR9ocGesUJkFijINy2WMvGkN66i4H/wWHFuhF+ZwIq2KuQrWony806xy1X8nNXzBwmBt6sbI6oVp2TNSSw+/xz3zF1Zokgi8v5+7u5cxOZr1lyPFlo5ygVf3cHMqarCLwVr02zJGQz8shr0JcSi+VYWtSrPjyrFKVhnJeuuvXotLBQhBF9expZOeSn30zd833ou44UAzn699hBeGW5geb0iQsQVoFyr5Ww383/XaIUY8mxfWzpXEg51+R503/aY66+UXSvEN5OcQkpaBGFujzDcp8Wu3ac5YxWMV1xu4q4RBJjpotm2Jh3ajWayYSDWn1UBfb541RhUPzPyWouuq05xOfzj4vXSkJK0eSNe59/m6BvxOl2I18zIa8FJR1ln/rHI6/mMyGub38XrDnbdCxI7hHj1PsqWYQ0zI6816KzsNpCryGtZOmSK11Kzr3NQiNdYr8eYzhHi9XvxnJmRV1WTj0VehXjVaU3Hasq0VRXidSPbbnrmYracv5J0Ul2uYC3ea6+eQ2i40oZb7n+22Se3CBuQFEtsRAghwWKLUNp1UdaT40mIFnY4OIjg0Cgi45JFnZVIUmwEESHCqQwR/6/8TVlHKER9ExtGZJAXPj5euPsF4xciriP2/9EzR/wjKZrYQA+8nV/w0s0LN+8AAnx9CAwIICgyjphkkQ8p4h4R/gS5PuPFs2fYu/jgGRBDdIKoj5XXSBPfokhXuEhXUIjQC7Hib3GTrKqqrBFH+hzhzroGNChVijK91NjwNBbv3F/gk5Di9UuQ5kuCw2Y2jKxKfpXvxIdbl45z9LnoHUdoYgrJCaLwKvvDxSuNrSikOVUAn0QcEY5n0On/G3VEhfV93nJUXnSGPcICfngLYfhe3kRn4hI0VI/wKCzlvb5Q6STFxRLmG0Kk+Oiy/NxTvYh0MOCw+jLmztuB1sVn2HnH/Acjr5HEeVtgaXSeM0cOc/joOc7dNMfSM/oTogxCPIa442JpiZ2DO16x6bzWqKLCiXTmxW0d9ixfzNxFBzh03y1jipcvVCd8FSQ6XuLOxEp0FE6aSr7KVGk3kIFzlrF8oy57Thhy29oJF1EB+wWFERwUQ0ZLvyBVWXmb38PB/jnOQq/Eie8g/PEODvUpTLUff6Bo6zksvheA8+/hBpHL0c4EvjLj0YsAXiinIYj1JPzCBFa2+IYChSpQYdoJdrlkyJ8PSAuxxWlbNyaWUeHnIo1op3mTy6JQZBXNUPg/wWFTR4ZULMGvdWaw/JIjWc5u9wbhMMW/ssPT8hF2vqEZzmdiwBMeLmpDzzzf80upfow5YIa98tCME95C4YTH3eVMbfIr36oUo2CtJay94i5cpSRSwu5wbVFbWhVQip5K1J9zlGPi4tkLMm9eXl7DzOqFM+q7so1msuGx97tpj7iD4+Eu9Kj2LSrflaBIg950HbOE+Wt2sOPQRS4Yv8TOQ7wr4cBHhApjLSqcXFWLiebYn55Jv2otaN1Xk0PuiTnMsZoTnyNeQ4h1PYTm4NfRzW9UatJZOWBLJCAn8RptcZwLgzL7vJZsQvnFRhz3FinwfIDJzAb0U/7+c0kKTDjy8QFbAWdf93lVjugX4rlw652Z3QbiSPQ5wbbhjSmRIV6r0ylzwFaO4jWjz2uZ131eizegzDxDDglhHe/zBIt5TRmkXGwnf9GMPq+rjD/S5zXoErbKPq8ZA7aqU6DZFrbf/ru7DUTgfWMLW5qXpmOvGUy5E4tjVh/qV0Eux738Y4haxv8k9zc0pUmZkvzabQWrzKNxz6n8/gmkeP0SxDgQfHUc8zspl2YtgEr+EYze9JjnwmJ9UcGh8MDviSYL2pSnoHKKkYJN6bX9FtdFbfFhFeyPr8NtdFYfZr/eE14J7+uPekh8IuleeL+04MolW8ztQ7LoQ5ZE1Isz3N44jnHjVzNHxzJjXsX/lKBKE6I+zAk3i+tcP6nLvh0b0Vy7hjXLlrJy6TJWbNRh1yUrnrh/ZK5GZa7FP8Xx+ibWTZ3FfM0zXPRIfmvaIfH1Jz/H/ux61gwdwcQVR9G3F47F3xVA+D8kPcgWF/1xLO5UkuLKCFaGgRZb4epUataXAbM10ThphrF37DtOWUaW/p6vynL+CtuDU5lULg8FvqlNo3GHuegZn6OBTwu1xW5DN8aUUKFQ0Vb02HKb20KtfPiNpRHvfotrkxvQ9psfKFRmMFMOW/FMvM6s6vN0vyc80+zA4ApCvNabxfLLL4Us/BTihM42QGdwbaoKQfpLneWsuuia9dR88cY4nh7GwDrKOqoCBRtrssUokOQ0H8LNVVnRtTR5VISIKzSciTtNMlaqytoGKfPwKVbHp9OvdAEh4H6mfPOFbDPxfXdJ22ThAJhsYN3w+lQu+Nb7+rE0pet1puPYVSzZa8h1hwiCc91hVRhzFx0MV7elTr2xdF10B9uYj00lmB2fI17DiXM/yfbhTSgjnuU7IdA6Lj/JeaEdcyo/URmzDRR7PdtAmaZUXv0wYwqrFB9jrBc0YXBe8bsQr/nH6rPmSXJGi0G2+J/BXKth5mwD9Snc4QD7MmbeTyDF/xy7RzennEjbtypVab/4GGeDPjJgSznbwOBStFNGf39tSIXldzkmXmSyvxl2S1syPP9r8Zp3pC4rHiUSnpN4DbyAze6mmbMN1KFA6z3suuf/xQbwZE0AL2/osLb7EOav0OOieDd/e7eF/wyiYg04xQPN5jRTiteuK1hhGs2rXHmhn44Ur18Ahe8jnm9ty+ia36DyTSlUaq9j3lF3lP7wFyXuCU5nRzO4XkFhRPKRt8xw5h634rnSvmQe8gfBhPo849YNOx6bBxD79uhghahe/C/x8Lw2Czbf48Sj0PcMs/gr3paHexYxt/sAJquf5ZRHQo7Rhn8jCn8LnC9rsl1tJfPXHkDn9C3uPHzAg4u7ObhqMIOa16JW48H0VbvOmRcJWUbmXiOsU+A57m3rSZc6TWk6Zie7XyQS8NYrUeZ50qsrGGuNYMTQOQxZ+5AnPl9tCOHPkx5Pip/I630zmSactUrKSFGGIPqWb37IS77CJSlVawBDN9/kkqci62Z6ZYkNvsDZ5S2pm198M6UnMnCrHS+yXa9dSRpxnje5MKkxrb/9kV/Kj2HmMRucxSkffmMhBFnuYUOnipRUKUOxpuvZdNvzwwFPmSj8TXi+uSNDKhWnZJ0ZLPtY5PUDPIVAVGdRG6XwrE2J3kfZ8yQ8a9Hpcw6zrY1oW1HZpNuAoj2PoWcZiyLKDFe9bgz/TdliVAGVJltYfdEnh6ZeUReEX+XO9m40LZJHnFOZqt23cOhp8HsRthTSI1/w/KwaGkJcNyr25n2J7fuf+KlAMYpUa0fLOSfZbxr+1vr8ORFD0Pm57OxflZp9NJlwIpCQzzaUnyNeY0nwucL+Ca2oLZ7jByEQ2y49zmkhRHOKLioXAjjTu0jG/KsqFVtTd5sFF0QGKwIseKnWJmN+bqV4zTPiAKqPEnKObirned1al+bKeV5VmlOs9xmOWChrYpHfIYYcmtzmdSucSiVaKed5FUI0p2b7KEshvvuXzJjnVaVcM2ptNOGMKLDpQTa4aHRkQklln9ei/DhkL8vux+ew+pdAiGcrIawz5nlVacIv3Y6jJ4T15zkXn4OyEEUS6GLL3dN3eGzqkrFsb06+gOTPIPLb34D7G5rRVIjXUt1WomoeIyOvXxNxzy9hOKkqXZXNbvkrk3/IMTTEh/7FPU7vs5hubkS7ikrDU5GfG6qz9aZHNpVVPEnxkfgHxRKqjJi+ZSwUyaEEX1PnuPocZutZcM454d0KJ8GPWNP1bJs6kDbCaGhec8+6v+y/FmWbpicvDQ+wd95sVq7fh+49B2zcQwlXTu8S9AKXR2LfuMa0LVaA4tUGMnDLXe4Fvd814w0idyNtcLq7j92btNl+4gkmganEvG/AU/yItt2FxrB+9OyxDM17Xm81b/85lH1e40O88XN9zssXDjg4OPD8+fO/aHt9vRdOrrj6RxIWn9V0Np9DKom+1lheOsjhLaqozhvH2J5NaVUlL/mVxlc4cPnqLWLSQSdeRmVhZZP8iHu0lI29ClMob0kK9N7JyvuxhOVY2YYTarcfzW5VKKFSmsKNN7DR0Cvr95pgidO5cQyrLcRQgRZUnXyd0w45rKUeZIaTVldGVClGidz0eX2feFNczw5jSJ28qBRuR40lxpx1zkpdpJNosZtL4wpRT1lHFe1C9cUmXPEWD+51BdNF1eiiFJcF6/HL+IvsskjKPs3psaQ77ODU7DJUUF4rXxcaTLnKzVdvzyX5FuGOvLp/gjM66mgsnsr0Ie3pVK9k5qAisf3akwEbbvEwNO0jzrBIa4oTj1YPZFLtakI0nmGH8CCSP7tcfY54TSEp6CHnZ3egvUh7XpXyNF1wmKM+OUX30gk1PsCRroVpJM75vnpXOhx8hpHyNmF2+O7pzrQaIh+EeP1OuUrRHVEecxKv7sd5rF7j9QpbeTtSftxtzj5T5rwCReQTLs/rTMeMtJWl8ZyDHPJSZOs8KdMWbnaEEz2LZyy68H3lDrTZZ8sNZSQ84jmBun2YXVvcR4jXb/tos+hWNME5ZY+XAaaatWmpFNZ52lJq1HVO2v6dDreyMKSQnJhAZEQiCQlStn5ZRH77HeOuekMalv6V0r3WoG4ThyhyXwQpXv9y4vB/sh/t9iUzvPFvf61HjTW30Xf90h5fGolmu7gwoTj1C4vK4seWlBxyTnjhURmfcO5JISXEklvrFqIxW5V9Zj68eKeCSifZ9wmW67oyZdAgumy24vKr/1qlECMMzWVOrxtLt0bDGKt2lRvCyMW/k9GxhN9bz74+haj0Yz6Kdl7B0odhuOZGbObwwtKjnmGiNph5XTvSZ9N9jrj+FV010kmJ8cDF6Bintq5i/ZpVrFilyurVq/+iTZVVK1awZoMW285Y8sgtgaTPKjJCQqXGEBPqi59vAAGRScS/uY4immhfO2xvHOT4hklM7FSWsvl/4rsfutBs8iXueMd/kE/pITY829qTscK45ivakOZrr3M+UNnLWEFqVCRxYeHEJae+K8LSHfEyWsCkRsVQ+b4RpYee55BVdBbvQEGa23HurqpN0xIqfFdzJD313DBVtuELRyEtNoQo4ehEim/r96wIs8FLvy/jaxeleJWRzDll95HZBt5F4XUe8w0NaF9G3K/2ILofckEUuSyIwOvcSjTqq1Ba5Vt+bDyRYed8eSp0RfozAwxHlqKNMpJdriW11R9zMicFnRJI8LmZaLRWodB33/LDb3MZsv8VDuGv5a5yPs+E8EACff3wC357Kd1kkoKdcH1yhgt7lrKofwMaFv0hY/BY7RGb2Pky8d1uB++jiCDdzwDt0Z1pWakHk/VMeSK+rWxF9kf5HPEq3l3kM8zW9mH0zyoU+LYkNWbsZ88rRQ79bhPwu7eTna1/obqwDwXrDmf8JTdslAUo3oWYy2NY2u47IURLoNJxOwsuhxOSpRfwGsVzPW4tLEd9ZbS2TF8aqtlwSzmbv5L4F1is78/YgiJt3xSn2lQddrqm59ACmEjAIx32ti9KLZG2ArUGMeasExbKyyW4E3d9Iqs6fce3eYqi0nYTsy+EEphDfaZwOszdpRVpUlKk7dce1F1lzjW3L9SGLPk/QBQUDz1urvyNuiXLUWmAJtqOokxl7v2rkeL1L8edF1dUmVqtcMbSrPmrdGXAYWvu5NQJ6i8hCt/zqmxv+h2VlR3+y/el7hpLrr36xOo82Ylgi12smbGCKQvPc88j9r2IcRhB1ofY3qsp/XpNZeHdEJ79RdG/rwZFuHjNe9Cb+RvlClakRJuNLLkSTND7ds7nJPdVq9OwiHgf1UbS46Ablll2QPwE0sKJvjYXrbEtqDdwF0vP+fwFAyCSSQy25P7O+Szq1YJObVrRvHVb2rVr99dsbdvSunlT2nQZQt9lZ9Ez/sypstKCiXW9xo29K1m9cjMbzj3HTDmw+nfShCgMI8LPEatDc1nerDC//tiY34YfFw7W+4MOE4hyOsfRkXWo/31eClWdxOxTDrgr9XFaBJ53bvHkwk3slJHizDMyiLiDvV5XelT9HpVSXam/VnxjHll9Y7EEG65hd6e8VPwuH6W6q6JmFYeXUqkGPhMi4SR3zW14LJTE73O+xr4g7MpoZrUoTvEK/Rl/yBJbse9DYZwV6cSb7+H8yBLUy/MdRdvOYeGDIDKWkn8HIR4Sbbm/ZQT98iubuisKsaiNnlsyEeJGydbHuDywREaT9rfVutJe9yk3chgBlRZhxYPVPRgorpXnm3LUmnCAXcLbDc3QKMK58LfE9LgmG5evRXX3Xe66xr07ECspkuhgdzyN1Nk9uiKVf/6FMj1Xs14o6RwjNvGORN6bxczuHajSdB1bb//ZKZg+T7wqEnzwPixE3W8qFPmpECXGaKFun0pgts5ZCG7X1rOqXiFKqvxM2dZL2GASmLEak3J5zfSna9k2ogQ//yico7prmXrUD/9s69dUEs20ODO6MLWUy6w2HE//k95YvsmIFH98jk5hTV0Viv5UgGIjt6L2NAX/bNMWhsfNTag1KkIpFVFmm89H/ZHv664r6cHCsdFg59hS/PJTEVRqr2KCvjc+2TYnppFkuYcL44tRVxmRrzeK3kdfYSLnEv8XI77s5zu5OLsaNYtWp86oXZzwScsh0v/nkOL1L0VYmsT7mBwcRodf82U0W5ZsMIWVt1xxysq+/WUoLdwrLPdOZ7IQSr8Iw5On+QT6n/LC7JPmJUkm1uGIqMAHMHDyRqYd8cbt/aGuiVY4XlrA8Ibt6DxkI8c9PjK6NyWaCGcLbO7cxOiBHdaitns9k00kUR62WN+5xq2r17j60AEb74QsR2H/gbBmke542z3i8W0hYq5f58pNE4yf+X0oHLMiPpAwJ1MsH919vfLTPRMe2njgEZpDs2hWKOf5DLjEjc0D6NO8BQ0GbGf5pSD83q/IQy5god2AFsq1yiv2p7mWI4/fCSclkBzmhKPZA4xuimd66oF37HuRvg9IBE8dzgrBUK/uZEap38NRnPDn4hmpJEe58fzWCU5uU2eTxnrWaWxAU1Pzr9k2bEBj3Vo0Nu9m+ylzHryM/awZNpJ8jLHVHsz0Br9SplxTqs+4xD7rpCxbNNKsdDnfvzS1y3em8Zzb3PNNfDePUl8JgbqKuc2Kk/+7GpTrc4gD5hHimAQUsbZc0drHdjUDHrmFveMcpL48wp2FlWhaVIUf649i4GlPzD7oMyDulPQS8x2jGF3iB/J/24gWs05hKGpxZaNplNV17mssQ+/0LW4p5918I9JS3El4Mp/l3cpQskwn+u18yD1RprLVGu8Qjc8lVTY1zkc5lRLUGrQVfZfYD79NRSRpL3eza0QlIVDy8m31iUzQtfu9+0nKs1MYTS5PqzyizNbsQ6/jjjzIrv1eEUqM9VY0upekhEoBCvw2nRknnvFSfIsZeR37DHfDxSzpU5mqxWtSpq0GW255vusMvCHyDGYbm9KwdE2qD9qBnuvbAxY/JMXLCHuN5vRr351a0+9w4cWfnaBPvJmAk1xd24TaGeJ1GC0WmGPh/5GKJS2aBKtN6I8qTrl8+fi+y1pm3Y/HO9uKzA17gzmMLf8z331bj99GneCiEPSvqw6RhrCrXFjWkoZ5fuabktMYsuMF7tkOYEsg/MYa9rT9UbzzAhTvqcZ6m5g/lvRUxJJos5UjY0tSIV8evuuoynSjODyzvZ4HL84tYlLlAnz3TW1qDDvCGaeYjDKrvBcRhlxRbUuz/Pn5pthE+m9+hku22S6cISMN9ncUzptKfop0XYWaRSSeuamnJV8pSaSYaHBkZAUqF2tGy+nHRf0mV9j6ShC1rZc+11XrULPw96h8W5OqPXZyzCEyi9H6fyXCvMXf47JaH5p9oxxZ+hMVB6xhnW3Ca4/+o6STnhhOtI8RV9aNZmzTVvRZcpi9zgoi37ecfgY81upFqwaD6DzjHI/DchBbqVHE+Jjz6LQOu5fPQ3XZalQP3OS82UucHB5hev0Yh3aos3nNcpas3Mbmw/d56BaV0ZT6LgoUCeGEu1lifeM4p/ZtY8cmdTYIkaWmtoGNu05g8MiVl+GJWaclTQicaG+8LK5z8+hudHdpsW3bdrZu02a71kGOG1phE5RETM6q8S1EpqT44ml2mYsHDnDkqhVP/FL5YFpKl4PcXFyB3wqr8E298Qw08Mb2TVREkUxCkD1OD09yUmcLa+YuYuXqXejedeVZlHLevewQsiDhDnd3jaNL1Xb0nnGAyyE5DxDJFQpRBlKVcxAmk/zFthSSU9NI+8wOr1Fmhzk/sCSt8+cjT6Uu1F1ixEmHrKRdFD4X17CtU3Wadl7AmMOeOL0/Aij6HnaHetOzyk+olO5Dq40OZEyPme4uHLhDbNugy7Lt5tj5vd3dIInwu5s42L0g1b77kZJdlrDKLAy3D5IgLHr4TU7Nb0+97wrzbZnpjNrr/Hq+w3QfHC7rs2OWJvrnzHkpXufvxV0RKMTxdrYMrUmVUk1os/YaBiJNH7f34sIKF6x0pzK+5I/8rFKWusN3ccJTlOnMI16TjiLAGDutngyv9QN5y7am6fIrGAjP+net5Xcfh50d6V9B1CPlO9B2t02G6P6QRBJdLnBXXTixVfLxU+XedFZ/wFXXDNn6Gj8hSLWEEauSlx9+bkiVnlroGvtlUVZTSLXbxun5TWnQcAR9VW9jId5X9s+dSoiJHvq9KtOpy2gGnPDF4k9H9MQXF2LAjXWNXkdefxhKy4WW2OTomSsRzxt1j8favekuBOn31cfRY4/rH9/5O4iCEmfEbc0etCxclO8rTWHInpe/d7F4jRfPj81iXu3C/JKvPa1mX+F+cNpbZfBtxLE645hd4UeKFWpLx6VXuRea9patEfeLfoDJnn70rPAzP1QZRdedTlhl+UziDgn3ub+tL+2KFuH78hPor/0cW3G9P/Dl5an5LK5XlMJ5RdmZdoHbAanZ1FXiWL0pzK/yIyUKtKTtgosYBaVkCmHJv5MYwq8sQatrGcqV60/3VUZYxyoXyf0ySPH6lxJPwr1V6A7IS0ll5OKnHtSbdIv7vllXPX8dwhy4aLFncg2KqLxezaTFlAMZU7bkHMlUItIW5YTTbR0OLOxGp0rVKFt5FNN0TXkqrMe7BS+NFJstnJ/XiNqNptFrlTC+onBmjTjT6w4v7uxl++EL7NmpwaFlnenboxeNu89h7qod7DtnhJGNDZZPrnBh/WQWjx3H+C1CkNi9F4FNcMfjtjY6y6YyYYY6q/Ze4oaZDdY2llhd385+1YkMH63G8gMm2Md8aPQUgbZ4XtVEa70GS7SucPGxHfb2z3j64BxX1cezbKkaC8+5Y/Hu8P6PkEZybCSRQUGERsURJx733Uo8huAbK9nWIR+lvi9FhQGb2W4Xh3+GQE4kNfIlJif1ObZHn5PXrnJ8zXgWdetA1xkn2P4wModKXplGR6yOL2BU9dq0HbaeLS9S8ftSNcT/EVFP9LgwtCKdGrSlySx9kU+B+HwQ+RElx+8ql1YPpV/D7gxcdoqT7slEvaWpMgi+gOn2ZrQok4cfGk5j3I1IXip/937AC/1FrNc+yhbxHnyUL/Z3AnA6No+l1YRYUKlA3VG7OeEen8WAyGgIOsv+SY2o9H1p8rXTYtldpahIyBjlb3hQk/nrb3DGJDjjPf9R6mJRhF7h2KzWNC9dnTqzRVlwFLXKR4ulkCuxd7m6vj8tv1PON5qX8j1WoW4Z9e5UW+mueF5fwaq2Janw62/8NlmPXWYhCE3xB0mehJqqs6ZzSX79pTZVpl9GVzldyTuIv0MfY6w1jLF1i1GqemfaLr/AqRfvTQnnfwJj7Y60bNiSGt3Wsub0cxwjUz4UYvHPsNQew/zOzWk3ZR8b7ofyjp57B+XZrtifXs7EGr/RYeBqUf6T8X3//X4y4oa+B7m0vCaVCgiH5ps+NJt5H9NcTRETQeDjrezsX55KJRpTbcQJTj5XziD8PhEkWq5De3BlyhZuSN0Jh9F3SiTynbSnEu94gisLmtOkaFnKd1jJetNwfD7MNFHGLnJyZlOaFRb1Sw9NVt0KRujc94gkyESL3YMqUqWEcCCGHeWofcxbAvcN0SRba6IzoirlC9ej9mg9dF8kvjdYLJUE59MYLmlJ82JlKNtmCWqPQ/D64F2Jch5ylbPzWgqRXpLyXdax7EYggX/6HUn+r0kLwl1vIqsaKae/m88o4Zi9s2T3X4wUr3+G1FBivU0xu32GE/oH0Nulzroh9ejw+zyGNSjUbCGLt+pz9JQhVx464RoSn4tIyseIJdrvGVY3z3Lu4F4O7FRl07TGtK345r6FKNt8LPP2HEH/5ElOnhCVqdhOnFD++zgnjh3m8MF96O7dxa7tGmguG8/4zlWpnjHdUFkK9TzATuPQLARUItGGy9k/pBrVmi9h8HYXvLNrE0iLIODaDi5uXoHGlafcMj7NY/U6tC5TBJWSfRikepIzTwN53WUxkqjLM9nYtxpV2i5m3P4XeIoKMaO+Dnfi1fWNbBrTlW4dhzJE9QxHTQP+aA6NeYiZzhj61mpM4z7qbDKLwPOdNEUT+EiHIxPb0nfMGmZcicmY4D+DcFOsV3ViwoDh9NzlwM2/bFhkAgr/61xa0J4uxYpSoe5Epuy3EMI6M4oW9ZIgc1201Lex7uATTNxfCuM9nJnVS1Ci9SamnwrJevT67/jheHE18xpUpEmfRcx6FIfrlw3t/1+Q6P6Ap/ums2TqFEatEmX7thVPnVxxdnPDzckeB4t7PLxxnDM7hHM0YQKDZ+5j3323jJkwPnizkY+wPzSIAVUKUKzeIAbrG3PR7DFPTuxEV10Y8avmmETw1hRbQhWkWHNnfR86K/uUq3Si/ZLbmEe8PT/yG0QBjHrIleUd6VSqBIXbr2ainhVmxtd5dGw92jv3oXXXB7sP1k1U3sOBB+sHMLxyGSoN2MFCo4QPWz/eJz0MhbsO+2fVpewP3/Nd2SpU7j2X8ZvOY/DQFtsXz3lufY/7Bmqsn9iVjs260GHCTrbfC8Dzg488idQIS4x3T2Zq20bUbT2FkesucsXCkWcuLrg6mGJ++zhnd8xi1oCOtGs/jCGrzmLwNJrI9zM52hqX20JUTRbva+pmtC6b8dDBRbyvV7xyFUL2qQnGRue5cnAdK8eNYtxYVdQvO2KRY1cnkdthp7ixsT+NKvej15xzGIvvKrtqKFsSfYlwFeXl2imOHNRDT2cbOku7M6SR0vlXvt+SFKg9hkmrtdA5cICDR89y/Iol5k5hWS4akBZsIxybGcxtL5yCugMYsu4CZ+yDCHqjYGM98DE7xok57ehdrw71equx5qoTyrFVH5TNRFf8H25Ec3B9mtRpQ5vZB9G654a7eM6MspYWSvCLy9zbNozhLX6jesvJTNC3yVj++INrCdJD7HA+OYv5HepQp04/Bqmd5ZQofAFv6ow4T3wtT3Jqfkf61v+NOj1XsfKCI8pxuB/o0qRXBBpvYcuwBjT9rSWtZ+xnm5ErbtGK161eoiyGvrzGA62RjG4l0tZ8PGN0LXkYksW1JP8ixNtNeomJel/GVClHhd7aLL4R9eGMOX8hUrz+GRKcCHyyDa0FA+nRohHN6lanRvlfKV20EEUKF6ZwkfKUriwqoNaiku87m4lqlzF0DMvs8/lnCMLH8gT75gxiaPNaNKpdmcrlS1KqeGF+Ud5XeLvlqtejSaeudOnZk549emRsPXoo/92N7p3b0LZZXerXqkK1ypWoVKEsZX8tRrFfClCi2Uj677XngX9WpS6GAIO5bO9UgWrtVBmt50NAlkpcgSLFF9sj+zixbhcXrd1wtDvKtTk1aFiqFpX7bGWfTQj+KRmL0gkSUViqc2hsZSqU7kD7hRcxTlSQqkgk9O5G9gyrzW/VutFq2ikuvIwgMvntJesC8by7gaXNylG5xkC67nTk4Tv9St2xPb6I6XUr06jHImZe8eVZWDzxSYlEuNzn9rpprFykjtpNH57+uREfmaSSHmTG88MTmNqqOpXrDGX41nvc9k39XeQoPO/jekmVrUcuoWsbgo/3PW4sbEPHUhUpN+gAavfe9DPLjjDcr2uwtkVZGnWdwYir4Tx/t334X4kiNZxYzzvc2LcO1dkLWb5uO9v1DTh+6hSnDu9Bd+Mils8az6iRM5m+3oATNuI7SXpTxt4jPZBAC112jmxJ9/bi+1i8hZXrVNmovhG1w+bcc4nLcDT+OFeokIQnXFMfQMeSFSnaaCXTjrhn07dRnJXmz6vzq4SRb06LblMZMFuDbZvWoKq2l20nLEUZTCY5S2segvvxWai3EeW5+UKG73XD62OOSaIncQ/msrbXzxQsUoziQ+cycLW2yItlqK/fwQ49XXS3LmLhyD706TOJCRqXOGUjRIZQG1nmjXjWlADhVOkvYvGArvQeOJVpGw+hIxzgU7pr0ZgznBF9B9J/kgbrDKwx80n4fQWzd1B2jQl4ivUxTbSXzmGh6hbW7z4qHPnTnDm5H/2d4j3OmcSUkeOYuFiHnTdf4ZylM/AWaVEkPFiEzoSGVG6zhgk6zgRm/RA5E2nBK8MVqE3rQ4dmzWhWrxa1hcNQ9teiFCkitl+KU7xkeSpUq0PdRk1o1mkI3SbuRfuyMz5Z1XniWVODzTDVmca8ni1o0WMmYzdf57q9J55+r/AQwvXM+jEMbdOO1n2XseLsC2zFs2addFFmo1/y6vIaNEa0p03LoQxafIgjJq9w9PHE7+VtDHfNYUG3ZrTtPJHx2sbcEYXk7aD3O4i0pYVYYKY7kwW9RNq6T2fMxqtceeqJh78HnuYnOL9xHCPatqVV78UsPfUMq7Dsui6JtMW44HFtHRtHdaBty8EMWKDHoSeuvPDxwt/5Drf3zmNR9+a06ySE6/YH3HT/KwI2kv9v4lCEGnJselvaVahLs8UX2eeU6dB8IaR4/TNkRF5NML15iuPCQOzX2cte3YMcOHScY8ePc/z4EY4d0efIEWUE9AaX7r/E5S+KvEb52WN5QxiBA7vR3bubnXsPsP/g0T/ue+wIR48dy/z77U38JtKkf2AvOru12am9k527lOnWQ+/wUQxumfLYKz6b1Zui8Do4nQ0tylCt89qMScGDszxOVHsib9zNbLB9YI9XaABeQmDq9CpHlQp9ab/0ARbvhBaFUHiyDr1BJSmfvxZNp5/kZkQcCRGPuavels7lf6FAy6WMPyXEyAc1agR+T3ag2vxXihdpT52FJlx7u98dHtidWMSkCvkoW6QG1buNZcg8ISJ2HEP//A0u33zIIxtnnIMTyGoq0E8mxhbHM8IA9GhKy/ZjGaN1nxse767YlBbkSIDNDZ44+eAY7k+opSYbelWkYumWtF9/l7NC6OYcbIvB+9YWtrQV4rXDJPobBGD3lwjvr4FoQl/ZYXvnGrcvneP8WSFcTx7juCjvGWX91HlOXXrEw2cBBOWYiWkkR3nw6tFpLuqLb0D3ELqHTnPutgWP3eII+UAwijKV4oXj7aPoa25ly3ETjNySSMhWOKWSFGCP873jnNDVZdduPY6cusRZo+fYvIrJokn5DSkkWGtxYXYD6tUaSMf5NzATQiInQacIf4bnvr5Mr65C/hJ1aLL2DPusnTC7dYU7p8T3flTUBYf1OXjwBCcuP8HYNTqHZvk3JJIUaI+D0RkunTjMkZOnOWFggMFxUcccOSr+vsLVx868DFfmZA6kJ5Hk64CL2U3uXL8o3tdpThuIdIjrHD12UrwzUYedN8TI0gORrGzE3B8oEt15vrkfC9tUp96MU6ibvjcQL7ck+hLueof7V09y+MD+jLp7z9797NNT1pvKelKIxYP70NmrI+pGXQ4cOcOxS0IAvgzNYcWrZHFZK2yviuttEcJ+nSabtu1g+w6xbV6PxvoNrN12nEO3n/NCvNPsy4AS8YIinXB9cBKDHRportNAY8sOtmkJZ2SrpvhbnXUae9A5b46ZEK4fj3CJtPnZYHdd2InMtG0Uadshrrd9swYb1gtneOsRDt50wCFUlN3Ms7JG3CzKGbfH4tvT3sDGtcq0bc9Im9a2jcIBVGft+j3sPWuKiWc80R8ta5KvnjQfEh02o9a/MbVrDGDiIStM4j/+Pf8ZpHiVfAJReB6YjkazMlTvqs6kU8HZi1dFColxySQpw0tp3jgcmMy82iUo3Wghw3W98Hq7nS89jKBzc9nQND+/5m1IuyXXuB/oS7DVWjb3KkzxX6pRc94Z9ivX2M485Q/ccbu5jKl1i5K3SFcaLjcXnv7b5iyJSIdznJzWhl6VilLkBxW+zfsLBcs1pGH/eczZfZfbzpFk23U31ySKx7DjxYW1bJjUj159ZjNjpzCOQco9mSgHKon/picnkhwvBLvyz2BjXu7ryYDqpSlefyaLrnvglnl49sTic3sr29uVo3H7ifQ/KcTrl5qP5P8WkXkxwnl65cCLpzbY2L/E0SeS0JytbhakkBzpg4+LMy7eEVmI1rdJJzk6gpjgIKIShSjL/DVnkkgMcsfLxQ1Xv1iic6O0Iu5jd3gM/Wo3pVnfDex/GUdQtuVTQZL3Ax7Ob06v/N9SqGxvRh205GnGviRSgtxwey7EklsQgTmH87MnLYoYX+HgOThg7+SHT+RHoqPZkRJGpJ8TTvbifdk+55mrSJNQXdk+2gckiue5yeHRbeldsw1Ddc24+n859ZIQ/kIoPrt9nJP7tISg28mOA+c5fd8RRyEMPy3vhFJWCkWTS1w8uJPdO7TYtks4atctMffOeRnjrEki2f+pcEpOYKCrjfY2bXbsP8epu895HpL8iZEyUbdHu/LK7AqX9HexR4j0bbsOc/SqOaaecVkMzJP8a4mwxPvEUMa2aym0wRZ2GfvnPAvRX4AUr5JPIBqfI7PY3KYcNTqvY/yxwFxMUSWq6kRzbqn1pmfZMlTov4PF9+LfHQiQ9Ap7raFMK5+HwiUGMkTbmqf+z3E7ruwH+j2/lOhAP+2HPBZq4YOgR7wxNvqD6FUxPz9WG07P/W6YBr9lDhWppMR44WdxktObZjC9d1Pa/FaGMsXyk/+X0hSrMIhR66/xIDTtI031OSHuF6GcFmgD6pNHMWjMWtaft8M6/I0xiCQqIgzf0ERiE9811TE2hzg7uir1Szei2rBjnHwe9bq5Oj0dxdvLnr1DFF43N7GxdTmadJ7GkAthPPtPWgqRR6nCGCcmkpgkRGiOIcCcEAIqNYVUcX7uhdSnkEZ6qhAtuY1AKQIINN/Dhm4NaN92DJMveGKe7ftNIMLhJHoDalBb5ReK1V3A6mtuf0wMLsp/qnKmh9RPEYlZkJ5CSpIQ7CnpSsny+aSLtCSJ95UoHNtPTVOam7CR6szt3I4GDWaz4Y57Rp/R/0/Etx8XQURIEEGBwQSFRhEZ/6nC9Q1ppCVGEx0WTHCQEPzB4YTHCKfos5/97bSJTZm2OFH+M/d+GqJsZ6Yt5Pe0iff7f/teJF+COIcz3JzdhB7thtBO1RQjj+Q/V0/kAileJZ9AHCHnFrKze2WqtVFl1D7vbPq8vo2wuv7H0JvWlLq//kajeafY9+rtteaFIo24w4XZTWn1c2EKt1rPUqMwggKscdrWiZGl8lK08lhmn7TjVeYZ7+Cix9W5wnD/UpISXdegZh6T2UcwnuRwJ54/usvDRxbY+3rj8soWm3uXuHZSl/2bJzOtVy3Kf1eeWr3XofUiPucVfXIi0hanmzvRVl3K/JX70Lnl8tZKWgkQaIiJyS0Om4TgFPJ2re7Ny7MLmFevGKVrjaTXLgesQ6KJ8vDkubk7/iHvTej+OyG4XlNHtWkFmvSYy/jbMTh+vvKW/N+RRlKgKRaavRjXvTvN5xly3C67GJsffo81WdK8NAVUalCq6350TUNyGRX+ygi6g+uBXvRq3Yuagwy48CI6w9GTSCT/JF64XlnHsjZN6TZkLWqPovD4G+yRFK+STyCZuAdqHB1Xm2pN59N/43M8PjbMN9WHRMuVqPcpR9lSLeiy+S7X3y7YyS7CJi1jQfuKlCrdkbar73HRV5wW+Qy//X0ZV60YRatMYt7pFx/OWZvsitPBCSxuXpKK1QfSV8MI44jMZvrEF/g/2MzG6eOZMH8vB+2j3xWnCjOeHZtIn+oNadxnPbtexGWMSn+NEJgp4UT5OfLSTgjelz54RKSS9IErmUR6hIP4cNXZOmccQydvQuOUBU+DwggJDSEkOBD/l8Y4nZnLlp0bmXXJH7PfQ2LC7IZfxnB9Z1qVqkTVQTvYaBNCYIgtFteusFfHHCuXyGyMswfPzi5nep2qtBi4guVWSbj/Ff11Jf8/pASRaLudvbP707bDEpYe+WMhgXdIt8Dx5Aj6V8mPyk+dqTnnCYaemfv+VaQTa6HHlfHVaNt5PJ22u2D54bxQEonkbyWJZI9jXFo3jM5tJzN+0x0sYjNt8BdGilfJJ6Ag/eUeDFVbUq/BWLouusfT7EcvvCb6Of4Gw5jdMA+Ffm1D9x0PuC3E6+v4YypRzwy4PL8F7Wo1odagnex8EkywMtyY4k3Co6Wo9qhNpUoDmbjvCTZCPP6uH9P8iLLbx64xLWlVsw2d5htw8Gn0H31X/W7wdE8P+jdtSO1+mmw2C39LnAqSH2F/cg6DO01gyPxz3A9+ewJtIRlDbvNEZwzjOram+ZANLL/slzGg5B3CbHC+tJKVQzrQukk3eo9bxOKN4hn26bB3lxbaOzajsWgaC/q2ZOic1Sy6H8azN6sVKcQ/HLdweGotKpdsQdvFQsj6eBNkr8dJvX0sO+iIuWdWK38pM8Eak4MzGFCtIZ3GbeOAp4K3e0pI/g2I7yrpJVYHF7GkW2cGLznMbvtkwt8JxSeS5nyIa8tq0qCYCipl+tNM0467v88F928iSDiBqqxoVIn2w1RZZJqEl3TYJJJ/FEXCKxz1p6M2tBtd5p1gh3FOc5T/tUjxKvk0om5geXAkHev0oMOYgxgGpuQ4x2KqrzE2aq0YVuFH8vzageaTdqB92Yi7D+9x9+oRDqpNZWr/gQyetp2thq949fuw2TghIO9zR3sKkzt1oPf41aw8cRPDh/d5cPsC5/S3or1yCpPGTmeS6nGOWgbi/bYxC32M04lxTOjUnHrtpzNn33UuW1hhaf6Ix0aXuaC3nm1qK5irfgb9u56Epryt/oTf6K3HhTmlKZMx52ML6s27w20hJl9rhyQhym2xOzWfea2KUSjjmIKUqFCZqjWqUKl8OcqVLUPZMr9SLH8e8qoUod5gNba8iMf7jRpViOdz2cnxOU2oWaIxbUevZecFA47s0UTrwFkOW0fileVkr+Iho85xY8sQWlTvy4CFZ3n4N3m6kr+bdGKcr3J/6xjGD53B2I33uB+QLEpfHNFu9zE6vIVtUzsztPHPopx9w7cl61CxzwImrdRB75IJFoEJH5kv+GtBlPnYO9zYNIqO5drQZ95RLkcphy1KJJJ/jAQfIix2oz11KENGqKJ+/RX2n7Qc/Z9DilfJJ+LKKyMNZjdvQZfey9n6NCZjQYGsSSf6+XnOjqxJuzLlKNJsJv0marBt+0727NvJTo35LJ23gFkbzmNgHpjFmueJxLy8zr2dc5k/ZRYTFm5iy25x7rbVrJgzm2kz16Nx7AnG/qkfGjJFMNGu17mgpcbKOUtQ3biLXYeEyD2ii96uDaxdtoY1m05y1tr3XdGbQTIE3cBYZxhDm1andNH2tB9xgPPP38zRK3zL4Ovc3DGWfnWqU7VqVbFVo3p1sVWrRrWMv//YqlTtzPAVx7kamPrWCFxx0+jHmB1bzqw+gxgzbjpLt+5k9ZaznL37ei7JLGPaQvSm2a7n8IL21G27gqm77V8vOyr5lxJMpPMFDi+ZzswJa9h05Sn2wW64mR5k15xhDO7Qji5du9MtYz7nLnTp3JWOXccwdYMB512jxdn/AtLCSLZazc7JrShfZy6TtK3wEj/LYi+R/AMo0lAkhhPx9DQ3t05k8vS1zNpnw9OPj97+S5HiVfKJJBL54gIGo5oxuOtwRhx7xaNsLWQ4fsZaqLcpS7VKHWi4xBA9Iwec7K2wNjXGzOQRJtZ2WLuFE5LdCJOUSGJ9HXCwNOb+3QcZ22PjxzwyscTEyhmXwIRsIr9ppCdHEubjhrOtGZbG97l/7yEPjc2xtLXFysaBZ04BBCdkNXpa/JIURLiXFVb3T6M1dx1qs/dzyyGA19Oppops8MHX0YyHhre4edsII6Pb3LppiOGNGxgaiv/P3G7eusUtI1OsHX0JSX57nWdhetOjiBLP9uzhTe7cvs1tE3vMHfzxD0vMIk2ZJAqxrT+e9YNb0HyGARsexGTTL1byryE1iADzExhsXMny5bvQu2GGrbcLduYPeWB0j/uiTJtZiLJqbozJg7vcMXqMib07ntEp/4qIvCLOA/+DA1nRqz6Vhh9m7a2IzxwZL5FI/jRp0aS6X+Gu3goWzlnDCt1HPPBNIulv9ialeJV8Mmnhz/DQH8W8AT1pMv4UeuaR2YxudsT10mzG1C5NmcZTGHMlnJcZqkwhPLfPmFxckUh8ZCxxn6PWEiOJDA0jLCrpE8WeEOcG59m7/irmzqFfqKkyjbS0NBI+iAC/TyxpAbc4NbMvIzoMYcphW4xer68r+dfjh6/NdS7qHef8XQecP1pW/j0o4vwJuKDOMY1lLD3lwC1l2FUikfwjKFKjSHa9ysPzemgfM+G+c8w/4kxK8Sr5dBThKNyPoL9kJN3bTGexnilPhXr9I1ooxGlaCikB57m7uQMtfy1JmfaLWf4kErdsQ4p/A4pPm1dSkexJjNMZDumfYcMhR174J/6jTZWKeDt8jFYxd/AoeozS4cTTYMJk2+l/BkVKrHDegoQDFpOxGtx/5tWnJZMU9IpALzfcwxOJ+A8Jd4nk/w1FejIpUUFEhgQSGpNMwj9k06V4lXwGaeK/frheWs/2kT0YPGcvmvdDCX3TJp6eSGKAA04X5qLeuwjFvy1EydazWXXLCRthdeO/CqsbS8iLm9zduYqtOmfQt4vD/x+deTuBUJtjnF/Ul1GT1Jh3yh2nXC3XJPk3ki4MhvRbJBLJ345CQXqWAzL+XqR4lXw+vsY4Gixh2fTZjF91hlM2IfjEirKdGEKY1XkMN49hZo96NP6tBW37z2P14ZvcdIsg4P8+aiRSlx6Mt7UhZ7X2cfq6Bc8SMpYb+EdIT4og3OkmhjuWsGTCPFYdvM+dkKyWypVIJBKJ5N+PFK+SzydduYa3Gaa6C1k7fwnzD1hh5JlCapwfQWYXuX1Ym93aO9ixQ0tse9E7eY3bLwLwfqeLwf8jwq1MDSbE3wWbZ164+cdm9JP9ZwS3guSwF9gdVUNr6RKW6j7mukt2g9QkEolEIvn3I8Wr5E+SSILrPUwvnuTwGQtMXaOIT44h1s8NTxdnnF554+ntibuLE05Or/AMiSEq9f898iqkdVo8ickJGX0L35kC9u9GkUBSuCNPDc9z6eI97rvFv17EQSKRSCSS/yhSvEr+ElKiIwl75UNoyOsVNv6/xelXhCKOlMRQ/EPjCPx3zDgvkUgkEsmfQopXyV9HSjLpqan/510CvjbSUChSM6K/Ml8lEolEIpHiVSKRSCQSiUTyFSHFq0QikUgkEonkq0GKV4lEIpFIJBLJV4MUrxKJRCKRSCSSrwYpXiUSiUQikUgkXw1SvEokEolEIpFIvhqkeJVIJBKJRCKRfDVI8SqRSCQSiUQi+WqQ4lUikUgkEolE8tUgxatEIpFIJBKJ5KtBileJRCKRSCQSyVeDFK8SiUQikUgkkq8GKV4lEolEIpH8d1GkQYwnwb4uPPOOwj9akblD8v+KFK8SiUQikUj+uySGEG2kypEN0xi524yTz4SY/ROkpaSQmpJKeubfkr8eKV4lEolEIpH8M6SHEeX1FJvHRty+cRNDI1PMnvvgk5C5/6Moo6QJxAb74uPsindgJBGp4rKvd+aK1PBnmC1pxeQ29Wiu8YCDrp8iXtNICnXB6c4pLuhsZrPmJjTWHeSU0TNeJYprZx4l+WuR4lUikUgkEsnfS3oCyVFe+D67w71zuuhsUWfdylWsXKHG+m372HfZhAcuEQQnKIQ8zAFFIoooKyzP70ZLbRv7rtlhEwPJmbs/TgTRLqfY3K0V3RsOYvF1F6xzf7IghVjPJzzUnsXCVqWplP9nfsrXhf6rrmAcDUmZR0n+WqR4lUgkEolE8jeSCj4Psbu0lW3rN6C68QAHTp7n/NnjGOxcjOqErnRp25WOE7ahccOLl1GZp2VFWjBpjjvQnd6SxrW701fjBleClbHYXBJvgffNmQxu0ZfG3XZzxjGC2MxduSOdlJhA/O2ucGFGU7oX+gaVgoPpte4JDiIRf64DgiQ7pHiVSCQSiUTyN5FIaqwrz85uR2fJHJZvOsTeGzbYugcRHOpLwLOrGGpNZEK9opT5pTa/Dddi630ffJOzaYJPCyfN7SSXts9i6pTVrDawwjwy95HXZEd9jFc3olX3GbRd+4KnoZ/b0O+F3Y5hTKlehlJtNzDDIJAw2en1iyHFq0QikXwVKIT1TiI1NYUUYRTleOiPoSBdOXAmKZnUdPHvzF8l/zAKf2JdT6A1YxyDey9B4+IzbCOTRJlWiDcm/pOaSLyfGZYbezK2wncUKtaElisvcdpXQWy2hT6BhJgIQkMiiIxNIjnX30csnmdXod2xIh0nbmD242T8PqudX5wUcYfTc1rTtnRVqow7hqZZspDp/0IU4h2lJJOWmvqPRpWleJVIJJKvgehAwu2Nee7kyssYYa6les2BdNISAnF5/BCTW09wDIolp5Znyd9I6kvCjBcxp0MFChbpSLMFtzj78v04aSRpxkvZ1vNHCv5YkLx9trLCOI6QT+qL+jGE4EyxxlBjAgMrNGfYKgMuRkP8Z31XwaQ47WLjgOpUKd2UluuMOOH373QwFclxxLs/xcv5Oc7RCkRV9I8gxatEIpH8XyNMYIQzLncNMNirx8k7dtgpjawMJeZAKLEeVziweAkLp2tx/nkwQZl7JP8wKa+ItFjPhhG1qFixNdXHnWHPkxhSMndnoIiEl5ocnPoLRQv9hEo7NSZfjiTgnY6s8cSHevDqhQP2z91xD44Vv3wCaaGku2xl+4xeVPltAQsPPEXozVwIzgQSQjzweG6D3dNn2DoF4uNjS9CtmcxvX47SVfoy6ogNT/6VYVeleI0hzsUIiytHOHzuEXdehhKWue/v5CsXr+mkK5vQkhJJTBQFKjGJpOQUklPEb8lJJIvfXv+u3P/2Jn5LyPw9SRybpmys+BTE0YpU0lLE/cQ1EhKU10l+fV+xJYt7K39PVP7++z3f25T3z9iUfyvTrTw/lZRU8Uzp/0Z/TSKRfBZx3vje2MS+FbOYtPosBx8HEJ72aVMB/eeIt8Tn5mxGtetBk65bOPo0BCGH/l7SU0nNsEViS01DmJnPRyHOV9o6pX0RdkKYiT8X1Xs/bX+mMH2Qto/YU0UMyYEmPDi8kU1qW9lyyQHTgLR3z1EKS8uV7Byeh4IFf+abXptYcC+e4N+b9BPEIXY8f3Ac/W0bWbtyMzuO3eW+VzzhuX2WSCcCDvdj/qC2VB53Ae1H0R//ptIiiPEyw/yqPvrbNdi0aQeaujc4c/Igtzd2ZGC9KpRuNB+12+54Z57yr0ORQnqCAzZnt6IxdQ5Ld1zmkkcqkX+zbPmKxWs6ikQfXO4bcEJjEavmT2f6rDlMn7uQeQsXsnDuLOZMm8oM8ducRUtZvHQpS5eJbfEiFs2fw7zZs5g9V/x7tfh4jhhhaB9MSG4zXxGHIsgYqytabF4h7jd9JnPmzmPB4sUsEtvCBfOYPUNcf/Z88dtSlijv/fu2hCWLFrBgzgxmTpnE5EmTmTJtJrPmzGf+yq2oHTDl/osYOb2GRCKBJA/CrPazd/54xoxfh/qFl9j6Jf854fIfINX1FKZrm9C8cR9qT7zOzVfx70b2siUZol1xdXbD3i2aqMTPVHWRrrhb3ODGmWMcPXyco+fvYWTji2+uh8C/RYofAQ4PuHfhOAZHjnL45FWuPXHGKfwzR7KLtHla3sDwrDJtYjt3l9vW3nh/Utgyk9QAAp8/4sGFEyJtR16nzdiJl2GKHOY3FaU3NY4IH3c8XV7hHR5P9PsPkuiOz5HhzK2lwk/5alJ7ngFHvNKIy3gdCUT72mMmBOOZo0fQ19/D9kn9mDR0BpP2PhUCNjfWM414j7tcHVOfYe0701vfCcOQzF1ZItIc74ST4R72r5jHcrVtbDlxnYs3xDs+J4TsqqHMaFeK8kWaUKmXLsdsw/6d/V1/J5rgFxe5tmEiE4bPY+rmezz0S/i0yPef5OsWr/Gu2J3fztaJvRnWoxVNq5emzPcqqKgotzx8W7w2NZp3oUvv/vTtP4ABAwbQv28f+nTvQrfOHejYtjmtmjWiScch9Jmvw66rDjgExn98lGJ6NAqfq9zVm8/0wT3o1vo36lUuQv6M+4rth1/4pVoTGnTsTs++/ekn7jugf3/6Z2z96NenBz06t6N9q8Y0rVuZKiXzkDfj3Mrkb7cb9cuBnzhVh0Qi+feRSIzDCa6vG8KQYUuYpG3B07DcSbD/NskE3tjAvh5ladpzLkOOB+IcnbkrS1JJjQ8n3N+dV+YXuXNoHWrrDrHhpBuun5Tf6aRGeuFjc5NbBrro7NjExg3rUVdXZ53GZjbt1OfA+cc8eBFIoBCxH5XFiYEEOz3mycVDHN65la3iWhriWurqmmhu3YfOUUMMrTzxiEzLxch6BWnKtD29hdEpXXR3bGTTBnGtdcq0bWKT9kH2n33IPQd/AuI/Mq+qksRgQlyeYHLpMEd2bWObSNt69XWsU6Ztiw57j1znhoXIz4jUTw/EKGKIeX6CI6Pr0qJAMSq2WMDScw44iwxTDrtLj7blxe0DbFq5i72XrbGwv8ONmU3oU60hVcZcQc8yFxIq3QffJzuY36QlndvPZbttOO6Zuz4kjdQYZzwMNdgwqgud2o9n4rbb3ApQfqEipwKvcVtd6ImSP/FNvl40nPuAOx7/sHRVtgwnJxAXK7b4lIxo+McRmiolkaT4GGITEolPFbmd02kKX6KfH2bvdFE/9RWC/uwLLKM+09n7DL5i8SpyNU14bIEeeDjYYGd9h0tqI5jyqwoFlUKwWDMqTz3KjitWWNnYYmv7ZrPBxlr8ZmWO2a1DnFQfzPAWZShWvAYVGs9m2u4n2IgPLuePV/iU4uMN83nJi6emWD/QQmtWS6pkitcfy3eiz5bzHDGzxvr3+7612YjfrSywNH/Aw8u72bu4B13LKM8tzbctd7LqcrAUrxLJfxph8hMsebR3DtM79mTE8uMccUn4xwZHfD0oa24nTHZNY1zVqnScvIOtTumEZmVT05JJig7NqMedzK9x4+AaVo9qSbvqFSlddRrdVlpi5f8JI4Ti3Xh5Xo1NE3rQY8hcJmhe4PyTZzx7YcvTOwc4sm4io3oPZeBMUecb++ORk6pL9ifcdC96C4bSv9s4Ri/WRf/uUyyf2/NCCOxz2+Yxv38vBoxRQ/XcS+zDPiI3E17hfHEdWyf1oOfg2YzfcJ6zxvbYOz7F7u5BjmlMZkyfIQyYps3OB7645aS9koOIMNfl0OJhDOg2hpELdNAzssXCwR5Hi8tc3LGAhQN6MmDUKlacfoFNyCcKGj8jLHYOZmCtSlSoO4ZJ+ywwDkjMjJwnkfzsKI+OqrL8wF3OvAzGx+44+gOqUK9UE6rPNOL4s1y8s9Br2B4aRrvGI2k77jyPgpJziMz74m+ixdbBdWlUpzOtFl/hqG0UkW8eS/EMm0MTGFzhFwpWHUOPPW5Y5boZ90uQTkqUJ74Oj7h3x4oH1sGExn3MHRHpTYkg4pUVdg8NuWP5AuvgdGJzPE3sTHTH8+wCNCf0pvMUfTbd9PvbBkb+iwZsxeBtsJQV5VUoKQRk/lYzGHk1kpeZe7MmigSXi5xd2Jb2P6vwjRCPJTqrsvSGN04RmYfkhpTr3NveiXr5fhACtCiVu6ix0yE+l32sIolyvMT5uW3oXa8+lYYeZt1tka7MvRKJ5D9Ikj/RJupsGd+Dpu1XsvLMS7wyd0lyQCHc/pDjHF3Ui/plezN83XVMhBB7VycqSA+259VdXQ5vX4vq6g2sX6fKhiWDGNysIHkyghADaTjrCabKyUVzQ4w7AUYb2DS0Ja0adqPnIn32PfTB+01FHumA000ttMa1oWvzznScoY+uWUDWA10UgUQ7HOHY3E70aNKSlqO3sfaCPc+FQcnQEql+eJse5syKvvRr2Yqmg9ax9sYrnLILOMZ6Enx3E1tHtKR1wy70mK/H3gfeeL05PuoFLka72DWxHd2bdaD91P3seeJHaObud1AEE/PiBCcXdKFXkxY0H7GJ1Wef8iw8I6QjEuiPr/kxzqv2Z0CrljTtvwbVK644xmWc/RHE00VYYaM3jXmdG9K4w0RGaz3krl/aW83RSSQ53sDhwVkuPAvCJcIFj2tzmdngV8rUGET/Ay95+FGxnE7cYw3OT69Fvb6rGaDrh09idmJTQarPVR6ua0/novkp0Xg602+F4/R7sVAG0YRwF+J1YOXSlO+4iBlGUQg/858jPYJQ2xNc1pzEhMkbmafjyIvgj7QgKBJJDrHB8tg6NKeMZvrGk+g6phD00YYH8fyBV7izbQw9W45g2KrL3BGF+u8Ivv1LxKvI4UQTbm4YQqcfVfhRJS+VxUezwVYI2swjsieOgCvr2NlSharKSqt4R6rPvs3pZ4kfb9ZRoogGO00OzShDiTzfo/JtSxqNPsa1V3G5niSZ1DAiLs5n36wedF5xmU3GoiBl7pJIJP81Ukn0vs/DlZ0Y3aU7bVbcx+DFv7sH3V9Goi8Jd2awdlhzyrZYz+Ljrghd9R4K0jxuY31wBksmDKb3iAXMWb2FfbvnsnR0NUrny4tKnqE0n2eKuV9uauJEIm0PcWZKPZpWbU7t4Yc5bBtGzPt6KCmAqEer2Tq0DlUr9aDr8itcC3zTj/MN6aT4XsV4S2+6Vq5O9Y5LWfsgANf3o7SKcFI8T3NoWitala9Dk8kH0baKJ/oDDZZItN1RIdTq07xqU2oM1eegVciHxyULUfpkHdoj61KtYlc6LbrAZSEaY99Pm99NzHb0p2e1alRtuxDVO744fZC2SNJ8znNsdjvala9Fo3H72GYe90ekMksSMsTTywuqrB7Rnc7dZjJrv7EQohnW/TUKkWhFGqnRocRFRhKlHHDmcZq7akJEl65Mxe7r2CxsvnLGgOxRPrg/dtqTWdm0Kp0X66PxQvge2aVN2Pfga6podSxMuTzVqTtmPwaeKW8FpsTDB57i6pq2NC5Vjdojd7DTJZ0cu89+ccIIebCBg6OrUrPuCJottOCJ90dUaHosCX6PuKUxkjG1KtFk5HqWWiTjlSshEozHza1odm1At4GLWWAYjFP2E/L+ZfxLxGsYaV76HJjTlHIq3wmvuQatphzgvE8SOXZ1yiT2gTYGvfJQTwhflW9+I197HbTvBuUu+hnvS8i5qWzo+AP5fxDitegYOq0wxerjLstbiBJiup5rO8YwfM9Ddtmmf6TbgkQi+ffigd/jzazqWIdW7Scw85oftn/nSIivmNQQWxzWtWdSu8bUnHmN3ZaJGXLlfRSxfoS5mmNj+oj7T2yxfu6Ah+0eji5rSLVC+VH5aSgt5udGvKYKG2AlhPAoRtYoSMFao+i+2xXb7NpO4424rdGTNsXKULTJMqaf88ftnb4gQbhfXs66tqUp/ksHms28zF2hhLLWVl481xnLrGoFKF1xMAM2PcE2+m3bIf6VYMPTw2MZW1ukrcZwumg7Y5Vdq2LCfe5v6Uv7EqUp0mAhkwx8cH7nOULwvL4azQ5lKFmoLY2mXOBmQHb9Y/14qTeJ+TULUKZ8f/poPMIqUgjPzL0fEGaOw1lVVowexsCxa1E/+xSLoMRMG5xAXFwCUXGpGbMiKDXsa2IJv7kK7R6lKVu6G63mXeNB2Mf66wpFEHmDQ3MG0Uk4ENP23MdY6M+szxE3SnHFRnsU48v+TL5fBtJd7TF2cW+9j/RoUq3Xc2BsVSr+2op2C89wS+TZ+3r+70Xks4M+95bWo3mzETSYbcajj6pQkbfxHqKsLGVpw8q0G76aBWbJOXdteYtk58s8WtqMXm360HLBHa675CrU/qf4d4jXZE/iTZewfmhxflLJh0regfRfdUdUILkRgYkE39iIXqc8/KYUryq1+bHRdrbe8MnVyLm08OfYafZjRmkVfvz+O75psoLhh/xw+9AFzp7UWJIfa3B97xSmnLBA3+m1fyiRSP6DhF3Hcq8wrjVa0XiQFsdfJWQRPZR8SDwxzuc50LcO3Rp1ZdCRlxhl2fadDWGnMVRvQu1fhHj9MZfiNT2WFMc9nJxWkaoFfiZ/t7XMe5yIT7anefP89AKmVilEvp/b0nj2TYy8kzKji+Kk2AcYru1M+0IF+a78TIbsdCL7sT/JRButY3+3gpT/sTQVhuxgn1MCv7eaK+JJcdrH6ZmVqV4wP/k6r2b2g3g8sxUkQnBeXMrMGoXIn68l9add44Z7QmYroPjfOGOMNnSnS5ECfFdmCgO2vcA1W42SRuz9jRzq9QuVfixJ2f6b2fU8jqAPVLhITLgdz6/uQGvFAmYt3cuum654Zu5Vivl0vwc8sHbgtmMC0b+nXVj2JHuebBzAiErFKdlyJVMNPPCKiyPCMwBvtxBikt6bfktJ0iuSTOezaFgPKrTcwpbrXjn00VQ6JmZcX9WDjgWLk6/mciYc9MD/7bhUWgjhZ6cKZ6MUv1Yewwhtc17EJxLr50WYlyt+Aa9wdbLHwdmV515+uD6zwMroOoZGFlh4RRGaGEeUhw3P7lzm+o373LPzxyvq7dXgRL5Hv8Lb5Snmpk8wffQYE3tPnMMycuAtkkmM8MHVVjhSpmZYXdrAyUWNad5+Ii0XWmHio7xiCoo4T149M+fhzVvcuSPKt0sYAb/naTxehlpoda5Pv/FrWWKee/FKjC1Bl8YxsV1zqrRaw6Y73l98XuV/h3gVhd/36ADmtvgGlW+LoFJ9JZP2ueKbq5a2AF4eX8yqGiqUU3Yb+LEpRfqcYP/jsFwI33QSfO9xcVobunyjwg/f5eOXkVosfZJE4AcvXRTItGTiIuKJjUok7Q/3UZSpGGLubcVQZwErr9pz0Sfzd4lE8h8jhQSTLZyeUpff6oyiy7L7WEd8vCaSCNId8bq7mgmNmtK0zXy2WoTgkesogKiwA09wdW1jan2KeE0KIOjcTDSaf0OxvEUoPWYnG5+nE5TtfaOEQNBEo3FhSqsUp1JXDfbahL1uZlaEonDawe7xFSiepxgqjdYxzSCAwGyTkEaqzW4uTi5J7YLC/rScyfhrgTx7IyjTggi+MJeNrb6lRN5f+HXkDjY8SyXgAwH5hhh87mxlU/OilFUpSvkOamhbiGsodynCUbjuQndKZUqJ51Spp8rEY3452tg0O12uTS9D3UIqfN90CqMv+WH7TmfIFNKCrXG+tJb1c6YzdsF+9t91xi0qjvikZJKSEoh3M+TlpaWo6Z9H42E8gW8iSv9r7yzgsrz6Ps50m9uM2d09u7u7u7u7E7sTUQwUUZEwUFREsKU7BARFuru74fueG3EzEHN7557r+3muB3dfda4T//P7n8wV9bPvBZRntqRp5ea0WqHDeaHoIoMdMLz2BO3rrgTEZ7zXYp0TZMrzfZ2ZOnQQzddZcu1FYekrVKpMvG4aQN/ylSnb7SDLb8a+IXZzRLQIYbilLxPq1KBSl33I6/kSGOHDs1t6WOjpYmmji87pLezdd4Atanqonj3JqbVzWDJ3OavP6HHZ4ikWume5tG0Wi2fPZ/qmy5w3DiUyS5aBMskIc8XjiRY3Lp1HWfkEyod3sfvgWZR0nHgamvaqhTcnjawoR54ZXkP9zDnOnFLm7K6prB9djzrtZtJ1nQPWQelkpQcS/FSPO5qnUdy6ga3rNrLusA7q5mGEZ+aIrxGOjb4CR/q0YPjnildCSHuhxJ7R7WhWfwiTz1jz5G8e+PqfEK8ZfsbYbGjHxApCfP5WmV+GqyB/P4n4j9p8kXHTbXisMIWhxeXylqv6ofYg2u60Qs/7I0Yrjxhin1/k4PDm1BT3Fi1ak9YbtFANECbqPeMVQ1yIE3qXTNDTcycy9Y0OlEwRVgsNLK4e46KND1afM1lMQkLiv0NuGJ4XFrC1Sw3qdJNn6vkARL0j8SmE3sD25GA6txhBuymXeSiU1adHnVBFIZrc3v554jUn0Q3HA6OYV1aOUkUr03jxWZR9ZAPZPkQW4UYnUelRhj/kilC29SxW3PPnhexUui8pDxewuX8xivxSEbk+iqzWiyWqsBFoHud5LF+b1pVE3Vd3DF0VXTEMyT+X7skzhXEsFPXi70Ur0GDBaU565RYyHjObSDMVzvcpTzO5HyjTfCpL7njhIjuVHkDakyXsHFyMH38th1yPgyy7FU14YRHspYHJ1vq0ryzCVmsEHQ868SCvBTCfGBtcrm1i88RBDOg/ianrjnL00i1u39VD7+Y1rl3R4NyOReyaO4gp+zXY55AlRF3+vWmeJBotZXXvmlSuO45pas9wjvMm1Po0x5SusOeSL/5CALxdDacRZX+JswMbMrz/ZGbpR2BfaO+2CGvmS2wOjWVWo2pU66fA0ltJ/HVLKPFWh9g/oArVSjShysQrnHXwIdDdCA0RXk2NJzjY63Jzgwh/z650XnQcebV73Lmwm1NL+jJixAQGrTyHkvZ9TB8cR2XrdIb1ns2s7QaYRyWQnuaI/c0T7FwtBOX5e5jLVkoy0+TMiunMGbeY1er2mMRBcoQbrmq7OLN7F4d1rbjn4MBT7c2cmFifxi2n0m2jJRbevnhYPeT2mcvoPzTHwfomt5WXMW3QBEYtVuWKV6LIs5kEGiigKMTrsM8Wr2nCn3jIlcU96F2rKW1XXOf4809Zwu3L+Q+I10xin11Da3R9Ov8gBGTZBtTboIuyu4jOj3rdcWQ/P4byjCZUlrW6FhGZcNQOtpiE4/FJYwbcCDHewKJuVfhJ7ieKlujNZKXHmIsEf0835zwjyFKZ9evOs+W4MwFJb4jX7HRSfZ0IeGaNS0gcn7M6i4SEhIxEUoKe4WLxmCePHvPIyBQTExNMjE0xt3+Ja0gaCR8ccJdPWhiRblbYPLnP/fuPeGRohLGxIY8eW2Dm4Itfwiesf5mHrEXpJT5OFpibmWMqDgtzE0xNzTA2d8HFN6aAiTUyxNPT7XiwbRija9ek/vgTbDROJe6jLxUXZAYT7mOPpbERjx8YYmLznGeBryfwiEo40Qd/V2ssZHFiYoThI/Ft5s7C3hQ0yecDJAoh7WyG+cN73H/wmMdG4hlGIn6eWGPlGoyI4k8khfQQF9wdRNyYmmNm/ip+TEwsMLFy42VwgkxKfibZJBvt4dKM+jTvvZIhil54fnAWTkF8iXgVlXOUBfqr+jFQ1D2/ydWi/aqLqAfJapYPE2N+nksDytJW1DnFGg9lmOYLTGRpHOdK2LlhLGku6qISlSg6Shn5R0nEFpZv/TWx2N+Y9jXEPaX6UX+JMbdeyB4mEjXRhnvrBjKkiBzF5arTZvk51AJlzSgfJs5KA+2hFekgC1uDAQxSc+aJ7P3xL4m8OJqVrcV7ipejyDAl1t5PJKqw6Am8ivXhZnSpLe4p2Ys6C55wzVUWthSyYuxxEE7aoq6VKVP0d4qLertV16506daZzh3a06F9W9q2bkaDiuWoWbEFg3ZqoxkmK+X5pL0k/tECVvSsS9WaI5mteA1dw2vcUtnNgYsPUHdIJvZd4ZUpyt4NeSY26sGAMQfRCsz4+MSq3DjCHh/k3GwRtp5zGSV/izt2zjg8tcPBQpc7p5aLMFSlTrUmVBx2mE2nL3L76gm2HdZHwyyIUB9TLNd1ZWKLxvwxV5295rFEBBniqTqYMe1aUaPPYQ4IbyM+xxdPg23Mb9eNQVOOcN7FC287RU6vmkz3sWc5fCc03/YIR+fYBFZ0bkSzCUrsfODEMws1jk6bzIK5B9HwyXrlOHlcxnRNG7p1nkWP1XcwNL+KzvE9LJl1FNVb1nj6m2F2ZQ2zO7Wlw4DVbDWPwE+8IfiuAsf6fol4FaS/xHrvKGY2rEGNAQqsuBXzt+669R8Qr+H4myiyuVM1qghvsXi1XoxQseLBR5usheEJssDhyBBmNvmJH4qW4cdmC5l63Ar7mCxZh8HHiTHETX0oo1v8jJxceX6suZB1mk7vLHacS65sK74XmpieXcDMrZpsuhlJ5FvKWlyTlUFWRjqZ2Tlft42ghMT/FKLspEUQ42rAI5XNbF88k1lzFjB3+VpWr1nNmhWLWbHxILsuWmPilZTn0L5fvET5jPfFx1iDS3uWsnLmFCZPm8vcpaJiWrGEuTMWMG/VEY7qu+IYU8ikExm5WaSFOolK8gind61m9bpNrN2wic0b17BuzTpWrd3PYfUnGAeIyvW9gp4gzNl1zi/oSNsqjWm58irHPWXTVQonNzOK1JfXuXd+C6uXLGLupHFMn7eeZUpG3HdPIFkI1xArda4obmL9qjWsWb2cpbNmMG/OGjaoGHLXM5VCJwfnZpIW8ZznBqc5u3k+i6ZOYcrMBSxYLuJn2UJmT1/Eos0qnDX1xUMIxkIlY046yT7m2GjtRXHrGlaK+NmwUT4vftasXs9qeUVO6FhjE55J0mdtkx2C86n5rG9Ti06zjrHBMpuPLX36Nl8iXlNIDdZHbU5XWgqx97NcA3psuMS1iLyU/CDxIi2uDytPJ3HPD3V70FbJAT1ZfRVuh/veHsyoIhN7lfl1yjm2maUX3oMYLATikRZ0lgnEH7pQafQttOxlOSaLnOgHaC7oQZu8sNWl61oNrobLBi58mAS7y9waXYVusrDV6kzLI9bcEB+TG+mI98G+zKkufi9enmITTiNvlEZMYRVl6A3sj7ehRz1Z2DpQfsQN1GxkHk64yK9nODm3C83KlqT4ryUpUaoM5SqUp3y5spQtU4YyZUpTuvTvlCpRmvJV+jPr5GNMxK1/aqmcMKGVVFBeOpJ+bQYwbdla1h9UYtfBK9y08iUg/d0F9sV/+Kpyb/9gWrZdwvCNprxIfXNs6YcQ9XGCA263d7FlyhjGjF3E8r1HOaiwn0MKx9mtoILKlunIT+1Dh4ELGT1pGfv2HUDBwBXzhGzSgm15tqUXc/v1pctOK7S8REjSbYm6M51p/YbScsQFLjvLXJ14gsyU2NC9KyOn7xKC1pqHSlORHybSb95tTlm8tgJCI5htQnVOK+q1XMD09bu4qraI0UMWMGbRNYQ2foXvDRz392TgoKX0XqDG3UurOLRhGp0HyrNmtwpXrp1H9fhOti5ZzMpd5zjrGEMwaQQJ8Xr0S8VrbiR+5+eypV0VqjRZxsRjrvh9kpD6Mr5/8ZrpiIvOYsY3LMNPciUp33QBWx/6fWSJrEwy/Z9gdHQ6s5sVp8IvFanUXQhLJVOeeCV/cldTtvsVTOUb01MUaLkf6vNz293suOSEX2wUMVERhIcGE+TzjBdWt9HZMoFlI3szbM9NjrlmvbM8ioTEvwVh5LOEgUxNJfWbH+mkpufk7cv+zYiwwVFrKzumjWT0qJnM2XyMw2raXLlxG12929zVVuL45iUsnLaWrecMMY7MfaelMZkENz0MFBaxcMxohk9ayar9ZzileYUrOje4eVP8PbyUDZP7M2DkYhaIStQwLPsD4kS2BqU+JmfWsXbJepbvOMP5m3e4rXcHfT099HSvY3BxF0cVFdly3gHDl4lvV57ZIWS6HmDv2AbUrtKRXnvuoxMts1aFkUFikCMWyntR3nMAxXOqXFCYwZJRXWjZZSqzth5CRfssR48dR0n5Ipq3dNG9dQMdVXkOLBxI/4HTmbJbl7vB6R9oLYwm3FaLS9tmMH3kOEbN2IC84gXOXtJG+4aIn+sX0Ng1iyVj+tN/4gbWX7bFTkROgY2wmXEkO1zhjsIqli4WQvrgBTRv30Hvdfzc1ELv/Hb2K5xmp5YbDoGftN6LQAjPxIdcXj2cvtU7MnbXbW4JhfZ5HVhfIl7jSPG7yrEp7V8NG5P7g76bhHgSaVbYZhIJNhrcGFWBLkVEvSHC22CnOdqRotgFWfB0XQfGl3glXkvOvMgOq6z3t059k5BrWB9tS5c64h651pTtexFVC1lKppEVfpNT0ztRR4StiBDWvddroSPeU5iwThTpc3tcVXrIwla1DXW2GqElBG9miBBh8l2ZXEo8S4jX36aqstkso/BW4bBbOJwU+biBLGwtKNVDFWVjWed0IpnhlpjdUOPUEVE+T57gxAkljolyofjWcZRjx09x6qwehq7BeWNv/yov6eQmeeNupsvNcypoXNbmkr4lj6z8CIotKM2SiBQ64dT4RjSdcopFt+MKjYe3SSMj+jnPHmmjc/EC6ldE+bkj8qwQmE9svfB8ZskL46tcVtPg7NnL6D6yxC5U1g0vinSoHc+29mXh8OH0VnDlpkyYZNsR+3A+M4dNoNP4y9x2k7kTyQRZnGFb726MnbWDnXcN0V7Xn4XtW9Fkrj6nrN9QJT5K3NnRi8YNJjBq3HiU9g+kXe/FDFz2AKfXjXY+N3A+0pchw1fRe9YJdE+OY93SqbQer4rSVROcHGyxsbHDzvYpTh6B+MULp1uki5/+YRS+aNiAjGTi9TdwfFA1alQdRv+N97EV4flYh9eX8p2LV5GVI3UxVepDl+q/5LV+lv1jARvVHmHx0g03txe8eCE7XHn+zBEnextsLEwxf3SZK6KyWjaiHe1adKbt8I2sv2CDddj7A7w/TBZxxsfRHFmGVsVF4Sxal5/brWT21nNc1r7M1SsaqF9Q4fShjWyZM4AeNStQu0YPRh83RF/Ylr8rQSUkvgxRQ6b5EuhswG01ZZSVjqGkJCoUccj+fv1xjGNCQB07LgTUXSFwwtL4qp0Ec2WVszX25+axsm996jXoRcf5qpy1jSbkdWWfE02krQbnFvRnUJ26dJp7mH3Pcwh5LV6z44l7cZMbG4cwukkt6rSZxJhDj7jvn/F2a2eoHkb7+tOjShUqtBFC+Lofzu81h2WQnfAch+Nz2TC0J30Xn+OAcTh/DV8XH5v4HL9by1kzdQytRl7gyJ3gtx3lvHF8i1nXpyqVqvdn7AmzvNamwrQLWb7422pzeJUCh07Z4R4fTbbfUdQW1KZK8d+p2KQ7A1buY43yY+47R/8lqtKteXFpGqPqV6Ny01nM1vbBIeHtBMlNCyXc+jzn5nelb/061O+xhLmqwoaKWvmvMIkAel3g6vJ2tChXixoDdrHFMBr/tHcTN420YHNMdo1l4aBBDNxwk/NP42R355NJVqQ5zy7OYsaoybSfrIOWdXQBreQFkBVI1tNtbJ/Qk7p/LGOd5rO8DR0+6d4/+RLxGkWSjzoHxrehYp5A/IP+m6+gG/Nx8XpzTCW6ybYyr9ye2hueoBUkYsjfFOulbRj1k/hdiNffZ19kp/VHxGuoDjZK7emWJ16bUqa7EHsmsiUWkkkPvoLi5HZ5Q+J+kGtE3w1a3BSnChevV9GbUI1esjBUbEX1NfdRE4IrNUgIslUdGVfslXgtPl2VLRaZhYvXcF0cTnWmd4MfRNgaU7LTEY4+DPzGC9hnkpuRQGxCKuJ/H0AEMt2FxxtGMr9FS4YfvJs3fOJL6uDc9EQSo6KJT8l8xzkS+T01lqRkIeDeeHBWqD1OW/uxePgweh924YYsY2bbE/doAbOGT6TTBOEsvBavlips69OT8bP3cMDQkruHRrO0XSNRpk6z50HeYIBXeB/FYHd/WnRazNQFizl3oB8d2o6k04wrPH7drB6sx4sjfRg8VIjXeSroq05h3dxxtBxzETW75Dd0ThqZKTGERqeSlJmAv2wjjf6tGDlnNxvtsvnY8rBvk06G9X40ptehXoW2wh5fRD8yR3zZ38N3Ll6F2HQ+zq1VtWlUTlZAKlOi9ijGLZBn98F97N27hz179rB7pzBs8qtZs3QucyaPYcLwgQwcOFIk0Bbkzz5A3yk4z1v7PE89Ek/trWxr/iO1fhAFvVQNynUZz+BpS1i6eBFLFs1j/uypTB7ahR4Ny1DihxKUrTOFVdrOiPrzK8gmOzubzOzcN9a7k/hvIxI6RxjpHJH2+b98e4TlD7/DE+VpjGnfkLq1alHrmx+1qVW7Nd1m72e/VRSen1fg3iI3wp4XanNY2rEsVWu0pOXCcxyxiCT0TzUkClmsOXe2jmdIxZKUKVqS2jMV2PEsl9C8cpNGsrc+uhv6MahqWSrXGcaoPXrcCUwqQFT74Xt3E4tbVKTEz+1pMvsmV57FvZMWISS+UEVhQhe6txzK9LM2PHlLwcST4qGByozW1C/3B6U7KbJXL0gmmf4i0YXIGxNZ1K485WuNYraaHU4irB8u5uJMxH2c9feyYvd1DhskkZwpai/3PZyd+Tuliv2IXI3xDNj1mLtuscS91RwaRKjZTpa2rsxvP3Wg0dw7XHZ+M8DxRNiroTanHZ3KVqBaixnMVRFiOvL12ptvkP0M+/OzGVe9NMV+H0K3jcYYvttqmutNiNlBNvVvQ5cu01h2ywuHt9I/jAibI+wZ2ogKpdtTY7A6560+ZcUXQbQDAWcGMadfN+qMucwps5gvECZfIl4jSPQ8x54xLSmXJxCbMHCLEH/CYylMoCXaaqI7vjLd8wRiO2qseoC6n5AvvkaYLWzFcFmrp0y8zlVnl0124eI17Aa2JzrRva6s/mtEmS5HOW4oW6QoidRADQ5NaEMFETaZeOy38RK6H2kVTnqqjf7k6vSWLRtZviVVlulzzlv87m+G5bL2jBaCWyZeS8w8x1bLrMLFa8Rtnp7uRp+GRcT761Oy/X4U7vkXOh747yGcTP8L7J0wmM5/TGezjgt5w4K/mA+XyHfJDLLGbmMv5gmHrfu+pwgfUcgWGyINZjNt4GjajtZAx0U2Cjkef9PjyPfowrBJO9lv5oyt/gb2jWpF3ZbLWXruKYF5r80mx2oX2puH0n3GSbac0eCJ2nRGt2pN076bUXBMIkgIg1wvbez3dKF3n/n0WKiBwfWN7J3Tk2YtZ7DgvAN5ozdkfTox1jjbGnHDMhCP6Ah8DQ6h0LspQ6ZtY41lBj6f1fKaRe4LocdWNKRRhQY0maSEun/+GNy/ge9bvObGE6u3AeUBv1D9F1HYSrehWv8NLNt2DJUzJzhxXNbac4yjRxQ4cvgAhw8f5tChgxw6cIADShqoP3iOi4jZT8+KrxElNssZk+PzGPO7HCWEcfi9aV+G7DjNIa0rXNLSREtTHU3185w7uR2Flf3p2a47Tbvt4fhDvzdaYz6PnCg3fIyvof/YhsfeacT/jeNJJP5F5KQKsWbNM/O7XLvvimPgWyrkGyEq6Th7XB6e4uiWtaxcufJvOuTZqaKLrkcCoV/S9CEj04uAx1vZMagqVeXK8EubtawzCMT/LdGZSlrwPTQX9aF7+cpUbzqUUYr3MQjLFxbB5jieHM30RkX56beG1JquwVnnpLfF5J8kE/n0HAr9aue9r0yrTey57/v29plpzoTdncOsdhUoI4TwBPWX2OefekUCqR6XODl3GL07T2TU5rvcdE1422GOtsfv3DBmNClPhXpTWX7VGY/8UwWSm0my1UkeK81jqaoRZ71E1ZYSTNrdRezuVZRSxStQcfAhNj2JJeI9IxdJuIOoLLvV4he5Gvze4RAHH7wW08JJ8rrN461dhbAXdrVMZ1qveYCef+YHRGEUPvd2s755WUrKCSdl4FHOO0a9LZISjXmhPpIh9YUwbzmbpQ+iEJroDcIJtz7J7rH96dZ9LtMPW2Dkl/IJPWHZJLvrcXvaHwztOoDuiq4YBH1J68CXiNdwEj3Osnt0C8rmi9cBQrze/hzxWqEd1Vfc56IQNUk+hpgsaMkwWWPIF4nXBpTpfASlJyKTixCk+F/k4PjWlH9DvN76HPFariWVl9xB1VPc42eKxdJ2jCr6aszr54vXepRst5fDd7+8/vti4u2I1J3ClMHDqDdUAw27mE8eGvhV5MQRY6/O5XE16VyzATVmXUbBMowQv1tYHO5Gt1r1hC3ZwjbdF/gGO2FzYT4TalagZrOpzLxki4XbAx4pzWF6j34Mm7uPg7eNMTZ9xAOldexdtZq1akIHuPsTYqeC8qTWdGrYgjZTd7JSURU1hXnsGlWJGjU7U3fscZR1L6O5ZyLjmlancceh9J23mo07drP3wCGOat5DxyEQ30B7zBXFu2v+So3WExmu5oZpWMZHhi29iSh3fqrc29yMZpWqU2vkXo6+SBVu/d/D9y1eM/xxOTGbNTXl8gpokRaT6XXQlJt2XgT6e+Hl5YGHhzvuL8VfL38CIuOJz/jUGcOFIUxT9E20t/ajiZzMaPxOo6FbUXSMISj/ij/JCiDzxREOy69jyCwdtC0j3qkAZLVKNlnZ2WTI1lorUEnnkJvghce9k5zbsY7NJ/XQck4h6h8pgf8ictNJi48kMjiAwIBAgkKjiEzM/DxDlJNFdpow7CkpJKWLeP+Seu6bkiMERxKpqWnIeloLDE52ErmB+hhp7kZeXolDV57iGJVJ5ud7Xd8/ucmku5/jxpqWtChTFLlSQ2m/1phH/u8KepG28W44XD3C0fXybFbU5aZjBPGyGM6JIeT2Fg72Eka6aBGKdZrP9JuBOH+wPzWBcHtVDvermze2sWztKay58extYZlgQ9C14UxpLexByaY0mH2KgwbPcfb0wy9ICLO4WKLDPXB6oIvBrQc8eRlN0LtNmGGWuCn2Y2K9ClT6Yx7rbjzHN/9UgYjyEGemhZnqHlSNXfOGGGTEPMfzyDDmCNFZunQ7+uzWxyBe1s78LgEEWe5nZaca/CRXnlJN1rNDz4sYYY9yM/3wPj+XNS3lKFP0F0oN3cFa43jei+I/CcfLYE+eeC0r9ws1Oq7moEXQ27Yw0gBn5S70kU0sqtiFDmsuccbQnZfCLvuHiDKdEENEgAt2d26gf8cEM9+kwpeI+pMQ/I0UWNe2Cd17z2etWQzPv8gufmHLq4fqGy2vfw0b+Jh4vTWuEt3yW16rr3yAukjoJF9DTBcK8Zrf8lpqjjo7rT8iXmXDBo53oFueeG0oxKsix5/kt7wGqHNoQuv8lte/hg0ULl6vcmdSdXq9bnldqs854RQl+ZtiuUyI1x/zxeuMc58wbECIV5Hmr4YN1BfiVdby6vcPt7wKB89Ri4cLG9J/0CS6HfHEJOQfMvrZotzbXOTS0gGM6TWEgWs0OWPpg+cLPR4dncy03r3oOnYvO2844exuiaXaapYP7E73IStYedkRm6g4Ip/fxuDAIlav2MjyQxc4p3me04qnUVI2wMjz1bjd3PiXeF0V5XdCdzp3Hs6ASUtYuWIGK6b2oE//MQxdo46q+QscTDS4vLo/w9s1pmGjFnQYMJ7hi0+ipO+JT2IiqeGWmCgtZFlfkZ+GL2X+BVuMAkW99OprPgFRIQVp8HhXa1pXqUyVwVvZaZ/4TqPCt+M7Fq+Z5CTIFhAewSBhBH6VK0q5YRtZ8jiaF0lZ5GZnkZUlKnjZ/seZ4t+ybvb8O7+a7AiyXfdxal5tfpf7URTM1nQRhkZfFIr37YwwJJ5KqJw4xPR99jx6/k7bjhAmOUmiggsOw114OSkF2MrcJCHU7uxDZdNC5u28zKknwuDHZZP+D5XBfweppIY+w/H+Za6cPMzRQ4dRPK3JxXuikPsJIZp/1cfIiPbB31IYj0emPHweR3jy/6cCzCIl6DkuD/QxtXHBVViilIKCkytqiJQQIuy10FNYwsJVh9mg4crz6MJqjv8muanevJAJqz9+FmXvB37psZF5etF4vdeXLcp7lsgXkUEE+/rhH5pAXN4KH6LqjnqA3tYBdP1NNk6xFs1mnETN5839yt8ljECLo8h3rkkZmXitPpaV15x4nn82jzQXIh/OY0nv0sIeFOPHCg2o02YAPUfPY+66AxzQeMQd+yD8whNITU7Oc1TetRU5weY829+LsbUqUrnZYjbqun1k4mkOGREBRPl4EBiXnCfMUwIfo7+oIz1/LEbpGpOZf9GBl/lXv0X2M7zvrWRWmwpCdFWkVFN5dt3xE7GTRFrQNdTntaFx3o6DLemx8ToiigupxHxwvbGROXVL84uwhzXaLmGfacDbYU8wwePKaMa0+A25H0rwa9UmNOw4lP4TFrN46zGOapvx+Fk4IVEiflJSP7AqRAEkPMT2/DT6NuxNtwknuRGc+RkTcd7kS8RrFEleFzkw7vWY18b03XT5owIxb8LW6Ip0LSrit3I7aq1/hFagsHD+xlgtbc1I2VjYEpUoOVONHZaZha82IJuwdawtXfPGvDahbPcTnDSWLQAlnLygyyhOej3mtSG912t+2oSt8dVE/hHPk415XXUPNX8RtiAL7FZ1YKzIEz8UL0fxqWfzJmzFFGaCXk/Yqi8LWyNKdVJA8WFgoXHz7YnES3c/21vXZdCYNWy0S0cU9X+G3DTSY4WT+NwOBxt77N0C8Y9JIjEhjHBvIVhtrLF29MQ9JJ64xGhiAl7wwk78Zvec50HCXom4zc0QAjXAlZdONlg/dcLh+UueuQXgGxhH0p+tFxlkR3vjZ2+IkYEBd59YYGpti721Gdbir93LIKEX0khOjCTa3Qq7+zrcvHYdnXumGNr54RORJhuACekxwpaIesjWCit7V1wCxH+nfM5QNRGe0MsY7etA+2qVqNxfnk1WCXh/+gM+i+9YvMaSEaiF8vxO1M4rnBVoMe84p31y/7YxFn+S7EOs7hx2DPiFIj/8KgzNZIZuMuGpEBPvGdyUANKeqXLj1iUO3gvFOextxZkb+YIoM1VuPXyCtls6ke/WEFnBxDproLJkItOnbWbbnQBc/vF+l/9PRMFMEoLF7BY3VI6jfEyRo4qHOXJwO7s2L2fxvEXMW6HAwcuy7fZSPtLFEUeI9QXOzB3EqPHrWKThhWPkJ1WR+aQRH+CNv7MrAeFxeWLnc+7OSY8l2sMeJ0N97t0WxuOqMse3LGbR+KksU9ThmqjAYgt7YIovMUJEHZ43ifHT93LEOLiQ7Rn/i6SQEXKXy4u70aGIHD/JVabZ0rOo+ELMpyZEhj9J1pvZPboqv8m2ki4xmtE7n+TtV/5BG5vzHI+765jRrKJ4ZzHK1JuJvK7r293eOZGk+lzn2o5RDKpXjJJ5rV2yowhypetSr8sYhi0+yAEhSJ2EP1tQcPPE67588dpiySeI13cRedL1PIeHNaSaXFVKt93Drg9tf5nwGBeNYQz9Q9gvuXqU6ngExSeRZGV6Ev54Ccu6lRE2tQxylRaw5OzTvBbggqNYxFqmNVYXZjKwUgnxrNLU6rKeY1bBQvK/QVYgMc/OobKsN12qytLudfz8zM+VmvBH7ymMX3eak4/9cf/kpjkh3h0PcWNlWxq1W8SQ7ba4F+j9fQpfIl7jRJG8ytHJHfJXG2hIr41aXP/YUlnWGuiMKE8X2fCA6h2ov9OUq+KerCBzHNe2Z7xsArAQr8WnnWObeXrh6/yGXMVGsRWd81cbKNPnAip56yWlkRV2g1PTXtWPRUQa91irjrZIlALzQz6J9le4NaYK3WVhq9KGOlsM0RL3ZIba8Ey+C5NLvhKvv0w6jbxJGoX6z+L9Dsfb0TNPvLagZHeRvoZh/0yXfR6yvBCGxxNNFKavZJ/iDUyEcv7Uho5/H1lk/KsbrER8h14R4rUjHaoJGybEq7ylEK9/UxvL9ytes32It9nC1tE1KSZXVHjznRiy4TqPheF7rxHmG5Md4cTzQ4NYKCuUP5ZErvlmposa1K8gwym8mYwAc1zdHDEPTCfircBlE+ekh/HehRxSucR5z2wi3rKVuWT53sTy5FTGjlrGhG2PsQzL+MC4s/8iuWSneBBkpYryjg0sX32Io1r3ue8gvMNnxphe38+eSW3pXKsWNTsuYK6yFTbR2YUU8BC8HymwbXB7OvdewuzzHjh8jnjNjcDtthY6exW4af6cFwW0nhVGVoIfnvfVuLx/E1vWLmHl7F70b1qGMqVq02yBMkoeuRQenFxyEp7jeHwWm8cNYdh2fc4+TfuMMUkfI/dVj0VGOhnp6aT/LUcGmVnCmxff+Rkx/4rcQOKdDrNzZAMhDkWZL9qLMXsMMBPC85MrxOin+F0YwaK2ouwWqYBcix0suuhX+Pjb+IfYnxvOgLpC7MpVp3yHHRx54vf2mNc84ol1uMrNraOZ2qUmdSvI0rY4JX79iZ+KFOWHYhUp31vkYw03Xia830uTG2oh7EofxtetQKWmC1h/88Ube7x/ArnuBBttYHGnChQt0ooq469z1iahwHjO9dbCdEcjOlUT8VC0PRXHXkfdSRinaGOeH+3KaNnyRkXrU6TXKXYbRBQyY1h422Ha3N3blZZlfhZ2uAmNhp9E61nU+yIhM5RQ4zOorRzAiNZVqFGuNKVL/kbxX34U4RXxU6oeNUceYucdf4JFpv54PR0j0nIe+/rWpdnEYyy9E/8JGzp8iC8RrymkBulz4c91XuvSdZ0GV0ILF4ixlmpcGVI2byMAuTrdaX3MDl1Zc2S4LR578td5FeK12AQVNhunFt41H3gZy4NN6VhL3PNDFyqOvIGmnax3L4ucqFfrvLYW7/lJrjadVqmhFSyT3B8m3laLayMq0UUWtpqdaH7YCh3xMa/XeZ2bt85rOX4ac5L1T5ILH9oRfA3bIy3pXlcWtg6UHXKFC5af7Jl8A2Q5P5GYIG+emjzjuVvoq272vHMS3x4RsyGXeLKnPe2qVaLKwM1stUnE94vLZOF8v+I1zp4g7XEs6FpMVChlkCs/l5lHrPH8JKP3NeQKb/sxBgvaMUQ2SezXspQYp8z6x8ILLagg52SSkyo89NQkEoUR+mucoixFvXmmr8LemevZf/oBVom5pL4V+AjctbdyeFQXhi85yU6zuE9vYfpPkEqEpRYG22ewavMRtum4YO8bRVRKBhkZCSSECgF5cz37xtSgZoWqVOglz/Ib/rz44BYyySQEOmNrcIvb+haYesQT/ckDekTEZ/thcXw7B8bP5PB1C8xFvfbpwlE4IqnhBDkYYnb3Pvr6ejzRWIL8MCFofqtMrSlHUXiZU8DEmndJJe35KS5vGk33/utZcsoGT5Gvvt6hkSnxeOKDX+JqbY65bPckY+NveBhhZGSCkYktDm6BBCVlfX4LTJoLEY8WsrT376LMl0Wu0mKWnHHEX8TZpxaLrAATHLZ0YKJMIBSvTvFxF9hmWNgi/Tnkuqlyb11dWlb4QZT3btSecoMrTgkFp31mNPFetjw1voXuxWMc3zKXhaPa0bqSbHiReGexRrSZqYz6y4S8dSvfIsIaj+MDmVK/HBUbzWL1dZd3JjV9hHgjXqgPZXjjn5Cr3JcWO2zR9S3IGmaSaKzApTG/0uRXEabqQ2m1y4H7sl4hr5uYLKlDn9/F72VbU3GxPmccC+hReo3IM5k2e1CbVYaqshbDMiPpuMoQQ/+0gh271FCi3CyweXSN62cPorBuKjMGNKVRKXGvLH5KdqTfBm30QgobxiFDFL4Ue+6sGcaEBs0YuOM254I+pzy+y5eIV+EoR5pzZ1VfBvwg28WqBm1WnOdCgKxf8ENkEWFyhvN9S78SvI2HMEjdFUNZAY59RpjqMBbLdtgqXpEiw0+w/n5CwfXKa7zUMdpen7YyJ6RkP+otMOTmc9nDRIrF23B37QAGFZHt/lWVVkvPoupXWM9kNlEW57k4sPyrjQ3q96PfOSceyqIg/gWRaqNZ2UqI19/K8cNgRVYZxL3T2PIOPpcw292YTrLdv0r0ouacB1x1/vQRlN+GbLIyM0kVFWtW1qdaCYkvQ8Rv0EUe7WhFqypVqTZ0B3sdk/NXSfj2fLfiNcvnIU93tGFMTVEwfqxFkQ4KrLsaXOjWd9+GRKKcNFAc3IiGooD/WLw2f8hfy9vP+vOGT6aR63+J2yc3MWXpJU4ZBLzdUpErjGn8fbTlpzCixUgWn3yCSeq3ECnfC7LIDMZJdSXrW9el4+BVLLvmg9e7ti/DjueaExlVV1TYxbvQeNE9brqlFlxxfhUiPFleGB1cy9ZBY9iuZcQTob4+R7zmZKeTEhdLnPBiUjKF1Q9WQ29jK5pVrkPDaUocdf8U8SouyH3O0yvyzGnTi9ELjnPBP4uor/5gEZ4ER1zvHefwmoXMnzaNWbPmMGvOHOZ8i2PWTGbOmM2MWWvYdEIXXc8kwj/Xy0y0IfjmGGZ3ESKySG2KtD7M5uuBhbZyvUuuzyNMFzVjuHA8fyjfgJrrdDnpVljLbSKRdzZztHtRqgiBUqzhbIad9sQmIj/w2cnEBwonys4WW2d//GLfTIgEEn2FkH2gxvnN45nSsizlf/yRyp0Xsd44DLd30zrWkSCNUcxpXo4KdSew+JLjqz3vP5Fsz0uYyDeiSwUhPFpNZqy2r3CI80++RTjuGqtZX1eOcnLFKNltGYseReEuskD2Uy3ujKuU16X9Q+3utD5klTec5YOkB+KvNosNzWTi7SdKdNrE3OtheApHXEZOehzRPs4429pj9zyUkDebcDOjiPEwxVJXmZMrBjGsYQlKypWi7qidHHiWSmGvJSdcFEdl9oztTct6E1ih9ZRnIkk+Wnw+yJeIVxGMBDcc949iblk5ShYtL8TjaY55FtaDIirzR4oodCpNPbkfKNNyBosNfHGRnUrzJuXBPDb3+5kffqmIXLfDwhmPIuKDRkbYFOcz6C+rSotyoh6sPYpOB114/HqmXKoHzofGsqC8HKWKlKXO3BMcEQ5y+AfDlkKw4QmOdStLA1G3lW46mfm6njjJTmX4k/Z4MTsGF+PHYuWQ67SPRdoRbyxN9z45z89zf5UQ9CI/ytUcRtu9T7n3d83ekfgXINLWWwWDDU1oWqEW9cYc5JRHhmzWz9/Cdyte4+0vozO++qsZm6WbUG7mNRQs0v6B8TSe+D3ZxqJ2VflFNmGkTFdGn3jCQ6E8Czdz75Dogbf6MhRWz2XGGTtueL6jPtKFsbDexM7pQ2jebTd7b3kW0E35BrmZZKWnkJKSRpps1YL8n2WTfbLSkklJTiIxOY3UjI9s3/gn2WSnp+ZNLklOSiJZPDc181O20xOIsGSmpYp3inuTRZhSM8j47Alz4k25ntieXcSsWmUoV7oLvVdc42FY+jtpHEyA4U6WtaqYN+ascj8VzlpFvnON+OYMES+yiSAZXzpxT9yV5Y3x4fVsHzKOnZeMMfws8fqKXNkafHn/EjcHqKKztgVNKgnxOv1TxauMdMJNT6M6rClDRi1jpm4ELl/dGydqoSgjrC+tZ8X4QfTr1p0+ffvRt18/+n2Lo29vevfsQ89eo5m6WRUVpzj8PtcTS7Il5NY4ZneSideG/NzvHPvuf8qyN7L0TyE9I4N494cYL2meJ16LVm5Fq32P0QopxClMeYrJ/tGMLSXHb0Wr0WTqCU64phEqKwjCwcwINcXw9CpWT5nG+CXnOGsU9I4DLcpRhihHnlcw3N2BzpVLUa7DItY8EeL1XYcjxY24e7NY3q0SFWoOZcpZK2zENZ9WXrOIN1FEc0RZmvxUjCp9RT61isL7vfwkYiveCL1tQ+jxUxGKFGlJp0Xq3Ax5tZh4hr0meuMq00mI1yINB9H33DPuf7AZMYvMsMfcWt6VXkXk+OWXFnReq83lgJxXu5jlxBPvoY/uwQUsnDCHqRuucd0x+u1hXTL7lJ5IivMJtJc35o8yFak+dAf7nFIKb7GJf0r4zcnM6tebun2Oc8okRCY/v4KCxKvVR8Ur6aGEX1vCHpEny/9SkjITFNjikEnIBzNUGO66W1nT5HfKypWjdp+dKNlFvargcyPJfXmEk7NqUf7nssg12sSsc/4EfTCDZ5JsehitsaVoKPLzj50WMk03FKfXDkt2BBE6yznQpQgVfynO72MPIG+bQdAHwxaBl/4uNrYQ9lauDDV6bOGIVRihslO5MeR6KKEyvy6Vi5VGrv46pp7xwf+DkS4cdMtjXJ1YJq91v2i7OUzUCcT+czxNie8MURs6HeHawno0LNeEVtOVuSbsyt+V5N+peI3H//ExdrcT3qSs9bNmZ9ocMOOyvyhj+Vf8bSQZ4aI1liGNZePfSlG89kzWaTvhLl786e8OEeL7NEpThzJpwlr2mYbw4p2ButmRT/E9NZT5g/rRZNotLlgXPHYtj5wUsoOtcb6njtbFq2jec8UlUjamLpP0ECec72ty7aIKx09f5cpDF9zicz7SgptJWsgznB9d54ZsrdozQihp3ELbyAu3qI9VpVEk+VlibnAdbXV1NDWucOnaAx47BuAn9NGn6xXZ10YKR+EUynNHMnLYcpYoGmMX9e66c2EEmB1gZZtqQrw2oFx3ZU6bh791TXZCAD5metxVP4fGtYfcc4ki8LNrOhEeIV5NFDawY9gEdl02wegLxOtfiAT3PYP26ub88dniVbz3pS6W69sytO94Om6y59HnrSZdACJlUvwJeWHMEz0drl25wrVr177hoY32VW2uauuib+qMU/gX7LCV6Sb09XKW9yiVN3v614EXOfg44aN5KifSDe/7Wtw1teeBjTHG27sztZqoUKu0o/1hI3SEV1hgUHKiSHdSQGFUVSrJFefXVouZr+7Ky9fpnuxK6KNVbBheharFK/JT3SWsuOBU8PJWaU/wvtCfvg2aUKffLk44xhL2blpn+ZFms4EtQ2pStVoPBis84Z4QIp9WZoRQvbqerU1+pbJcNZpPUOKST/L7Xe+ZYaRY7WDv0PKUFgLlty4bWaPjR3C+kM52u47x8vp0l3XjNx7KEM3nGH5ohkuGH5GP17Oma0mKy1WmQq+dbDEQeUhEZl58xlrgdnUas7qWpdyvtSjddit7DXxEqS6AmMtY7O9I65ptaTHltLDlhQ8bSPPQw2JNCwb3HEoreWsMvD6r6aAAhEEIvYTejnY0yROvE+i0yhqbkI+U8JxkURaVubyoLvVL/kaRbpuYY5CA7zv2/BWyBH+B/cV5jKtWErlfutFm4R3u+8tme8sQ/59kwr2d/elVsjg/lpvOyP0OvPzgJLQkIeA3otD+J6rKVaLW2MOccEsl4k+nKJVM9zNcW1afRiV/4YfO65ipF4dXgbZP9g53nC4tYXJNEbafO9Fi7i30vYWDlndexEOKOY/2DaG/iJ8fS09iyC5bnue3sL9PChF3tqHUuRg15MpTfcR+jrokEfquwybxH0I46cY7ODeuJnUqdqPbsqs8ic39hMaFL+M7Fa8veX5tOZNqleA3uR8p3XwC8+744Zh/9m8l4DKm2xrTQbZ4949NqdjnFKrWcZ/YOiKMVIwPPsbHUF/fn45txtB7vrYwXilvt0YIQ5Li+YAni9owuvtAOu+045bXh0q9yDCR7jjfVkNbYR27t6xi9pI9bFO8iu6Th9w30EH7wilUju1jj/xa5LcpcEjbDgv/BFlb2ztkkB75Ek/zG9y6eIrjR49yVFEchw9yaN8edu48itIVU4xlleJ7OTKdnLRAAuwNuK+hjIryaU6eOsXpU8c4fXQfB09d4sxdT16Ep36GgM0hPcwVb3N97j20w9gtjriMd4xllhNu12Yzro6ocIp1puEcA3ReJOaZ4rxWncgX+FjfRue8CMv2xWxevZT5u7RRMwsh+pNbtWSIJ35T8SpqkK8Qr4Sb4Ht+CBN6DaTxqEtoOcR8RVi+F6JI8VBDeUpDahWtyM+t97H+VnghLW5JJAU4YKOtJNJ+CwevmnPH5QUvdJeyuVsxSv7egHqrdDlboNpMIvmFNnflu9C3XilKNB3NwP0mojJ/Y6JV9APc1XozpGUpfizbkUbDjqFsFFDA0KUMUp6e5MaqjnTuPIlB8g8wE+L9fbkVSba3MsemNKdRlVZ03KyLWnBeW+lHELk42wXz4zMZV/pHfpGrSJOxR7jgnfHOrPc0Mr10ebi+A/1q/iK+aQxDj5nzULzjz3IQaYmH2igmNyzCj5U70/6gNboFq01irE+iuaApbWqUpVSHeUxVfYZFXjNdPkGamB1qRevaZfilUl86zVJH20mkYf7pv0gg3mgbZ2a3oVW3RUw9YoVsRcEP6xxZ9/ZxjnSvQ68Bc5mhH1XIGr2fgRDQ93a2pnHp34RtH0/n1XY4frRHQ4QyzR6HC1OZ1KgUxWqOpvseRywLjDNxbbQOuvJdaVGyMr+1XMf8KwF4vSUAI/HV3cSuLpWo+EtbWs3URDdI1gxRADkvsD08hqmVilGuqnDw95tin5DzxrUiVdOe4qQxk6l/lOSX6iPostMes7eWgXiNCEPsbQy296LN7xX5tekqZmn58TL+zbBF46+/nf09qlC5WCuaTlHjunAyCnQbcj1wODaRWVWLUb7yEIbuMsQ6LrvgayX+I8QTobOSQz2rUq32RIbuNOWZcLw+vY79PL4P8ZqbQ45sFnTemq0JZPhroburOy1LynbuKEallnPY8kAIo4xMsmQzmXO+tGv4XcRTcsXz8taLlU0SiiJYeJMnB/5MHdlwhWJdqTb+Oho2MaT/uabsu4fsvnQyUiKJfPkEUw15NgyrR/MqFSnReQPTLvjh/d5skTSiHTU5N7QRvbqMZNAFbx6/N7tDhrgv8zleNjdR3KvJRbWL3L0uPP++7WlaoyV9p61mmbI+120D8fL3JNBUgTNrx9Bv0DqWnTTHJflN8SWqyGgbbNXl2TZ1FBPn7WCzpjUmL4MICQ4WAlIDnfVDmDRmDmP3mXHf850qKMObKMezHFu/jgVLlblo7I57RASRIU8JfLKDXcsXMXzWRTTMgt6fhVwY2Rlky4ZDpGbkDVt4O6ZEZeChjv6GFrSu+Bs/t5nPFC1fnsbKiou4MjUYf70T6CgfR+mmCYZ6e1Bb1ZV27SYzYfcD7MUnfJbgy/XDTFGeXcMnsueqGSZChX95wRQv/xrxmvyU6LszmdOnC/W77ERRiKa/fYm4/3eyyUlwwf7YeGY1qkj52lOYeNgU5xRRucvKvMxOyLbQzVvjOZnkYGus1Tazf+USlu6/iYZtHLGpwmkLvsGVZR3oWLk6lQceZI1eGGGy4TSyZ+TIbE0KWUGPMTo6haktq1OryTAG7jTgxkshaN9UVHHGeOtMY8rAvrQYtINtV5/hHJ1KumxoiAhL3na+2cJZi3PA/MRCVvXtysBFJ9lrGkf4u05YHsKFjX8k8kRvelavyx/zLrDXScjoj2YyUZBj7nB960BayRa4l/uN6gPWseFxMC9SZN8lOzLJjrXG4eJCFrStSs36fem9RdgGN/FNbz4/O4wEFyGgxzekcYXG1J5ykUNmceK7xTNk3yX7pswYUj10uLF5EEMbivjpMIOJxy0wDsrIW7/2T8J0sFIZzYAeQ+gwXpGjD7zwSkgnMz9+8tIqK5H0EGPu7pjAvN59GLrxKqefphYyf0CcyHmK7cXljKnflj6TDqDqm/3p5eZPZOkjyyf5djo9igznI1xcWptqvxYVcdiHljNuYOAemzfcJO+aD9YtacQ+Pc/luc1pXa0ZdYcc5bh5KK+HRb9C3JXqT7jBCnYMrEX1an3otf4Wt0Oy345/Ea7MgDuY7B/MgFrVqdlpMSvv+PJMCNy33psTTqqbCsentqB5pcY0m3GWI9bJr4ZrvEU68U7qXF3QgnbVm1JnkAJHTYLfGW8ubkoLIvL+WvYOrU2Naj3ovuo6N4KySHznuqyge1geHsbgOtWo0W4eS2954fhe2CJJdz/P6VltaFmxAU2mnOKgZSJ5Zlniv0tWMC9PTmNNcyFe28sz+5zP39rS/h2I13TSo12wvXGG01tWsWHlPBZNaEu3ejIjnX/80pAOExcxb8NO9hy7xHWHILyFFnuvHH8umREke+nxUH0v21cvY+k8IXo616GJbHHpvHeXQ67OOIbN3si2bdvyjq1bt7I17+8WtsivY/3KpSyZP5e5MycxaVgXujculb8GZDXqzNXklHt2AZVTNEHmx9nRpT7tOk9mkm5owRMvZGNLvS5hemkHyxXuc8ncFjejTSxsW56SP9el+fyT7Hvkw8vX96be5ckh4X3XaE3ricdQds/K72LKIEsIV+szC1k6uCudBi1l3tFHPPJ4o9sx0R4/9bHM6NKMml03slHXA583mlDTvfWwPjScUX2n0Xe1EaK+y0eobvO17JwxmvYjVVB+ElxIS9nnIDO4LjidmsT8VqWp0mQQvXfqczswgzhZfOaGk+T3gEu7d7NztzDEzgEEW+1DfUpNqpfrSc8VNzEXAfn0VmAZUTgq7+DgmOkc1nN8Z/vPz+UrxWuWO4mW61jRry2Nms1j2x03ZNtm/+fJTSHpxS3u7ZrItG6d6D50IYtP3OLqQyusbS2xeHwbg+sXuaB6BuXjShw7fAil8zpctQnF4888GYqvoRIn5vWnT/sB9Jqym31XHnPP0g47Uz0MNBU4tmEaM0YOYeCoZSxUuIe+EK5vNULJSA8k1vUKF7evYNGstWw+eQ3NhxaYW9tjb2eG5ZOb3Lh4glO7V7Js5lxmLxbPveeOiyiPBdt0kXGzPbA+PIE5japSe9B+Ft9OKHwtTRmyTVPcDnF8Tj0q/VqMn5sK53XcamasP8nJq/e4Z2KMkYE66vvmsWBkX3r2n8WUHbfQEQF5f5H5bBHFnrjdFA7n+B506TCSwQuPcULXjCfW1tgaXeeW6m4OrJjA+CFCxEzcyDpVc0z9M95vIRbPCbRS5fiaJSyYv5ld5/W49sQKS1sRPzbGmD24zlXVIyhtXcrCqfOZv06FcxZBeBbY5Z5PbgYEnOHG1v780XAKIzbcx+lLekCSXhJqdxGtEzvYsGolKxfPYuGIZnSo/tq2/0qRil3pNW4ui5avYJX8PrYcvYOuVRBRBaVHgjchD/dwYFw7OjbpRq8FJzjyUIj1PGEn4jTyKa6397F3bFu6NOtK9/nCFlqFFDyPQTgQcc8uor6sJ/1btqHVqB2s07TFXhjr1Dy754ePyWk0lveiX6s2NB+xg013vHH70Hpmib6EPt7PoQnt6dSkKz3nKXH4viceIkMLF4LcKCee6x/i4Pj2dGvWiS6zT3HCLOj91TBkCNGc4KqJ1sreDGzVipYjtrL6osgXYZmv7Hp6AH5mZ7m0qi8DW7em2dDNrL/lgetntVhIfH8Ii5bqxONNgxhbpxb1xquwxTDlG9X1BfMdiFcRASHm3Fday5qRPRnUoyPt2grx1bIVrdu0pY042nUQBa7vIHoNmMDkxfs4+siDZyLWvtrRE5VTvOMZNHZNZWzvLnRu1YxWLVrSopV4f5s24t2daN+pH/0GDmfk6NGMFseoUaMYlfd3BCOH9mdgj850aiXuadaMZs2b07xFC1q0FL8NWMUOHSechS1+vyILFJXrfpa1aUDLzrOYfz8Cx4IMek46aQ6aWOsocsLwJWbedrhcncHkJlWo0momc24F4Pim0cixxkZ1MkNqlqdyj5XMN0zHQ2b109wJNNjAuk5VqVevP70PWHHn3VmhOf5k2MvnjcerUrU7g44YcfeNrrpk67PoTqtNhybdaTLjAir3nXFx98PP8ykeBkdQPaLAdhVrTDyTvj5dBDnJbvjd38HWEcK4N+lP/3XXUHdK/Gs9yhwfYtx1UT6ly6nr3viFe+J7aTZr2lSiUsM5TD5qj4eI+9d6JDczmaQQL3yf2fHU3g5bO1HB2r952IkKVxeV5dOZ17UvC/aocMbSHut3r5HNOrd9ir2TEPeh8XmOScHf+5XiNdeP5Kd72DCwDU0ajmP1NSdcPvXe755Ukjzv8/jYYlbMnMb4xXvZdvQ8ahpqqJ1W5PjBbWzZuJmNu86ictcVp6jc97srM4UzY3me82unMmfyLOZtO85hVSHwTu/j4IY5zJ44jWkrj6Go745rIZuC5KaFE2KixS2FjWzfLpzcIyqoXFBHQ+00KseE47R2GUtmLWTZ9gucNQ3F70MC40/iCbm5DsVBtanXehGjDj3j3U6O90jxJk5/Lpt6/UzJ8lWpMW8X805ocnjjFg7tPsShUyc4cWANq2ZMYuKMTcirWWMamFW44Et+icc9RY4umsCMaYtZvFeF4+cvcPHEdnatmM70iSKO5C+gahKEbyHhy4r3xefuGbT2b2DLzoPsPqrKuYsins+fRPnIDrasWMTiOctZdVCHyw4fWXpJRlY0cboLUBjflLqDDrFIM+gjS2p9gDg7fB9uZ+/ycQzq2YMendrRTtjpli1ltr0tbdu0oo3sv9t0oEPX7vQcMpURi1Q4pe/JB+dwpXrhrruLQ3MGM3jkAqZuEyLviS02T62wuXOCs5unMW7gGIYLYXvSNATfwsaDZIQSbaXChTXjGN1POArLj3H8jrCf9rY8Nb3CpX2LWDJkAMOmbGXLtZc4xXzEqqZ643F7LwpzRdhGzGfKVg3UH4mwOdpga3CKc9umM2HgaIbNO4qSUSDehTkQmRHE2p5DY/0ExvYfz7glihy7bYmxsH+OZtpcObiEpUMHMHzSZuSvuuIQ+Tc2v0n8S4gnJ/QaZ2Z2pkPt9vTecRct/4K0zbfjOxCv2WSnxRDh85znthZYW5hhamaBuaUodK9Fg50NNjY2WFnZ4/DME+/IpLz9oL+6Ls9JJTPej0B3B+wszTAzNsbEzBILG3vsXosVW5lYEUeeaHnnsLHCSoRXdp+xkThMxL8txG9C3Dx18SUoNvUD49l88Hq8i7ktGtC88zyWP4nCtSCDmZtFRvALwryf4x6dRLTPTcz2d6N7jQY0GLKHE89T35gcIYxb0gNMjw2gZ7Xf+K3LMqY9SsNdVoO5aXBvWXM6lipPze7r2GER/f5+xJm+pFmtZvPAMpSu2Ir2u+5zRTz89WWZLld5vKwRvWqVoFilJjRoN4QBE5ezbOcZTl15zCN78U0RIl3e6lf8UoIIMDrGiend6NNjLMM330bbMZbYN2vj7GhSoz156haKR1isEKYP0V3ZlZ5V61Bz1Gl2PIp7a23P7DgvXl7Zy/F5Qxk/QoR98HCGjxjBiNfHyOGMGNaHzo1qU79seeq36kSnYSMZ9uY1I4aJawYzcPB4Rk7diYKOPW5pH2oV+krxKhycVJfDwploQ9P6I1h8SeTRbxG13ws5yaSEeeDpbIm50SMe3NFD3+AhD83ssHvmiuuLl7zwDCQwNqOAsd0yRESnRxHlI5wsqycYP7qLvp4eurcNMHhgjKGlI07uIYQkytrNCic3KZK4wOd4OFtgaXSPe7dvclPnJjq3H3DvsSWWds944RNO2Cc51DlkuZ3j/uautG88mO7zr/IoLPMD3/CK7EgH3BQGMLOGHCUqtaPnQX2u+Ubg7WrHsyd3uHPrJrdu38VAFpZnQkxGZbwzxr4gsslJCiXM3R4n80c8eWDAndu30dW7x93HpphYu+DqHfnOpisFIZ4TH0qUn4iDp6aYPRbxq3uDGzduceOOSDdDa6yfvuClbCvKjwlXQU7Scyw3D2JB+yZ03HCbo8+yPiFOCyAzjpQIIdBd7ESdYoGFmfgmU1GvWIn8Y++Ag72oX6zMMTMT9Y25ORbWT7F19sM3/NXWvgWTQ3ZCIEFOj3h0VTgxR/ZxYPdOdu7YyY7dB9h/7DyqN8wwcQsnXMTbR8OdFkmUhwVWumqonxBOyN5d7NopnrVzD3sPKXNSU+Q1+4C8rcI/HnWysAUR7PyYx9rCqVMUYdvzZtjOcVbHBMPnYYSmfDzPy8pOtJcQ5XoX0TxxOD9sO/LDdooTGiK/2Yr4ihV1VP4tEv9hMrxJtNrM+iHtaNx8Biu1XXAu1Dv+er7TCVv/dXzzxWtDmneZzwrDD4hXWYdUZiY5eVYwh0zbI2jPqkfDyt1oN/cKD8PfXAhe5KTAi9zZ1JTmFYpTvJ88K23S8M9KJEZ3DbvalqRssfa0nX+NBxGZ74tqUWlE3ZrCsrY/UaJiR3oeNkQv/g0DnOpLxIMdHJnZnk61ilOyqGzXsxIUr96B1qM3sPGSLVbR2X+1jH4p6b54PFTixJJxTBo1m9l7ddFxTfur9SVbVGZ5Y/zE3+zXkwkCiLfdzaZeNaleuQs995lx650+sZykQPwfqHJ51xJWL1vEvIVLWLJ0KUvzjuWsWL2UZYunMapTS9pVr027fqMYuXgti5ctZ+Wy19ctZuniBSxYuIblm1RQf+yGnwhAwb2+30K8Kgjx2jZPvC65/BT7r/bWvlNkSzKF+OHvH0Jo/JdUliLiEoVQ8/fB218Isi/OpOlkJQjB6+uJp4dw1oJiiSlMdX6IZFteXl/ClObCSRwgz+GnCQQUIphSfR5wd0Ebev/8I6VrjWeuphMv88+SGEaYn4ib0ETemhf0WWSSFSuEj68v3oHimwprMSyUFNJihEPh7YGHpz8+oQkkfNa4nQTSA6+hNKYrvRsOYLbmU4z+rd3R8d74293j/nUttDQuo3XTiEeOIg6/JD9khRL+3AQT3ctc1dRC44o+dy09eBkrcw2+gAQfAuzv80DnEpc0LqF5w5CHDiJdPu7RvE92OJFuQpDfvoy2pqYI2x0MzF/iFpP7mUOyJL5ncsJN8Tg1mPFde9B49FnO20VT0EjHb4kkXv+VBOFjeIBlbRrSsuscFj6KxPGjRi+BEJ01HOxRlZoNpjF4lw0ub43eTybTcicq4ytQtXQtak8/zbmATGKz/XA+OZUpVWUzgqcxZI8Dz98epf+KUFMc93ZjZJVf+b3+ZOZdeoazrHVbNqEtNYHkhBhiwl7i+kgTrT2LWD55IP3a/UHDKuUpX6IkNQauYv7tkK+YFZxLTloAITYanFs9g3lTV7P+oi1GIfmnhWSJDwnG2zWAyJiUtw1nuBHPlQczokF1KrdZzDoDX15mpYtwJ5KWIQSuLJrEd+SkJZAUG05YWAjBwUKEhMiOUHEIAx0TQligFbe2L2Vd/+GsP3WLG/7xBIRFECWuf3WtOIKDCQmNIDxKiIXUrEIql68Ur7m+JDvuZcOgdjRpNIG1Os645p/6n+WLxdlrCpqM8wXkTUj6mmfFEu2syenx7ejffRzjz7/A8O3ZP2+QSJTjeZQG16OOXEUqtN3C3vu+BY+l/Fq+6pveIC9+8v/9OaS7EGm4mtk9e9G00xaUzIIocOL8v4U/J/tmkZmVk7cl8pcjHPKs/EnLeRPH8n/+UvLCJnveNwrb6wnV3yJsEt8ZGcTaXuDKtNb07zOD4UddMQ/5Irfqs5DE67+SVxO2tnetT/uuQljqhWH9MTcmxxvbo1OY07AK1btuYY6WEFFvtpBkBeKtOo0VzUrwe9XhDNptinN6Dlm5bpgdGMPwCuUp8cdappwNIPA9oZxOnONFLoyuS5PfG1BzxGlOWb3auzw3JRBfoyvcunyNSyZCCPtGERPghruzNdbGulw9OJe5TUtSp+kwuiu68jj41RM/nwC8TdVQlV/FuvVHOHrbhaeihv6rlc0DyzsGnFZ4jPWziDd+zyTO9ixXp9anedX2NJ5+hatuQmiHOONndh8n31D8M8V35F9dOIFYHtvMnpGT2XfNEvP8X7+MVPBT4dqb4tUjt+A1MAsi050Eyw2s6C++qfk8tuv/j0zY+p8gl6xYZzzOTWbZyIG0m3mZ0+ZRH2hR9sHv0WaWtKlIMbmWVB+hhZpd7Je1yP3LyfXXw/lQd/p3G0nz2Xe565nyn/xOCYnvB1FzZj3D6fJ65nfsydBZRznpkkbY3zxkQIYkXv+VpBH1VBPVIQ3o3XkUg9V8eVKoqhEqNdGQm+t70bVSVcoPPcm6J1lvjJOLJ+OlOiqTW9KuQiOajFdGwSRC1vYnCMBZeRoLGpWnTLPVjD8T/P7i6VGmWChNZnSDetRqvYBZF17ikLdMQRxJXjqorRjFmKHzmHXaFdN3mnxy3S+jNqwJ/TqPY8wFT0zf7a5PCCTM/i4Pr17i6h1LbAIT35mAIQKT7o+vySmUV01m0ph5LNivzRU7H9y8PPB0c8Xl6RMcnhxl+8Z9TF2sh4FtVH7Lq+xDAnl+ZTXLm1WiphB549V8eBEbit/DK2jvO46ejRfe4uJPEq85Ppge2cjOYRPZLVvvVhTQr6o8oy5yR74lTavUo/Gcs5wJkaX8J5LsSPS92czp3YUGnXZwzNC/kP3UJb47cuLJ9dHk0sbxDOoyi0UnzLBMkLVxvUOGCc5nBzOgRjHkSg6hubwThn/Xfoz/r2QSY3wcjVG16DZwAcMvhOAc90mlVkJC4m8jmaSnR1FfPZRuA9ax+Ix93iTwf2LIiCRe/5XINim4j+HCVozuNoCOu+y46VWYoY4SukqFU7MaU7NkVUoPOsRa/XCCkkTGSkwgwfshtmemMa1LW5r3WsXaG244/blrSwpRj/dzbkoLWrSezsCNT7AIiCdBtiVsYhzxUR546G5FYVpnOnaeyridBjwKzeHV7QFE2iuyaXBrmjQaxvD9Juh5peeti5iRLtuO1R+Px2dQGD+S+Yv2cdwxAZ93PLIMz3uYbhIeW41yVGo9k1larm+0MmeTleqF35MjHBzXnu4N6tO83ziGzlnB0lWrWb1qBSuXL2XxrNHMGNGWNoMX0X+rNQ89Xjc5y6p6ZyxPz2R0rcrU7ifP0vueOLsbcU/lDHu2avPQOfT9JZAKRFz0tZsU5A2xSCIlLpqYaH8i7fZxek5tapaqTNWRu9huEY5bZDTRcUkkpGSRWVj3W4QJvucGM77XABqPvsQlhxipFeq/Rm4IL2/s5vD4PoxZfJQdhjH5vSK55GQkkSjyUIjRAc7Pq0Gj0nLIVR9M221GXHeKIiY+mRRZd3Deg753RNnL9eGp2hoW/dGQPtP3ssc1m3+gZ1JCQuKDZJEdbY/54emsHj2C0bvvcvFZ+j9mcyTx+i8lJ8IO35MDmTewD42n3+KcdSGDRdN9SDZdzdZh1fn9lxrU7jqVeQcucEb7BjpXzqK6Zxkrp0xg0qK97NRxxiH6zRnYuWSJd724tokN44YyePgilh/R5MK169zUUEL5wHrWLpzD/KXb2HbekMfusW8MxI4j0esW6itGMqZbP4YsVWS35n3uPbzHvVtaaJ3cw/6tm1i75Qxn9F14mZTz3izn9OfXuT+7Gi3z1lZsTo0Vd1F/+Vq1ReNvdIKTY+rQIm/xdXEUL0uJ8hUoX7okv5csSckSJSj+sxw/yc61nkKPU96Y/dl0LPvrg/Ol1SxpWY3mvScxdLcqCgr7UVJSR1nfm5dRqZ9Y2L5evOamRhJmdo17J7ayd9NykSbt6Vkn/7sqt6PlhOUsXL+drUoiTg2D8c9bsLZgMtx1sd7QjmH9xtNxsy0P3/UKJP4TpIWa4ai+imXjZzFlvTa3vIVoFeUu+pkOl0S5XjakDb2blKZimd8oUbUhNbuOY/CUjWw/o88D/+T/yMYVwlpF66CzYwwdag5i9AYdDIUh+eReCgkJiW9P/AtC7u9g+6ypjJ53nNMWYfh/yaS/L0QSr/9WUv1IsRKV0JSBNOmyg503PT44HjI35ikB54Yzp111ylQdwOg56zl2ToUTquc5d0aBQ7t2smnnBS4aeeNboFLLJDPiKXaX9nF08xrW7VHikPIZzh7bzcHtG1i/S5UT+u64FzDuNjslCH/jy+ie3IuC4nGOnFHnopYQrupnOXNI/Hb0HBeMfXj2gT7trBB7XNVWs3tKJ7r1G02LxbooGb8eyxaF78MznJ49gMn9BzJg0EAG9u9P/3596dv3jaNff/qJ8yM2nmKvRRzeb80WTybS6Tb6exaxce1aFu08wcFDKlx7ZI9DXN60qU8kX7weXs/2oePZeckEw88Urzkp4YQaaqJ3eC1bVi1k3nThUIwaxNAhgxk0agJjps1j/rJ1rD2ozdkHgfh8cO3GdMJNVVAd2owhI5cyWzcCl/j8UxL/MZJICzNB/+AaNsxdx7YLjzH2fM4L28uoblnI/AmTmDZ7EfMXL2HJwlnMmTaFiZOXsU44QPq+SX/PxK1/mowwkh8vYd/E1lRut5lFZ198+thwCQmJb0tuBrnx3vgZKnNxyyxmr1Ji2w0ffBMK6yr89kji9d9KbhJEG3Bl4ySGthzObMUHPEwoWCxl+j3EYm07BtZqRPXeCijoC48oJoxg35d4enrh5htKYFg88Wk5eW2RBSMEbGIkMcGe+Lg/w+mZK8+ee+EbEERweCzRydnvj7eTIesKT0skOTqYMF83Xjg54ODoiqu3ELXBYURExhCb+uZ+22+Tm5VGenwI0e5XuK+jyBJFI1QN4/Inp2SRnhBFVIA3/r5++PmLw1cUEh8ffN46fPER5/3DY4iSveutj8wlOz2epHAvPF1dcHTywMs/XHyPeG/+FZ/GK/FqfEgIiMHj2HHJ+LPFKzmyOI4mLjyIkMAA/P38Xx0B4vD3x0/8OyAwiKAw8R0JGaQXOHBIhCPXFQcteea3783Yhcc575P9zlaUEv8pckX58nnIQ9V97NxwBOVbVjhGxRAcLPKQr8g7QaGEhIURFirKaoCsjAQSFBFHvGxCZv4jvmdyk3wJPDOebaO70HrJTY6YpRRixyQkJP5WsuLI9NDG4LQ8y9cqcfj6M9ySZHu1/bNI4vVfi8gKuRF4XlnP/mFt6DP/JJuMEol7r+U0h0SXS6iPrk+r6t1oudSIO375p/iA4PwoQmRlZJL+2YNXRAZOTSQpKZW0z61dYh/gbXSMAzccuPos9e+rdD/7m95AJl4PrGX7gNF54tVIKOx/vrM+nRy3U1zfMpJu/dez8KQd7v8v4ZD4Z4kj1tsaC/27GNoJp/K/oEo/kdw04cA+OcddtVMoG/lhW+C+pRISEv8EudmJZPgZ4/DkNtceueH81rJG/xySeP2Xk+2hg4XieMaMWMyYrU8wDcn6a9xoThoZCW44aq9hYdNSlK3al/bbrdDzyvx+1trLTSc7yR+v28e5fuIAp808sYrJP/dvIzuM5zpqXN2+D20TV1yFEP4aLfz5CMWS+BwX5TlsmTSc4dsNOGf/zpq2Ev9hZA5tKumZGaSIRP9eivhXk5tDdnJs3lrS8RnZpEvNrhIS/2/k5mSRlZJEeurf2Mj0CUji9d9ORhhRDhc5MW8c06duZNcDfxzzxp6KqivFhxD786iu6UXHCj/xY83edNymzwWbaMLf3Pv030xWMEleulxRVGT3vhs8fBlVQOvyv4RcIRqiwonyDyBKNptb1oOff+ofIcufWKdzHFs0k2lTdqFk5I/nPzhAXuLfg2yRf0nDSUhI/H/wRZuMfGMk8fodkJMiRIreQU6unMXcNSc4+tCdl0I8JYdZ4Hx7P3uXjWf0wD70Gj2D6bsvcNTAHafgzHfGfv47yRXfFv/iFno3DNC6709AnNQB/j5CzWcF4W97mat7lrF46QG2azjyPC7jf6f1TUJCQkJCIh9JvH4XCPGS/hIXXSUUV65lu+pjDHxjiQqy44XpTa5ducoV7Wtcu6rF1eu30THzwCkkg4zvQNnkpMSSEuJOSHgYIWnS2M0Ckc3uTLDHTucY+9bsReGSBTZxstGvEhISEhIS/3tI4vW7IYv0KDc8re7zwNQFC88E4hJiSIwJJyw8mujYOOKiI4gSIjAsOom41BxyvoeW1+wsstPTyM4tbCWE/3Gy08mOdMXnqTFGls9xCU36jCW+JCQkJCQk/ltI4vW7I5X4uETCIr+PllWJb4BM4CdEk5qcIIlWCQkJCYn/eSTx+p2SKwnX/y3+DSPkJSQkJCQk/gVI4lVCQkJCQkJCQuK7QRKvEhISEhISEhIS3w2SeJWQkJCQkJCQkPhukMSrhISEhISEhITEd4MkXiUkJCQkJCQkJL4bJPEqISEhISEhISHx3SCJVwkJCQkJCQkJie8GSbxKSEhISEhISEh8N0jiVUJCQkJCQkJC4rtBEq8SEhISEhISEhLfDZJ4lZCQkJCQkJCQ+G6QxKuEhISEhISEhMR3gyReJSQkJCQkJCQkvhsk8SohISEhISEhIfHdIIlXCQkJCQkJCQmJ7wZJvEpISEhISEhISHw3SOJVQkJCQkJCQkLiu0ESrxISEhISEhISEt8NkniVkJCQkJCQkJD4ToD/A9M7zHuy8bI5AAAAAElFTkSuQmCC)"
      ],
      "metadata": {
        "id": "FrCd0mStIKAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    Positional Encoding proposed in \"Attention Is All You Need\".\n",
        "    Since transformer contains no recurrence and no convolution, in order for the model to make\n",
        "    use of the order of the sequence, we must add some positional information.\n",
        "\n",
        "    \"Attention Is All You Need\" use sine and cosine functions of different frequencies:\n",
        "        PE_(pos, 2i)    =  sin(pos / power(10000, 2i / d_model))\n",
        "        PE_(pos, 2i+1)  =  cos(pos / power(10000, 2i / d_model))\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model: int = 512, max_len: int = 10000) -> None:\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, d_model, requires_grad=False)               # 임베딩해야할 거 크기 구현 - zero padding\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)   # 0부터 max_len끼지를 요소로 하는 텐서 구현 후 1차원 추가 (< 왜?, 결과는 같음)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)                         # 0::2 -> 0부터 시작해서 두 칸씩 뛰어라\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, length: int) -> Tensor:\n",
        "        return self.pe[:, :length]"
      ],
      "metadata": {
        "id": "lgEUIZ519Ax6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding TEST"
      ],
      "metadata": {
        "id": "0LZJcJ6LFyp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enc = PositionalEncoding()\n"
      ],
      "metadata": {
        "id": "G7SOoAKpF0WI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "position = torch.arange(0, 10000, dtype=torch.float)\n",
        "position[1::2]\n",
        "position[0::2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozzNsy3rHBSK",
        "outputId": "ee620dd0-64c9-46de-f25e-74a5b6f0e4a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000e+00, 2.0000e+00, 4.0000e+00,  ..., 9.9940e+03, 9.9960e+03,\n",
              "        9.9980e+03])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "position = torch.arange(0, 10000, dtype=torch.float).unsqueeze(1) \n",
        "position"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1gffnehHPzq",
        "outputId": "66a2a7a3-3cf6-4e94-88ae-cb80de20a625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000e+00],\n",
              "        [1.0000e+00],\n",
              "        [2.0000e+00],\n",
              "        ...,\n",
              "        [9.9970e+03],\n",
              "        [9.9980e+03],\n",
              "        [9.9990e+03]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Refs\n",
        "[torch.arange](https://pytorch.org/docs/stable/generated/torch.arange.html)\n",
        "[]\n"
      ],
      "metadata": {
        "id": "u5gWcI9cGufh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modules"
      ],
      "metadata": {
        "id": "XihAX92z9Pq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright (c) 2021, Soohwan Kim. All rights reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "from torch import Tensor\n",
        "\n",
        "\n",
        "class ResidualConnectionModule(nn.Module):\n",
        "    \"\"\"\n",
        "    Residual Connection Module.\n",
        "    outputs = (module(inputs) x module_factor + inputs x input_factor)\n",
        "    \"\"\"\n",
        "    def __init__(self, module: nn.Module, module_factor: float = 1.0, input_factor: float = 1.0):\n",
        "        super(ResidualConnectionModule, self).__init__()\n",
        "        self.module = module\n",
        "        self.module_factor = module_factor\n",
        "        self.input_factor = input_factor\n",
        "\n",
        "    def forward(self, inputs: Tensor) -> Tensor:\n",
        "        return (self.module(inputs) * self.module_factor) + (inputs * self.input_factor)\n",
        "\n",
        "\n",
        "class Linear(nn.Module): #!!! 논문에는 안나와 있음\n",
        "    \"\"\"\n",
        "    Wrapper class of torch.nn.Linear\n",
        "    Weight initialize by xavier initialization and bias initialize to zeros. -> 이거 하려고 새로 생성한 linear class . nn.Linear는 초기화 방법이 정해져있음.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_features: int, out_features: int, bias: bool = True) -> None:\n",
        "        super(Linear, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=bias)  # https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
        "        init.xavier_uniform_(self.linear.weight) # 노드가 n개일 때, 표준편차가 (n)^-1/2인 정규분포로 초기화\n",
        "        if bias:\n",
        "            init.zeros_(self.linear.bias)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return self.linear(x)\n",
        "\n",
        "\n",
        "class View(nn.Module):\n",
        "  # 모듈로서 사용하기 위함. 초기화 하고 forward때 사용.\n",
        "  # contiguous : 메모리 상에서 연속이도록.\n",
        "    \"\"\" Wrapper class of torch.view() for Sequential module. \"\"\"\n",
        "    def __init__(self, shape: tuple, contiguous: bool = False):\n",
        "        super(View, self).__init__()\n",
        "        self.shape = shape\n",
        "        self.contiguous = contiguous\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        if self.contiguous:\n",
        "            x = x.contiguous()\n",
        "\n",
        "        return x.view(*self.shape)\n",
        "\n",
        "\n",
        "class Transpose(nn.Module):\n",
        "  # 모듈로서 사용하기 위함. 초기화 하고 forward때 사용.\n",
        "    \"\"\" Wrapper class of torch.transpose() for Sequential module. \"\"\"\n",
        "    def __init__(self, shape: tuple):\n",
        "        super(Transpose, self).__init__()\n",
        "        self.shape = shape\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return x.transpose(*self.shape)\n"
      ],
      "metadata": {
        "id": "JrrcpJgt9RS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feed_forward"
      ],
      "metadata": {
        "id": "FxTGwqW59HhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "\n",
        "\"\"\"\n",
        "from .activation import Swish\n",
        "from .modules import Linear\n",
        "\"\"\"\n",
        "\n",
        "class FeedForwardModule(nn.Module):\n",
        "    # 블록 그대로\n",
        "    \"\"\"\n",
        "    Conformer Feed Forward Module follow pre-norm residual units and apply layer normalization within the residual unit\n",
        "    and on the input before the first linear layer. This module also apply Swish activation and dropout, which helps\n",
        "    regularizing the network.\n",
        "\n",
        "    Args:\n",
        "        encoder_dim (int): Dimension of conformer encoder\n",
        "        expansion_factor (int): Expansion factor of feed forward module.\n",
        "        dropout_p (float): Ratio of dropout\n",
        "\n",
        "    Inputs: inputs\n",
        "        - **inputs** (batch, time, dim): Tensor contains input sequences\n",
        "\n",
        "    Outputs: outputs\n",
        "        - **outputs** (batch, time, dim): Tensor produces by feed forward module.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            encoder_dim: int = 512,\n",
        "            expansion_factor: int = 4,\n",
        "            dropout_p: float = 0.1,\n",
        "    ) -> None:\n",
        "        super(FeedForwardModule, self).__init__()\n",
        "        self.sequential = nn.Sequential(\n",
        "            nn.LayerNorm(encoder_dim),\n",
        "            Linear(encoder_dim, encoder_dim * expansion_factor, bias=True),\n",
        "            Swish(),\n",
        "            nn.Dropout(p=dropout_p),\n",
        "            Linear(encoder_dim * expansion_factor, encoder_dim, bias=True),\n",
        "            nn.Dropout(p=dropout_p),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs: Tensor) -> Tensor:\n",
        "        return self.sequential(inputs)\n"
      ],
      "metadata": {
        "id": "hN0kyLt29Lwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Convolution ?"
      ],
      "metadata": {
        "id": "LFoiL8Ib83qa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "from typing import Tuple\n",
        "\"\"\"\n",
        "from .activation import Swish, GLU\n",
        "from .modules import Transpose\n",
        "\"\"\"\n",
        "\n",
        "class DepthwiseConv1d(nn.Module):\n",
        "    \"\"\"\n",
        "    When groups == in_channels and out_channels == K * in_channels, where K is a positive integer,\n",
        "    this operation is termed in literature as depthwise convolution.\n",
        "\n",
        "    Args:\n",
        "        in_channels (int): Number of channels in the input\n",
        "        out_channels (int): Number of channels produced by the convolution\n",
        "        kernel_size (int or tuple): Size of the convolving kernel\n",
        "        stride (int, optional): Stride of the convolution. Default: 1\n",
        "        padding (int or tuple, optional): Zero-padding added to both sides of the input. Default: 0\n",
        "        bias (bool, optional): If True, adds a learnable bias to the output. Default: True\n",
        "\n",
        "    Inputs: inputs\n",
        "        - **inputs** (batch, in_channels, time): Tensor containing input vector\n",
        "\n",
        "    Returns: outputs\n",
        "        - **outputs** (batch, out_channels, time): Tensor produces by depthwise 1-D convolution.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            in_channels: int,\n",
        "            out_channels: int,\n",
        "            kernel_size: int,\n",
        "            stride: int = 1,\n",
        "            padding: int = 0,\n",
        "            bias: bool = False,\n",
        "    ) -> None:\n",
        "        super(DepthwiseConv1d, self).__init__()\n",
        "        assert out_channels % in_channels == 0, \"out_channels should be constant multiple of in_channels\"\n",
        "        self.conv = nn.Conv1d(\n",
        "            in_channels=in_channels,\n",
        "            out_channels=out_channels,\n",
        "            kernel_size=kernel_size,\n",
        "            groups=in_channels,\n",
        "            stride=stride,\n",
        "            padding=padding,\n",
        "            bias=bias,\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs: Tensor) -> Tensor:\n",
        "        return self.conv(inputs)\n",
        "\n",
        "\n",
        "class PointwiseConv1d(nn.Module):\n",
        "    \"\"\"\n",
        "    When kernel size == 1 conv1d, this operation is termed in literature as pointwise convolution.\n",
        "    This operation often used to match dimensions.\n",
        "\n",
        "    Args:\n",
        "        in_channels (int): Number of channels in the input\n",
        "        out_channels (int): Number of channels produced by the convolution\n",
        "        stride (int, optional): Stride of the convolution. Default: 1\n",
        "        padding (int or tuple, optional): Zero-padding added to both sides of the input. Default: 0\n",
        "        bias (bool, optional): If True, adds a learnable bias to the output. Default: True\n",
        "\n",
        "    Inputs: inputs\n",
        "        - **inputs** (batch, in_channels, time): Tensor containing input vector\n",
        "\n",
        "    Returns: outputs\n",
        "        - **outputs** (batch, out_channels, time): Tensor produces by pointwise 1-D convolution.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            in_channels: int,\n",
        "            out_channels: int,\n",
        "            stride: int = 1,\n",
        "            padding: int = 0,\n",
        "            bias: bool = True,\n",
        "    ) -> None:\n",
        "        super(PointwiseConv1d, self).__init__()\n",
        "        self.conv = nn.Conv1d(\n",
        "            in_channels=in_channels,\n",
        "            out_channels=out_channels,\n",
        "            kernel_size=1,\n",
        "            stride=stride,\n",
        "            padding=padding,\n",
        "            bias=bias,\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs: Tensor) -> Tensor:\n",
        "        return self.conv(inputs)\n",
        "\n",
        "\n",
        "class ConformerConvModule(nn.Module):\n",
        "    \"\"\"\n",
        "    Conformer convolution module starts with a pointwise convolution and a gated linear unit (GLU).\n",
        "    This is followed by a single 1-D depthwise convolution layer. Batchnorm is  deployed just after the convolution\n",
        "    to aid training deep models.\n",
        "\n",
        "    Args:\n",
        "        in_channels (int): Number of channels in the input\n",
        "        kernel_size (int or tuple, optional): Size of the convolving kernel Default: 31\n",
        "        dropout_p (float, optional): probability of dropout\n",
        "\n",
        "    Inputs: inputs\n",
        "        inputs (batch, time, dim): Tensor contains input sequences\n",
        "\n",
        "    Outputs: outputs\n",
        "        outputs (batch, time, dim): Tensor produces by conformer convolution module.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            in_channels: int,\n",
        "            kernel_size: int = 31,\n",
        "            expansion_factor: int = 2,\n",
        "            dropout_p: float = 0.1,\n",
        "    ) -> None:\n",
        "        super(ConformerConvModule, self).__init__()\n",
        "        assert (kernel_size - 1) % 2 == 0, \"kernel_size should be a odd number for 'SAME' padding\"\n",
        "        assert expansion_factor == 2, \"Currently, Only Supports expansion_factor 2\"\n",
        "\n",
        "        self.sequential = nn.Sequential(\n",
        "            nn.LayerNorm(in_channels),\n",
        "            Transpose(shape=(1, 2)),\n",
        "            PointwiseConv1d(in_channels, in_channels * expansion_factor, stride=1, padding=0, bias=True),\n",
        "            GLU(dim=1),\n",
        "            DepthwiseConv1d(in_channels, in_channels, kernel_size, stride=1, padding=(kernel_size - 1) // 2),\n",
        "            nn.BatchNorm1d(in_channels),\n",
        "            Swish(),\n",
        "            PointwiseConv1d(in_channels, in_channels, stride=1, padding=0, bias=True),\n",
        "            nn.Dropout(p=dropout_p),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs: Tensor) -> Tensor:\n",
        "        return self.sequential(inputs).transpose(1, 2)\n",
        "\n",
        "\n",
        "class Conv2dSubampling(nn.Module):\n",
        "    \"\"\"\n",
        "    Convolutional 2D subsampling (to 1/4 length)\n",
        "\n",
        "    Args:\n",
        "        in_channels (int): Number of channels in the input image\n",
        "        out_channels (int): Number of channels produced by the convolution\n",
        "\n",
        "    Inputs: inputs\n",
        "        - **inputs** (batch, time, dim): Tensor containing sequence of inputs\n",
        "\n",
        "    Returns: outputs, output_lengths\n",
        "        - **outputs** (batch, time, dim): Tensor produced by the convolution\n",
        "        - **output_lengths** (batch): list of sequence output lengths\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels: int, out_channels: int) -> None:\n",
        "        super(Conv2dSubampling, self).__init__()\n",
        "        self.sequential = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=2),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs: Tensor, input_lengths: Tensor) -> Tuple[Tensor, Tensor]:\n",
        "        outputs = self.sequential(inputs.unsqueeze(1))\n",
        "        batch_size, channels, subsampled_lengths, sumsampled_dim = outputs.size()\n",
        "\n",
        "        outputs = outputs.permute(0, 2, 1, 3)\n",
        "        outputs = outputs.contiguous().view(batch_size, subsampled_lengths, channels * sumsampled_dim)\n",
        "\n",
        "        output_lengths = input_lengths >> 2 # 비트 쉬프트 연산, 2의 2승 만큼 나눠짐\n",
        "        output_lengths -= 1\n",
        "\n",
        "        return outputs, output_lengths\n"
      ],
      "metadata": {
        "id": "JL6WMB3h867Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attention*\n"
      ],
      "metadata": {
        "id": "eYE19mJH8xfj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "from typing import Optional\n",
        "\n",
        "\"\"\"\n",
        "from .embedding import PositionalEncoding\n",
        "from .modules import Linear\n",
        "\"\"\"\n",
        "\n",
        "class RelativeMultiHeadAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-head attention with relative positional encoding.\n",
        "    This concept was proposed in the \"Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context\"\n",
        "\n",
        "    Args:\n",
        "        d_model (int): The dimension of model\n",
        "        num_heads (int): The number of attention heads.\n",
        "        dropout_p (float): probability of dropout\n",
        "\n",
        "    Inputs: query, key, value, pos_embedding, mask\n",
        "        - **query** (batch, time, dim): Tensor containing query vector\n",
        "        - **key** (batch, time, dim): Tensor containing key vector\n",
        "        - **value** (batch, time, dim): Tensor containing value vector\n",
        "        - **pos_embedding** (batch, time, dim): Positional embedding tensor\n",
        "        - **mask** (batch, 1, time2) or (batch, time1, time2): Tensor containing indices to be masked\n",
        "\n",
        "    Returns:\n",
        "        - **outputs**: Tensor produces by relative multi head attention module.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            d_model: int = 512,\n",
        "            num_heads: int = 16,\n",
        "            dropout_p: float = 0.1,\n",
        "    ):\n",
        "        super(RelativeMultiHeadAttention, self).__init__()\n",
        "        assert d_model % num_heads == 0, \"d_model % num_heads should be zero.\"\n",
        "        self.d_model = d_model\n",
        "        self.d_head = int(d_model / num_heads)\n",
        "        self.num_heads = num_heads\n",
        "        self.sqrt_dim = math.sqrt(d_model)\n",
        "\n",
        "        self.query_proj = Linear(d_model, d_model)\n",
        "        self.key_proj = Linear(d_model, d_model)\n",
        "        self.value_proj = Linear(d_model, d_model)\n",
        "        self.pos_proj = Linear(d_model, d_model, bias=False)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=dropout_p)\n",
        "        self.u_bias = nn.Parameter(torch.Tensor(self.num_heads, self.d_head))\n",
        "        self.v_bias = nn.Parameter(torch.Tensor(self.num_heads, self.d_head))\n",
        "        torch.nn.init.xavier_uniform_(self.u_bias)\n",
        "        torch.nn.init.xavier_uniform_(self.v_bias)\n",
        "\n",
        "        self.out_proj = Linear(d_model, d_model)\n",
        "\n",
        "    def forward(\n",
        "            self,\n",
        "            query: Tensor,\n",
        "            key: Tensor,\n",
        "            value: Tensor,\n",
        "            pos_embedding: Tensor,\n",
        "            mask: Optional[Tensor] = None,\n",
        "    ) -> Tensor:\n",
        "        batch_size = value.size(0)\n",
        "\n",
        "        # n heads 한번에 계산\n",
        "        query = self.query_proj(query).view(batch_size, -1, self.num_heads, self.d_head)\n",
        "        key = self.key_proj(key).view(batch_size, -1, self.num_heads, self.d_head).permute(0, 2, 1, 3)\n",
        "        value = self.value_proj(value).view(batch_size, -1, self.num_heads, self.d_head).permute(0, 2, 1, 3)\n",
        "        ## embedding에서 들어오는것 linear를 한번 거침: Transformer-XL\n",
        "        pos_embedding = self.pos_proj(pos_embedding).view(batch_size, -1, self.num_heads, self.d_head)\n",
        "\n",
        "        ## 상대위치 기반 셀프 어텐션 식: Transformer-XL\n",
        "        ### a,c 항\n",
        "        content_score = torch.matmul((query + self.u_bias).transpose(1, 2), key.transpose(2, 3))\n",
        "        ### b,d 항\n",
        "        pos_score = torch.matmul((query + self.v_bias).transpose(1, 2), pos_embedding.permute(0, 2, 3, 1)) \n",
        "        pos_score = self._relative_shift(pos_score) # 왼쪽으로 미뤄주는 것\n",
        "\n",
        "        ## scale : Transformer-XL\n",
        "        score = (content_score + pos_score) / self.sqrt_dim # 텐서 더하기는 요소별 더하기 : 형태는 유지\n",
        "\n",
        "        ## Masking 옵션\n",
        "        if mask is not None:\n",
        "            mask = mask.unsqueeze(1)\n",
        "            score.masked_fill_(mask, -1e9)\n",
        "\n",
        "        ## Softmax\n",
        "        attn = F.softmax(score, -1)\n",
        "        ## Dropout ------------------------------->? \n",
        "        attn = self.dropout(attn)\n",
        "        ## value랑 matmul\n",
        "        context = torch.matmul(attn, value).transpose(1, 2)\n",
        "        context = context.contiguous().view(batch_size, -1, self.d_model)\n",
        "\n",
        "        # concat 후 linear\n",
        "        return self.out_proj(context)\n",
        "\n",
        "    def _relative_shift(self, pos_score: Tensor) -> Tensor:\n",
        "      \n",
        "        batch_size, num_heads, seq_length1, seq_length2 = pos_score.size()\n",
        "        print(\" batch_size {} num_heads {} seq_length1 {} seq_length2 {}\".format( batch_size, num_heads, seq_length1, seq_length2))\n",
        "        zeros = pos_score.new_zeros(batch_size, num_heads, seq_length1, 1) # pos_score의 devidce, type따라가는 zero\n",
        "        padded_pos_score = torch.cat([zeros, pos_score], dim=-1) \n",
        "\n",
        "        padded_pos_score = padded_pos_score.view(batch_size, num_heads, seq_length2 + 1, seq_length1)\n",
        "        pos_score = padded_pos_score[:, :, 1:].view_as(pos_score)\n",
        "\n",
        "\n",
        "        return pos_score\n",
        "\n",
        "\n",
        "class MultiHeadedSelfAttentionModule(nn.Module):\n",
        "    \"\"\"\n",
        "    Conformer employ multi-headed self-attention (MHSA) while integrating an important technique from Transformer-XL,\n",
        "    the relative sinusoidal positional encoding scheme. The relative positional encoding allows the self-attention\n",
        "    module to generalize better on different input length and the resulting encoder is more robust to the variance of\n",
        "    the utterance length. Conformer use prenorm residual units with dropout which helps training\n",
        "    and regularizing deeper models.\n",
        "\n",
        "    Args:\n",
        "        d_model (int): The dimension of model\n",
        "        num_heads (int): The number of attention heads.\n",
        "        dropout_p (float): probability of dropout\n",
        "\n",
        "    Inputs: inputs, mask\n",
        "        - **inputs** (batch, time, dim): Tensor containing input vector\n",
        "        - **mask** (batch, 1, time2) or (batch, time1, time2): Tensor containing indices to be masked\n",
        "\n",
        "    Returns:\n",
        "        - **outputs** (batch, time, dim): Tensor produces by relative multi headed self attention module.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model: int, num_heads: int, dropout_p: float = 0.1):\n",
        "        super(MultiHeadedSelfAttentionModule, self).__init__()\n",
        "        self.positional_encoding = PositionalEncoding(d_model)\n",
        "        self.layer_norm = nn.LayerNorm(d_model)\n",
        "        self.attention = RelativeMultiHeadAttention(d_model, num_heads, dropout_p)\n",
        "        self.dropout = nn.Dropout(p=dropout_p)\n",
        "\n",
        "    def forward(self, inputs: Tensor, mask: Optional[Tensor] = None):\n",
        "        batch_size, seq_length, _ = inputs.size()\n",
        "        pos_embedding = self.positional_encoding(seq_length)\n",
        "        pos_embedding = pos_embedding.repeat(batch_size, 1, 1)\n",
        "\n",
        "        inputs = self.layer_norm(inputs)\n",
        "        outputs = self.attention(inputs, inputs, inputs, pos_embedding=pos_embedding, mask=mask)\n",
        "\n",
        "        return self.dropout(outputs)\n"
      ],
      "metadata": {
        "id": "eAS0s60Q8tti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Encoder\n",
        "구조를 이루는 class"
      ],
      "metadata": {
        "id": "o8imEIO49CrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright (c) 2021, Soohwan Kim. All rights reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "from typing import Tuple\n",
        "\"\"\"\n",
        "from .feed_forward import FeedForwardModule\n",
        "from .attention import MultiHeadedSelfAttentionModule\n",
        "from .convolution import (\n",
        "    ConformerConvModule,\n",
        "    Conv2dSubampling,\n",
        ")\n",
        "from .modules import (\n",
        "    ResidualConnectionModule,\n",
        "    Linear,\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "class ConformerBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Conformer block contains two Feed Forward modules sandwiching the Multi-Headed Self-Attention module\n",
        "    and the Convolution module. This sandwich structure is inspired by Macaron-Net, which proposes replacing\n",
        "    the original feed-forward layer in the Transformer block into two half-step feed-forward layers,\n",
        "    one before the attention layer and one after.\n",
        "\n",
        "    Args:\n",
        "        encoder_dim (int, optional): Dimension of conformer encoder\n",
        "        num_attention_heads (int, optional): Number of attention heads\n",
        "        feed_forward_expansion_factor (int, optional): Expansion factor of feed forward module\n",
        "        conv_expansion_factor (int, optional): Expansion factor of conformer convolution module\n",
        "        feed_forward_dropout_p (float, optional): Probability of feed forward module dropout\n",
        "        attention_dropout_p (float, optional): Probability of attention module dropout\n",
        "        conv_dropout_p (float, optional): Probability of conformer convolution module dropout\n",
        "        conv_kernel_size (int or tuple, optional): Size of the convolving kernel\n",
        "        half_step_residual (bool): Flag indication whether to use half step residual or not\n",
        "\n",
        "    Inputs: inputs\n",
        "        - **inputs** (batch, time, dim): Tensor containing input vector\n",
        "\n",
        "    Returns: outputs\n",
        "        - **outputs** (batch, time, dim): Tensor produces by conformer block.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            encoder_dim: int = 512,\n",
        "            num_attention_heads: int = 8,\n",
        "            feed_forward_expansion_factor: int = 4,\n",
        "            conv_expansion_factor: int = 2,\n",
        "            feed_forward_dropout_p: float = 0.1,\n",
        "            attention_dropout_p: float = 0.1,\n",
        "            conv_dropout_p: float = 0.1,\n",
        "            conv_kernel_size: int = 31,\n",
        "            half_step_residual: bool = True,\n",
        "    ):\n",
        "        super(ConformerBlock, self).__init__()\n",
        "        if half_step_residual:\n",
        "            self.feed_forward_residual_factor = 0.5 # Macaron인 대신에 0.5\n",
        "        else:\n",
        "            self.feed_forward_residual_factor = 1\n",
        "\n",
        "        self.sequential = nn.Sequential(\n",
        "            ResidualConnectionModule(\n",
        "                module=FeedForwardModule(\n",
        "                    encoder_dim=encoder_dim,\n",
        "                    expansion_factor=feed_forward_expansion_factor,\n",
        "                    dropout_p=feed_forward_dropout_p,\n",
        "                ),\n",
        "                module_factor=self.feed_forward_residual_factor,\n",
        "            ),\n",
        "            ResidualConnectionModule(\n",
        "                module=MultiHeadedSelfAttentionModule(\n",
        "                    d_model=encoder_dim,\n",
        "                    num_heads=num_attention_heads,\n",
        "                    dropout_p=attention_dropout_p,\n",
        "                ),\n",
        "            ),\n",
        "            ResidualConnectionModule(\n",
        "                module=ConformerConvModule(\n",
        "                    in_channels=encoder_dim,\n",
        "                    kernel_size=conv_kernel_size,\n",
        "                    expansion_factor=conv_expansion_factor,\n",
        "                    dropout_p=conv_dropout_p,\n",
        "                ),\n",
        "            ),\n",
        "            ResidualConnectionModule(\n",
        "                module=FeedForwardModule(\n",
        "                    encoder_dim=encoder_dim,\n",
        "                    expansion_factor=feed_forward_expansion_factor,\n",
        "                    dropout_p=feed_forward_dropout_p,\n",
        "                ),\n",
        "                module_factor=self.feed_forward_residual_factor,\n",
        "            ),\n",
        "            nn.LayerNorm(encoder_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs: Tensor) -> Tensor:\n",
        "        return self.sequential(inputs)\n",
        "\n",
        "\n",
        "class ConformerEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Conformer encoder first processes the input with a convolution subsampling layer and then\n",
        "    with a number of conformer blocks.\n",
        "\n",
        "    Args:\n",
        "        input_dim (int, optional): Dimension of input vector\n",
        "        encoder_dim (int, optional): Dimension of conformer encoder\n",
        "        num_layers (int, optional): Number of conformer blocks\n",
        "        num_attention_heads (int, optional): Number of attention heads\n",
        "        feed_forward_expansion_factor (int, optional): Expansion factor of feed forward module\n",
        "        conv_expansion_factor (int, optional): Expansion factor of conformer convolution module\n",
        "        feed_forward_dropout_p (float, optional): Probability of feed forward module dropout\n",
        "        attention_dropout_p (float, optional): Probability of attention module dropout\n",
        "        conv_dropout_p (float, optional): Probability of conformer convolution module dropout\n",
        "        conv_kernel_size (int or tuple, optional): Size of the convolving kernel\n",
        "        half_step_residual (bool): Flag indication whether to use half step residual or not\n",
        "\n",
        "    Inputs: inputs, input_lengths\n",
        "        - **inputs** (batch, time, dim): Tensor containing input vector\n",
        "        - **input_lengths** (batch): list of sequence input lengths\n",
        "\n",
        "    Returns: outputs, output_lengths\n",
        "        - **outputs** (batch, out_channels, time): Tensor produces by conformer encoder.\n",
        "        - **output_lengths** (batch): list of sequence output lengths\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_dim: int = 80,\n",
        "            encoder_dim: int = 512,\n",
        "            num_layers: int = 17,\n",
        "            num_attention_heads: int = 8,\n",
        "            feed_forward_expansion_factor: int = 4,\n",
        "            conv_expansion_factor: int = 2,\n",
        "            input_dropout_p: float = 0.1,\n",
        "            feed_forward_dropout_p: float = 0.1,\n",
        "            attention_dropout_p: float = 0.1,\n",
        "            conv_dropout_p: float = 0.1,\n",
        "            conv_kernel_size: int = 31,\n",
        "            half_step_residual: bool = True,\n",
        "    ):\n",
        "        super(ConformerEncoder, self).__init__()\n",
        "        self.conv_subsample = Conv2dSubampling(in_channels=1, out_channels=encoder_dim)\n",
        "        self.input_projection = nn.Sequential(\n",
        "            Linear(encoder_dim * (((input_dim - 1) // 2 - 1) // 2), encoder_dim),\n",
        "            nn.Dropout(p=input_dropout_p),\n",
        "        )\n",
        "        self.layers = nn.ModuleList([ConformerBlock(\n",
        "            encoder_dim=encoder_dim,\n",
        "            num_attention_heads=num_attention_heads,\n",
        "            feed_forward_expansion_factor=feed_forward_expansion_factor,\n",
        "            conv_expansion_factor=conv_expansion_factor,\n",
        "            feed_forward_dropout_p=feed_forward_dropout_p,\n",
        "            attention_dropout_p=attention_dropout_p,\n",
        "            conv_dropout_p=conv_dropout_p,\n",
        "            conv_kernel_size=conv_kernel_size,\n",
        "            half_step_residual=half_step_residual,\n",
        "        ) for _ in range(num_layers)])\n",
        "\n",
        "    def count_parameters(self) -> int:\n",
        "        \"\"\" Count parameters of encoder \"\"\"\n",
        "        return sum([p.numel for p in self.parameters()])\n",
        "\n",
        "    def update_dropout(self, dropout_p: float) -> None:\n",
        "        \"\"\" Update dropout probability of encoder \"\"\"\n",
        "        for name, child in self.named_children():\n",
        "            if isinstance(child, nn.Dropout):\n",
        "                child.p = dropout_p\n",
        "\n",
        "    def forward(self, inputs: Tensor, input_lengths: Tensor) -> Tuple[Tensor, Tensor]:\n",
        "        \"\"\"\n",
        "        Forward propagate a `inputs` for  encoder training.\n",
        "\n",
        "        Args:\n",
        "            inputs (torch.FloatTensor): A input sequence passed to encoder. Typically for inputs this will be a padded\n",
        "                `FloatTensor` of size ``(batch, seq_length, dimension)``.\n",
        "            input_lengths (torch.LongTensor): The length of input tensor. ``(batch)``\n",
        "\n",
        "        Returns:\n",
        "            (Tensor, Tensor)\n",
        "\n",
        "            * outputs (torch.FloatTensor): A output sequence of encoder. `FloatTensor` of size\n",
        "                ``(batch, seq_length, dimension)``\n",
        "            * output_lengths (torch.LongTensor): The length of output tensor. ``(batch)``\n",
        "        \"\"\"\n",
        "        outputs, output_lengths = self.conv_subsample(inputs, input_lengths)\n",
        "        outputs = self.input_projection(outputs)\n",
        "\n",
        "        for layer in self.layers:\n",
        "            outputs = layer(outputs)\n",
        "\n",
        "        return outputs, output_lengths\n"
      ],
      "metadata": {
        "id": "5QGF2JLh9FvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#model \n",
        "전체 연결"
      ],
      "metadata": {
        "id": "Ud1q-GhE9J6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright (c) 2021, Soohwan Kim. All rights reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "from typing import Tuple\n",
        "\n",
        "\"\"\"\n",
        "from .encoder import ConformerEncoder\n",
        "from .modules import Linear\n",
        "\"\"\"\n",
        "\n",
        "class Conformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Conformer: Convolution-augmented Transformer for Speech Recognition\n",
        "    The paper used a one-lstm Transducer decoder, currently still only implemented\n",
        "    the conformer encoder shown in the paper.\n",
        "\n",
        "    Args:\n",
        "        num_classes (int): Number of classification classes\n",
        "        input_dim (int, optional): Dimension of input vector\n",
        "        encoder_dim (int, optional): Dimension of conformer encoder\n",
        "        num_encoder_layers (int, optional): Number of conformer blocks\n",
        "        num_attention_heads (int, optional): Number of attention heads\n",
        "        feed_forward_expansion_factor (int, optional): Expansion factor of feed forward module\n",
        "        conv_expansion_factor (int, optional): Expansion factor of conformer convolution module\n",
        "        feed_forward_dropout_p (float, optional): Probability of feed forward module dropout\n",
        "        attention_dropout_p (float, optional): Probability of attention module dropout\n",
        "        conv_dropout_p (float, optional): Probability of conformer convolution module dropout\n",
        "        conv_kernel_size (int or tuple, optional): Size of the convolving kernel\n",
        "        half_step_residual (bool): Flag indication whether to use half step residual or not\n",
        "\n",
        "    Inputs: inputs\n",
        "        - **inputs** (batch, time, dim): Tensor containing input vector\n",
        "        - **input_lengths** (batch): list of sequence input lengths\n",
        "\n",
        "    Returns: outputs, output_lengths\n",
        "        - **outputs** (batch, out_channels, time): Tensor produces by conformer.\n",
        "        - **output_lengths** (batch): list of sequence output lengths\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            num_classes: int,\n",
        "            input_dim: int = 80,\n",
        "            encoder_dim: int = 512,\n",
        "            num_encoder_layers: int = 17,\n",
        "            num_attention_heads: int = 8,\n",
        "            feed_forward_expansion_factor: int = 4,\n",
        "            conv_expansion_factor: int = 2,\n",
        "            input_dropout_p: float = 0.1,\n",
        "            feed_forward_dropout_p: float = 0.1,\n",
        "            attention_dropout_p: float = 0.1,\n",
        "            conv_dropout_p: float = 0.1,\n",
        "            conv_kernel_size: int = 31,\n",
        "            half_step_residual: bool = True,\n",
        "    ) -> None:\n",
        "        super(Conformer, self).__init__()\n",
        "        self.encoder = ConformerEncoder(\n",
        "            input_dim=input_dim,\n",
        "            encoder_dim=encoder_dim,\n",
        "            num_layers=num_encoder_layers,\n",
        "            num_attention_heads=num_attention_heads,\n",
        "            feed_forward_expansion_factor=feed_forward_expansion_factor,\n",
        "            conv_expansion_factor=conv_expansion_factor,\n",
        "            input_dropout_p=input_dropout_p,\n",
        "            feed_forward_dropout_p=feed_forward_dropout_p,\n",
        "            attention_dropout_p=attention_dropout_p,\n",
        "            conv_dropout_p=conv_dropout_p,\n",
        "            conv_kernel_size=conv_kernel_size,\n",
        "            half_step_residual=half_step_residual,\n",
        "        )\n",
        "        self.fc = Linear(encoder_dim, num_classes, bias=False)\n",
        "\n",
        "    def count_parameters(self) -> int:\n",
        "        \"\"\" Count parameters of encoder \"\"\"\n",
        "        return self.encoder.count_parameters()\n",
        "\n",
        "    def update_dropout(self, dropout_p) -> None:\n",
        "        \"\"\" Update dropout probability of model \"\"\"\n",
        "        self.encoder.update_dropout(dropout_p)\n",
        "\n",
        "    def forward(self, inputs: Tensor, input_lengths: Tensor) -> Tuple[Tensor, Tensor]:\n",
        "        \"\"\"\n",
        "        Forward propagate a `inputs` and `targets` pair for training.\n",
        "\n",
        "        Args:\n",
        "            inputs (torch.FloatTensor): A input sequence passed to encoder. Typically for inputs this will be a padded\n",
        "                `FloatTensor` of size ``(batch, seq_length, dimension)``.\n",
        "            input_lengths (torch.LongTensor): The length of input tensor. ``(batch)``\n",
        "\n",
        "        Returns:\n",
        "            * predictions (torch.FloatTensor): Result of model predictions.\n",
        "        \"\"\"\n",
        "        encoder_outputs, encoder_output_lengths = self.encoder(inputs, input_lengths)\n",
        "        outputs = self.fc(encoder_outputs)\n",
        "        outputs = nn.functional.log_softmax(outputs, dim=-1)\n",
        "        return outputs, encoder_output_lengths\n"
      ],
      "metadata": {
        "id": "IGfiAXt59N8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TEST"
      ],
      "metadata": {
        "id": "60WexFd__A54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "    Conformer Inputs\n",
        "        - **inputs** (batch, time, dim): Tensor containing input vector\n",
        "        - **input_lengths** (batch): list of sequence input lengths\n",
        "\"\"\"\n",
        "            #encoder_dim: int = 512,\n",
        "            #num_encoder_layers: int = 17,\n",
        "            #num_attention_heads: int = 8,\n",
        "            #feed_forward_expansion_factor: int = 4,\n",
        "            #nv_expansion_factor: int = 2,\n",
        "            #input_dropout_p: float = 0.1,\n",
        "            #feed_forward_dropout_p: float = 0.1,\n",
        "            #attention_dropout_p: float = 0.1,\n",
        "            #conv_dropout_p: float = 0.1,\n",
        "            #conv_kernel_size: int = 31,\n",
        "            #half_step_residual: bool = True,\n",
        "\n",
        "Batch_size = 5\n",
        "input_dim = 80\n",
        "input_length = 10\n",
        "\n",
        "model = Conformer(num_classes = 3, input_dim = input_dim)\n",
        "dum_data = torch.randn(Batch_size, input_length, input_dim) # (2,3) 크기를 같는 랜덤 텐서 생성 :  https://pytorch.org/docs/stable/generated/torch.rand.html\n",
        "input_lengths = torch.tensor([input_length]*Batch_size)  #[10, 10, 10, 10, 10]\n",
        "\n",
        "outputs, output_lengths = model(dum_data, input_lengths)\n",
        "outputs.size() #torch.Size([5, 1, 3])\n",
        " "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6DQ4fAR_DcV",
        "outputId": "1badb415-a400-46ea-a2bf-5bf4e5541ebf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before shift tensor([[[[  2.6747]],\n",
            "\n",
            "         [[  5.1723]],\n",
            "\n",
            "         [[ -0.7950]],\n",
            "\n",
            "         [[ -2.6228]],\n",
            "\n",
            "         [[  1.2504]],\n",
            "\n",
            "         [[ -0.1003]],\n",
            "\n",
            "         [[ -0.0339]],\n",
            "\n",
            "         [[ -8.9552]]],\n",
            "\n",
            "\n",
            "        [[[  8.6664]],\n",
            "\n",
            "         [[ 13.8540]],\n",
            "\n",
            "         [[  8.3596]],\n",
            "\n",
            "         [[ -8.8623]],\n",
            "\n",
            "         [[  2.9194]],\n",
            "\n",
            "         [[ -2.4039]],\n",
            "\n",
            "         [[  2.9085]],\n",
            "\n",
            "         [[ -5.9977]]],\n",
            "\n",
            "\n",
            "        [[[  7.7767]],\n",
            "\n",
            "         [[ 11.7281]],\n",
            "\n",
            "         [[  3.1200]],\n",
            "\n",
            "         [[ -5.8037]],\n",
            "\n",
            "         [[  7.9312]],\n",
            "\n",
            "         [[ -0.0364]],\n",
            "\n",
            "         [[  3.0293]],\n",
            "\n",
            "         [[  0.9338]]],\n",
            "\n",
            "\n",
            "        [[[  5.7425]],\n",
            "\n",
            "         [[  6.5794]],\n",
            "\n",
            "         [[ -1.5250]],\n",
            "\n",
            "         [[ -3.1990]],\n",
            "\n",
            "         [[  2.7679]],\n",
            "\n",
            "         [[ -5.1100]],\n",
            "\n",
            "         [[  2.6525]],\n",
            "\n",
            "         [[  2.0846]]],\n",
            "\n",
            "\n",
            "        [[[  5.6113]],\n",
            "\n",
            "         [[  9.6051]],\n",
            "\n",
            "         [[ -1.5421]],\n",
            "\n",
            "         [[-10.4818]],\n",
            "\n",
            "         [[  1.2267]],\n",
            "\n",
            "         [[ -4.5101]],\n",
            "\n",
            "         [[  0.4637]],\n",
            "\n",
            "         [[  0.7807]]]], grad_fn=<UnsafeViewBackward0>)\n",
            "ssfter shift tensor([[[[  2.6747]],\n",
            "\n",
            "         [[  5.1723]],\n",
            "\n",
            "         [[ -0.7950]],\n",
            "\n",
            "         [[ -2.6228]],\n",
            "\n",
            "         [[  1.2504]],\n",
            "\n",
            "         [[ -0.1003]],\n",
            "\n",
            "         [[ -0.0339]],\n",
            "\n",
            "         [[ -8.9552]]],\n",
            "\n",
            "\n",
            "        [[[  8.6664]],\n",
            "\n",
            "         [[ 13.8540]],\n",
            "\n",
            "         [[  8.3596]],\n",
            "\n",
            "         [[ -8.8623]],\n",
            "\n",
            "         [[  2.9194]],\n",
            "\n",
            "         [[ -2.4039]],\n",
            "\n",
            "         [[  2.9085]],\n",
            "\n",
            "         [[ -5.9977]]],\n",
            "\n",
            "\n",
            "        [[[  7.7767]],\n",
            "\n",
            "         [[ 11.7281]],\n",
            "\n",
            "         [[  3.1200]],\n",
            "\n",
            "         [[ -5.8037]],\n",
            "\n",
            "         [[  7.9312]],\n",
            "\n",
            "         [[ -0.0364]],\n",
            "\n",
            "         [[  3.0293]],\n",
            "\n",
            "         [[  0.9338]]],\n",
            "\n",
            "\n",
            "        [[[  5.7425]],\n",
            "\n",
            "         [[  6.5794]],\n",
            "\n",
            "         [[ -1.5250]],\n",
            "\n",
            "         [[ -3.1990]],\n",
            "\n",
            "         [[  2.7679]],\n",
            "\n",
            "         [[ -5.1100]],\n",
            "\n",
            "         [[  2.6525]],\n",
            "\n",
            "         [[  2.0846]]],\n",
            "\n",
            "\n",
            "        [[[  5.6113]],\n",
            "\n",
            "         [[  9.6051]],\n",
            "\n",
            "         [[ -1.5421]],\n",
            "\n",
            "         [[-10.4818]],\n",
            "\n",
            "         [[  1.2267]],\n",
            "\n",
            "         [[ -4.5101]],\n",
            "\n",
            "         [[  0.4637]],\n",
            "\n",
            "         [[  0.7807]]]], grad_fn=<ViewBackward0>)\n",
            "before shift tensor([[[[  4.4685]],\n",
            "\n",
            "         [[ -1.6518]],\n",
            "\n",
            "         [[  2.7131]],\n",
            "\n",
            "         [[ -7.9108]],\n",
            "\n",
            "         [[  2.4066]],\n",
            "\n",
            "         [[  2.0904]],\n",
            "\n",
            "         [[  4.9762]],\n",
            "\n",
            "         [[ 11.9160]]],\n",
            "\n",
            "\n",
            "        [[[ 10.9135]],\n",
            "\n",
            "         [[ 12.0015]],\n",
            "\n",
            "         [[ -0.6287]],\n",
            "\n",
            "         [[-10.7289]],\n",
            "\n",
            "         [[  2.1797]],\n",
            "\n",
            "         [[  7.6025]],\n",
            "\n",
            "         [[  6.9191]],\n",
            "\n",
            "         [[ -0.6965]]],\n",
            "\n",
            "\n",
            "        [[[  3.9600]],\n",
            "\n",
            "         [[ -0.0211]],\n",
            "\n",
            "         [[ -8.4090]],\n",
            "\n",
            "         [[ -0.7597]],\n",
            "\n",
            "         [[ 12.9477]],\n",
            "\n",
            "         [[ -6.7750]],\n",
            "\n",
            "         [[ -6.3164]],\n",
            "\n",
            "         [[ 10.4939]]],\n",
            "\n",
            "\n",
            "        [[[  1.7673]],\n",
            "\n",
            "         [[  8.1410]],\n",
            "\n",
            "         [[ -3.0538]],\n",
            "\n",
            "         [[ -5.3834]],\n",
            "\n",
            "         [[  8.3114]],\n",
            "\n",
            "         [[  4.1210]],\n",
            "\n",
            "         [[  0.8454]],\n",
            "\n",
            "         [[  2.4197]]],\n",
            "\n",
            "\n",
            "        [[[ -5.0031]],\n",
            "\n",
            "         [[ -0.7387]],\n",
            "\n",
            "         [[  4.0620]],\n",
            "\n",
            "         [[  3.8850]],\n",
            "\n",
            "         [[ 10.6429]],\n",
            "\n",
            "         [[ -0.6037]],\n",
            "\n",
            "         [[ -3.7349]],\n",
            "\n",
            "         [[  3.2682]]]], grad_fn=<UnsafeViewBackward0>)\n",
            "ssfter shift tensor([[[[  4.4685]],\n",
            "\n",
            "         [[ -1.6518]],\n",
            "\n",
            "         [[  2.7131]],\n",
            "\n",
            "         [[ -7.9108]],\n",
            "\n",
            "         [[  2.4066]],\n",
            "\n",
            "         [[  2.0904]],\n",
            "\n",
            "         [[  4.9762]],\n",
            "\n",
            "         [[ 11.9160]]],\n",
            "\n",
            "\n",
            "        [[[ 10.9135]],\n",
            "\n",
            "         [[ 12.0015]],\n",
            "\n",
            "         [[ -0.6287]],\n",
            "\n",
            "         [[-10.7289]],\n",
            "\n",
            "         [[  2.1797]],\n",
            "\n",
            "         [[  7.6025]],\n",
            "\n",
            "         [[  6.9191]],\n",
            "\n",
            "         [[ -0.6965]]],\n",
            "\n",
            "\n",
            "        [[[  3.9600]],\n",
            "\n",
            "         [[ -0.0211]],\n",
            "\n",
            "         [[ -8.4090]],\n",
            "\n",
            "         [[ -0.7597]],\n",
            "\n",
            "         [[ 12.9477]],\n",
            "\n",
            "         [[ -6.7750]],\n",
            "\n",
            "         [[ -6.3164]],\n",
            "\n",
            "         [[ 10.4939]]],\n",
            "\n",
            "\n",
            "        [[[  1.7673]],\n",
            "\n",
            "         [[  8.1410]],\n",
            "\n",
            "         [[ -3.0538]],\n",
            "\n",
            "         [[ -5.3834]],\n",
            "\n",
            "         [[  8.3114]],\n",
            "\n",
            "         [[  4.1210]],\n",
            "\n",
            "         [[  0.8454]],\n",
            "\n",
            "         [[  2.4197]]],\n",
            "\n",
            "\n",
            "        [[[ -5.0031]],\n",
            "\n",
            "         [[ -0.7387]],\n",
            "\n",
            "         [[  4.0620]],\n",
            "\n",
            "         [[  3.8850]],\n",
            "\n",
            "         [[ 10.6429]],\n",
            "\n",
            "         [[ -0.6037]],\n",
            "\n",
            "         [[ -3.7349]],\n",
            "\n",
            "         [[  3.2682]]]], grad_fn=<ViewBackward0>)\n",
            "before shift tensor([[[[ 0.7282]],\n",
            "\n",
            "         [[ 4.4039]],\n",
            "\n",
            "         [[ 4.3522]],\n",
            "\n",
            "         [[ 5.3383]],\n",
            "\n",
            "         [[-2.6072]],\n",
            "\n",
            "         [[-1.8080]],\n",
            "\n",
            "         [[-5.9148]],\n",
            "\n",
            "         [[-1.1547]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3468]],\n",
            "\n",
            "         [[ 2.0457]],\n",
            "\n",
            "         [[ 0.3998]],\n",
            "\n",
            "         [[ 0.6443]],\n",
            "\n",
            "         [[-5.8341]],\n",
            "\n",
            "         [[-5.2826]],\n",
            "\n",
            "         [[ 5.6022]],\n",
            "\n",
            "         [[ 8.1649]]],\n",
            "\n",
            "\n",
            "        [[[11.3426]],\n",
            "\n",
            "         [[ 0.3328]],\n",
            "\n",
            "         [[-8.5087]],\n",
            "\n",
            "         [[-0.8328]],\n",
            "\n",
            "         [[ 2.3219]],\n",
            "\n",
            "         [[-5.1974]],\n",
            "\n",
            "         [[-7.5214]],\n",
            "\n",
            "         [[ 7.3148]]],\n",
            "\n",
            "\n",
            "        [[[15.7774]],\n",
            "\n",
            "         [[ 4.2235]],\n",
            "\n",
            "         [[ 0.3790]],\n",
            "\n",
            "         [[-0.6927]],\n",
            "\n",
            "         [[-3.0532]],\n",
            "\n",
            "         [[19.2390]],\n",
            "\n",
            "         [[ 0.0229]],\n",
            "\n",
            "         [[ 6.2561]]],\n",
            "\n",
            "\n",
            "        [[[-1.1078]],\n",
            "\n",
            "         [[ 5.5729]],\n",
            "\n",
            "         [[ 3.1335]],\n",
            "\n",
            "         [[ 5.9367]],\n",
            "\n",
            "         [[-4.3544]],\n",
            "\n",
            "         [[ 5.8218]],\n",
            "\n",
            "         [[-0.7779]],\n",
            "\n",
            "         [[ 7.8451]]]], grad_fn=<UnsafeViewBackward0>)\n",
            "ssfter shift tensor([[[[ 0.7282]],\n",
            "\n",
            "         [[ 4.4039]],\n",
            "\n",
            "         [[ 4.3522]],\n",
            "\n",
            "         [[ 5.3383]],\n",
            "\n",
            "         [[-2.6072]],\n",
            "\n",
            "         [[-1.8080]],\n",
            "\n",
            "         [[-5.9148]],\n",
            "\n",
            "         [[-1.1547]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3468]],\n",
            "\n",
            "         [[ 2.0457]],\n",
            "\n",
            "         [[ 0.3998]],\n",
            "\n",
            "         [[ 0.6443]],\n",
            "\n",
            "         [[-5.8341]],\n",
            "\n",
            "         [[-5.2826]],\n",
            "\n",
            "         [[ 5.6022]],\n",
            "\n",
            "         [[ 8.1649]]],\n",
            "\n",
            "\n",
            "        [[[11.3426]],\n",
            "\n",
            "         [[ 0.3328]],\n",
            "\n",
            "         [[-8.5087]],\n",
            "\n",
            "         [[-0.8328]],\n",
            "\n",
            "         [[ 2.3219]],\n",
            "\n",
            "         [[-5.1974]],\n",
            "\n",
            "         [[-7.5214]],\n",
            "\n",
            "         [[ 7.3148]]],\n",
            "\n",
            "\n",
            "        [[[15.7774]],\n",
            "\n",
            "         [[ 4.2235]],\n",
            "\n",
            "         [[ 0.3790]],\n",
            "\n",
            "         [[-0.6927]],\n",
            "\n",
            "         [[-3.0532]],\n",
            "\n",
            "         [[19.2390]],\n",
            "\n",
            "         [[ 0.0229]],\n",
            "\n",
            "         [[ 6.2561]]],\n",
            "\n",
            "\n",
            "        [[[-1.1078]],\n",
            "\n",
            "         [[ 5.5729]],\n",
            "\n",
            "         [[ 3.1335]],\n",
            "\n",
            "         [[ 5.9367]],\n",
            "\n",
            "         [[-4.3544]],\n",
            "\n",
            "         [[ 5.8218]],\n",
            "\n",
            "         [[-0.7779]],\n",
            "\n",
            "         [[ 7.8451]]]], grad_fn=<ViewBackward0>)\n",
            "before shift tensor([[[[ -5.1682]],\n",
            "\n",
            "         [[ -0.2218]],\n",
            "\n",
            "         [[  7.8531]],\n",
            "\n",
            "         [[ -1.4963]],\n",
            "\n",
            "         [[  2.3530]],\n",
            "\n",
            "         [[  5.5204]],\n",
            "\n",
            "         [[ -5.1001]],\n",
            "\n",
            "         [[  9.2904]]],\n",
            "\n",
            "\n",
            "        [[[ -2.3394]],\n",
            "\n",
            "         [[  4.6394]],\n",
            "\n",
            "         [[  0.8669]],\n",
            "\n",
            "         [[ -7.3848]],\n",
            "\n",
            "         [[  6.3568]],\n",
            "\n",
            "         [[  3.9067]],\n",
            "\n",
            "         [[ -4.0883]],\n",
            "\n",
            "         [[  7.6461]]],\n",
            "\n",
            "\n",
            "        [[[ -2.3200]],\n",
            "\n",
            "         [[ -9.1733]],\n",
            "\n",
            "         [[  3.7951]],\n",
            "\n",
            "         [[  8.1013]],\n",
            "\n",
            "         [[ -1.5914]],\n",
            "\n",
            "         [[ -1.4755]],\n",
            "\n",
            "         [[  1.3107]],\n",
            "\n",
            "         [[ -9.5663]]],\n",
            "\n",
            "\n",
            "        [[[ -8.9734]],\n",
            "\n",
            "         [[  5.9691]],\n",
            "\n",
            "         [[  0.1111]],\n",
            "\n",
            "         [[ -4.7821]],\n",
            "\n",
            "         [[  1.4889]],\n",
            "\n",
            "         [[  6.7434]],\n",
            "\n",
            "         [[ -0.3145]],\n",
            "\n",
            "         [[  3.0389]]],\n",
            "\n",
            "\n",
            "        [[[ -1.3385]],\n",
            "\n",
            "         [[ -1.3908]],\n",
            "\n",
            "         [[  0.9941]],\n",
            "\n",
            "         [[ -6.1607]],\n",
            "\n",
            "         [[ -0.7398]],\n",
            "\n",
            "         [[ 11.0238]],\n",
            "\n",
            "         [[-12.8982]],\n",
            "\n",
            "         [[ 14.9247]]]], grad_fn=<UnsafeViewBackward0>)\n",
            "ssfter shift tensor([[[[ -5.1682]],\n",
            "\n",
            "         [[ -0.2218]],\n",
            "\n",
            "         [[  7.8531]],\n",
            "\n",
            "         [[ -1.4963]],\n",
            "\n",
            "         [[  2.3530]],\n",
            "\n",
            "         [[  5.5204]],\n",
            "\n",
            "         [[ -5.1001]],\n",
            "\n",
            "         [[  9.2904]]],\n",
            "\n",
            "\n",
            "        [[[ -2.3394]],\n",
            "\n",
            "         [[  4.6394]],\n",
            "\n",
            "         [[  0.8669]],\n",
            "\n",
            "         [[ -7.3848]],\n",
            "\n",
            "         [[  6.3568]],\n",
            "\n",
            "         [[  3.9067]],\n",
            "\n",
            "         [[ -4.0883]],\n",
            "\n",
            "         [[  7.6461]]],\n",
            "\n",
            "\n",
            "        [[[ -2.3200]],\n",
            "\n",
            "         [[ -9.1733]],\n",
            "\n",
            "         [[  3.7951]],\n",
            "\n",
            "         [[  8.1013]],\n",
            "\n",
            "         [[ -1.5914]],\n",
            "\n",
            "         [[ -1.4755]],\n",
            "\n",
            "         [[  1.3107]],\n",
            "\n",
            "         [[ -9.5663]]],\n",
            "\n",
            "\n",
            "        [[[ -8.9734]],\n",
            "\n",
            "         [[  5.9691]],\n",
            "\n",
            "         [[  0.1111]],\n",
            "\n",
            "         [[ -4.7821]],\n",
            "\n",
            "         [[  1.4889]],\n",
            "\n",
            "         [[  6.7434]],\n",
            "\n",
            "         [[ -0.3145]],\n",
            "\n",
            "         [[  3.0389]]],\n",
            "\n",
            "\n",
            "        [[[ -1.3385]],\n",
            "\n",
            "         [[ -1.3908]],\n",
            "\n",
            "         [[  0.9941]],\n",
            "\n",
            "         [[ -6.1607]],\n",
            "\n",
            "         [[ -0.7398]],\n",
            "\n",
            "         [[ 11.0238]],\n",
            "\n",
            "         [[-12.8982]],\n",
            "\n",
            "         [[ 14.9247]]]], grad_fn=<ViewBackward0>)\n",
            "before shift tensor([[[[ -6.6136]],\n",
            "\n",
            "         [[ -4.3471]],\n",
            "\n",
            "         [[  7.1327]],\n",
            "\n",
            "         [[ -7.8984]],\n",
            "\n",
            "         [[  8.9832]],\n",
            "\n",
            "         [[ -6.7648]],\n",
            "\n",
            "         [[  2.9000]],\n",
            "\n",
            "         [[ -3.7071]]],\n",
            "\n",
            "\n",
            "        [[[ -5.9207]],\n",
            "\n",
            "         [[  1.7508]],\n",
            "\n",
            "         [[  2.8841]],\n",
            "\n",
            "         [[ 11.0341]],\n",
            "\n",
            "         [[  7.8105]],\n",
            "\n",
            "         [[  2.0886]],\n",
            "\n",
            "         [[ 10.1307]],\n",
            "\n",
            "         [[ -4.3541]]],\n",
            "\n",
            "\n",
            "        [[[ -2.6708]],\n",
            "\n",
            "         [[ -1.0970]],\n",
            "\n",
            "         [[ -7.0305]],\n",
            "\n",
            "         [[ -6.2168]],\n",
            "\n",
            "         [[-10.3848]],\n",
            "\n",
            "         [[-13.4398]],\n",
            "\n",
            "         [[ -5.1365]],\n",
            "\n",
            "         [[ -4.4272]]],\n",
            "\n",
            "\n",
            "        [[[ -0.2272]],\n",
            "\n",
            "         [[ -3.3673]],\n",
            "\n",
            "         [[  4.5805]],\n",
            "\n",
            "         [[  1.5358]],\n",
            "\n",
            "         [[ -1.3963]],\n",
            "\n",
            "         [[ -3.9672]],\n",
            "\n",
            "         [[  2.1312]],\n",
            "\n",
            "         [[ -3.0487]]],\n",
            "\n",
            "\n",
            "        [[[ -1.1570]],\n",
            "\n",
            "         [[  9.3561]],\n",
            "\n",
            "         [[ -0.8575]],\n",
            "\n",
            "         [[  4.2913]],\n",
            "\n",
            "         [[  1.8514]],\n",
            "\n",
            "         [[  2.8439]],\n",
            "\n",
            "         [[ 10.8444]],\n",
            "\n",
            "         [[ -6.1003]]]], grad_fn=<UnsafeViewBackward0>)\n",
            "ssfter shift tensor([[[[ -6.6136]],\n",
            "\n",
            "         [[ -4.3471]],\n",
            "\n",
            "         [[  7.1327]],\n",
            "\n",
            "         [[ -7.8984]],\n",
            "\n",
            "         [[  8.9832]],\n",
            "\n",
            "         [[ -6.7648]],\n",
            "\n",
            "         [[  2.9000]],\n",
            "\n",
            "         [[ -3.7071]]],\n",
            "\n",
            "\n",
            "        [[[ -5.9207]],\n",
            "\n",
            "         [[  1.7508]],\n",
            "\n",
            "         [[  2.8841]],\n",
            "\n",
            "         [[ 11.0341]],\n",
            "\n",
            "         [[  7.8105]],\n",
            "\n",
            "         [[  2.0886]],\n",
            "\n",
            "         [[ 10.1307]],\n",
            "\n",
            "         [[ -4.3541]]],\n",
            "\n",
            "\n",
            "        [[[ -2.6708]],\n",
            "\n",
            "         [[ -1.0970]],\n",
            "\n",
            "         [[ -7.0305]],\n",
            "\n",
            "         [[ -6.2168]],\n",
            "\n",
            "         [[-10.3848]],\n",
            "\n",
            "         [[-13.4398]],\n",
            "\n",
            "         [[ -5.1365]],\n",
            "\n",
            "         [[ -4.4272]]],\n",
            "\n",
            "\n",
            "        [[[ -0.2272]],\n",
            "\n",
            "         [[ -3.3673]],\n",
            "\n",
            "         [[  4.5805]],\n",
            "\n",
            "         [[  1.5358]],\n",
            "\n",
            "         [[ -1.3963]],\n",
            "\n",
            "         [[ -3.9672]],\n",
            "\n",
            "         [[  2.1312]],\n",
            "\n",
            "         [[ -3.0487]]],\n",
            "\n",
            "\n",
            "        [[[ -1.1570]],\n",
            "\n",
            "         [[  9.3561]],\n",
            "\n",
            "         [[ -0.8575]],\n",
            "\n",
            "         [[  4.2913]],\n",
            "\n",
            "         [[  1.8514]],\n",
            "\n",
            "         [[  2.8439]],\n",
            "\n",
            "         [[ 10.8444]],\n",
            "\n",
            "         [[ -6.1003]]]], grad_fn=<ViewBackward0>)\n",
            "before shift tensor([[[[ -7.8526]],\n",
            "\n",
            "         [[  5.1932]],\n",
            "\n",
            "         [[ -2.6914]],\n",
            "\n",
            "         [[ -0.8661]],\n",
            "\n",
            "         [[ 11.8681]],\n",
            "\n",
            "         [[ -3.3029]],\n",
            "\n",
            "         [[  1.1134]],\n",
            "\n",
            "         [[  0.2053]]],\n",
            "\n",
            "\n",
            "        [[[ -0.8136]],\n",
            "\n",
            "         [[  7.1177]],\n",
            "\n",
            "         [[ -5.0666]],\n",
            "\n",
            "         [[  4.6354]],\n",
            "\n",
            "         [[ -0.0205]],\n",
            "\n",
            "         [[  1.1502]],\n",
            "\n",
            "         [[  0.1317]],\n",
            "\n",
            "         [[  4.7229]]],\n",
            "\n",
            "\n",
            "        [[[ -2.0091]],\n",
            "\n",
            "         [[  9.6813]],\n",
            "\n",
            "         [[  0.8247]],\n",
            "\n",
            "         [[  5.1857]],\n",
            "\n",
            "         [[  1.7632]],\n",
            "\n",
            "         [[ -1.9392]],\n",
            "\n",
            "         [[ -0.2359]],\n",
            "\n",
            "         [[  1.2501]]],\n",
            "\n",
            "\n",
            "        [[[  2.5242]],\n",
            "\n",
            "         [[  2.7315]],\n",
            "\n",
            "         [[ -3.2710]],\n",
            "\n",
            "         [[  6.6498]],\n",
            "\n",
            "         [[  1.9880]],\n",
            "\n",
            "         [[ -9.8186]],\n",
            "\n",
            "         [[  1.5549]],\n",
            "\n",
            "         [[-11.0089]]],\n",
            "\n",
            "\n",
            "        [[[-13.8794]],\n",
            "\n",
            "         [[  4.1333]],\n",
            "\n",
            "         [[ -8.8026]],\n",
            "\n",
            "         [[  3.8000]],\n",
            "\n",
            "         [[ 10.2453]],\n",
            "\n",
            "         [[ -2.1549]],\n",
            "\n",
            "         [[  6.7263]],\n",
            "\n",
            "         [[ -0.7526]]]], grad_fn=<UnsafeViewBackward0>)\n",
            "ssfter shift tensor([[[[ -7.8526]],\n",
            "\n",
            "         [[  5.1932]],\n",
            "\n",
            "         [[ -2.6914]],\n",
            "\n",
            "         [[ -0.8661]],\n",
            "\n",
            "         [[ 11.8681]],\n",
            "\n",
            "         [[ -3.3029]],\n",
            "\n",
            "         [[  1.1134]],\n",
            "\n",
            "         [[  0.2053]]],\n",
            "\n",
            "\n",
            "        [[[ -0.8136]],\n",
            "\n",
            "         [[  7.1177]],\n",
            "\n",
            "         [[ -5.0666]],\n",
            "\n",
            "         [[  4.6354]],\n",
            "\n",
            "         [[ -0.0205]],\n",
            "\n",
            "         [[  1.1502]],\n",
            "\n",
            "         [[  0.1317]],\n",
            "\n",
            "         [[  4.7229]]],\n",
            "\n",
            "\n",
            "        [[[ -2.0091]],\n",
            "\n",
            "         [[  9.6813]],\n",
            "\n",
            "         [[  0.8247]],\n",
            "\n",
            "         [[  5.1857]],\n",
            "\n",
            "         [[  1.7632]],\n",
            "\n",
            "         [[ -1.9392]],\n",
            "\n",
            "         [[ -0.2359]],\n",
            "\n",
            "         [[  1.2501]]],\n",
            "\n",
            "\n",
            "        [[[  2.5242]],\n",
            "\n",
            "         [[  2.7315]],\n",
            "\n",
            "         [[ -3.2710]],\n",
            "\n",
            "         [[  6.6498]],\n",
            "\n",
            "         [[  1.9880]],\n",
            "\n",
            "         [[ -9.8186]],\n",
            "\n",
            "         [[  1.5549]],\n",
            "\n",
            "         [[-11.0089]]],\n",
            "\n",
            "\n",
            "        [[[-13.8794]],\n",
            "\n",
            "         [[  4.1333]],\n",
            "\n",
            "         [[ -8.8026]],\n",
            "\n",
            "         [[  3.8000]],\n",
            "\n",
            "         [[ 10.2453]],\n",
            "\n",
            "         [[ -2.1549]],\n",
            "\n",
            "         [[  6.7263]],\n",
            "\n",
            "         [[ -0.7526]]]], grad_fn=<ViewBackward0>)\n",
            "before shift tensor([[[[ -7.3980]],\n",
            "\n",
            "         [[  6.8468]],\n",
            "\n",
            "         [[ -5.1253]],\n",
            "\n",
            "         [[ -8.2145]],\n",
            "\n",
            "         [[  3.2932]],\n",
            "\n",
            "         [[ -1.4202]],\n",
            "\n",
            "         [[  8.5131]],\n",
            "\n",
            "         [[ -9.1819]]],\n",
            "\n",
            "\n",
            "        [[[  3.8757]],\n",
            "\n",
            "         [[  1.7947]],\n",
            "\n",
            "         [[  6.7234]],\n",
            "\n",
            "         [[-16.1295]],\n",
            "\n",
            "         [[  3.9242]],\n",
            "\n",
            "         [[  0.4461]],\n",
            "\n",
            "         [[  2.0839]],\n",
            "\n",
            "         [[ -5.1749]]],\n",
            "\n",
            "\n",
            "        [[[ -0.1318]],\n",
            "\n",
            "         [[ -3.0433]],\n",
            "\n",
            "         [[  0.2287]],\n",
            "\n",
            "         [[  4.1038]],\n",
            "\n",
            "         [[  2.7457]],\n",
            "\n",
            "         [[ -2.0294]],\n",
            "\n",
            "         [[  2.6131]],\n",
            "\n",
            "         [[ -0.3057]]],\n",
            "\n",
            "\n",
            "        [[[  6.9532]],\n",
            "\n",
            "         [[  9.9006]],\n",
            "\n",
            "         [[ -4.6338]],\n",
            "\n",
            "         [[ -5.7732]],\n",
            "\n",
            "         [[ 11.4460]],\n",
            "\n",
            "         [[ -2.6188]],\n",
            "\n",
            "         [[  4.9832]],\n",
            "\n",
            "         [[  2.4945]]],\n",
            "\n",
            "\n",
            "        [[[ -4.2425]],\n",
            "\n",
            "         [[ -7.2870]],\n",
            "\n",
            "         [[ -1.0739]],\n",
            "\n",
            "         [[ -8.5926]],\n",
            "\n",
            "         [[  5.2883]],\n",
            "\n",
            "         [[ 16.7387]],\n",
            "\n",
            "         [[  8.9268]],\n",
            "\n",
            "         [[ -4.3122]]]], grad_fn=<UnsafeViewBackward0>)\n",
            "ssfter shift tensor([[[[ -7.3980]],\n",
            "\n",
            "         [[  6.8468]],\n",
            "\n",
            "         [[ -5.1253]],\n",
            "\n",
            "         [[ -8.2145]],\n",
            "\n",
            "         [[  3.2932]],\n",
            "\n",
            "         [[ -1.4202]],\n",
            "\n",
            "         [[  8.5131]],\n",
            "\n",
            "         [[ -9.1819]]],\n",
            "\n",
            "\n",
            "        [[[  3.8757]],\n",
            "\n",
            "         [[  1.7947]],\n",
            "\n",
            "         [[  6.7234]],\n",
            "\n",
            "         [[-16.1295]],\n",
            "\n",
            "         [[  3.9242]],\n",
            "\n",
            "         [[  0.4461]],\n",
            "\n",
            "         [[  2.0839]],\n",
            "\n",
            "         [[ -5.1749]]],\n",
            "\n",
            "\n",
            "        [[[ -0.1318]],\n",
            "\n",
            "         [[ -3.0433]],\n",
            "\n",
            "         [[  0.2287]],\n",
            "\n",
            "         [[  4.1038]],\n",
            "\n",
            "         [[  2.7457]],\n",
            "\n",
            "         [[ -2.0294]],\n",
            "\n",
            "         [[  2.6131]],\n",
            "\n",
            "         [[ -0.3057]]],\n",
            "\n",
            "\n",
            "        [[[  6.9532]],\n",
            "\n",
            "         [[  9.9006]],\n",
            "\n",
            "         [[ -4.6338]],\n",
            "\n",
            "         [[ -5.7732]],\n",
            "\n",
            "         [[ 11.4460]],\n",
            "\n",
            "         [[ -2.6188]],\n",
            "\n",
            "         [[  4.9832]],\n",
            "\n",
            "         [[  2.4945]]],\n",
            "\n",
            "\n",
            "        [[[ -4.2425]],\n",
            "\n",
            "         [[ -7.2870]],\n",
            "\n",
            "         [[ -1.0739]],\n",
            "\n",
            "         [[ -8.5926]],\n",
            "\n",
            "         [[  5.2883]],\n",
            "\n",
            "         [[ 16.7387]],\n",
            "\n",
            "         [[  8.9268]],\n",
            "\n",
            "         [[ -4.3122]]]], grad_fn=<ViewBackward0>)\n",
            "before shift tensor([[[[ -1.9531]],\n",
            "\n",
            "         [[  8.8983]],\n",
            "\n",
            "         [[ -0.7732]],\n",
            "\n",
            "         [[ 12.4810]],\n",
            "\n",
            "         [[  2.0165]],\n",
            "\n",
            "         [[  8.8535]],\n",
            "\n",
            "         [[  5.4694]],\n",
            "\n",
            "         [[  0.3948]]],\n",
            "\n",
            "\n",
            "        [[[ -9.2689]],\n",
            "\n",
            "         [[  2.6602]],\n",
            "\n",
            "         [[ -6.8515]],\n",
            "\n",
            "         [[ 10.3246]],\n",
            "\n",
            "         [[  2.0106]],\n",
            "\n",
            "         [[  8.0597]],\n",
            "\n",
            "         [[  0.5085]],\n",
            "\n",
            "         [[ -5.2200]]],\n",
            "\n",
            "\n",
            "        [[[ -1.1977]],\n",
            "\n",
            "         [[  5.4469]],\n",
            "\n",
            "         [[ -2.6055]],\n",
            "\n",
            "         [[ -3.2451]],\n",
            "\n",
            "         [[ -0.8118]],\n",
            "\n",
            "         [[ -2.4036]],\n",
            "\n",
            "         [[  0.2402]],\n",
            "\n",
            "         [[  0.8145]]],\n",
            "\n",
            "\n",
            "        [[[  0.4910]],\n",
            "\n",
            "         [[ -1.4937]],\n",
            "\n",
            "         [[  2.2855]],\n",
            "\n",
            "         [[  4.4089]],\n",
            "\n",
            "         [[  3.6235]],\n",
            "\n",
            "         [[  0.0888]],\n",
            "\n",
            "         [[ -5.7245]],\n",
            "\n",
            "         [[  4.1891]]],\n",
            "\n",
            "\n",
            "        [[[ -2.2527]],\n",
            "\n",
            "         [[  1.6990]],\n",
            "\n",
            "         [[ -7.5121]],\n",
            "\n",
            "         [[  2.8269]],\n",
            "\n",
            "         [[-19.7172]],\n",
            "\n",
            "         [[ -0.1672]],\n",
            "\n",
            "         [[ -6.5765]],\n",
            "\n",
            "         [[  0.4764]]]], grad_fn=<UnsafeViewBackward0>)\n",
            "ssfter shift tensor([[[[ -1.9531]],\n",
            "\n",
            "         [[  8.8983]],\n",
            "\n",
            "         [[ -0.7732]],\n",
            "\n",
            "         [[ 12.4810]],\n",
            "\n",
            "         [[  2.0165]],\n",
            "\n",
            "         [[  8.8535]],\n",
            "\n",
            "         [[  5.4694]],\n",
            "\n",
            "         [[  0.3948]]],\n",
            "\n",
            "\n",
            "        [[[ -9.2689]],\n",
            "\n",
            "         [[  2.6602]],\n",
            "\n",
            "         [[ -6.8515]],\n",
            "\n",
            "         [[ 10.3246]],\n",
            "\n",
            "         [[  2.0106]],\n",
            "\n",
            "         [[  8.0597]],\n",
            "\n",
            "         [[  0.5085]],\n",
            "\n",
            "         [[ -5.2200]]],\n",
            "\n",
            "\n",
            "        [[[ -1.1977]],\n",
            "\n",
            "         [[  5.4469]],\n",
            "\n",
            "         [[ -2.6055]],\n",
            "\n",
            "         [[ -3.2451]],\n",
            "\n",
            "         [[ -0.8118]],\n",
            "\n",
            "         [[ -2.4036]],\n",
            "\n",
            "         [[  0.2402]],\n",
            "\n",
            "         [[  0.8145]]],\n",
            "\n",
            "\n",
            "        [[[  0.4910]],\n",
            "\n",
            "         [[ -1.4937]],\n",
            "\n",
            "         [[  2.2855]],\n",
            "\n",
            "         [[  4.4089]],\n",
            "\n",
            "         [[  3.6235]],\n",
            "\n",
            "         [[  0.0888]],\n",
            "\n",
            "         [[ -5.7245]],\n",
            "\n",
            "         [[  4.1891]]],\n",
            "\n",
            "\n",
            "        [[[ -2.2527]],\n",
            "\n",
            "         [[  1.6990]],\n",
            "\n",
            "         [[ -7.5121]],\n",
            "\n",
            "         [[  2.8269]],\n",
            "\n",
            "         [[-19.7172]],\n",
            "\n",
            "         [[ -0.1672]],\n",
            "\n",
            "         [[ -6.5765]],\n",
            "\n",
            "         [[  0.4764]]]], grad_fn=<ViewBackward0>)\n",
            "before shift tensor([[[[ -6.8774]],\n",
            "\n",
            "         [[  5.2993]],\n",
            "\n",
            "         [[  1.3874]],\n",
            "\n",
            "         [[  1.1443]],\n",
            "\n",
            "         [[ -2.1393]],\n",
            "\n",
            "         [[-10.9844]],\n",
            "\n",
            "         [[ -2.0635]],\n",
            "\n",
            "         [[ -6.6558]]],\n",
            "\n",
            "\n",
            "        [[[  9.9595]],\n",
            "\n",
            "         [[  4.4842]],\n",
            "\n",
            "         [[-11.1895]],\n",
            "\n",
            "         [[  1.3789]],\n",
            "\n",
            "         [[  2.6699]],\n",
            "\n",
            "         [[ -5.4400]],\n",
            "\n",
            "         [[ -5.3260]],\n",
            "\n",
            "         [[  9.6217]]],\n",
            "\n",
            "\n",
            "        [[[ -8.7554]],\n",
            "\n",
            "         [[  7.3349]],\n",
            "\n",
            "         [[  3.2868]],\n",
            "\n",
            "         [[  5.7028]],\n",
            "\n",
            "         [[  7.9129]],\n",
            "\n",
            "         [[  2.2560]],\n",
            "\n",
            "         [[  3.7541]],\n",
            "\n",
            "         [[ -0.0340]]],\n",
            "\n",
            "\n",
            "        [[[ 10.8703]],\n",
            "\n",
            "         [[ -4.2542]],\n",
            "\n",
            "         [[-11.8009]],\n",
            "\n",
            "         [[  0.9556]],\n",
            "\n",
            "         [[  2.3281]],\n",
            "\n",
            "         [[  2.4055]],\n",
            "\n",
            "         [[ -0.8505]],\n",
            "\n",
            "         [[ -1.2476]]],\n",
            "\n",
            "\n",
            "        [[[  6.5278]],\n",
            "\n",
            "         [[  9.9870]],\n",
            "\n",
            "         [[ -2.6303]],\n",
            "\n",
            "         [[ -2.5706]],\n",
            "\n",
            "         [[ -1.3290]],\n",
            "\n",
            "         [[ -3.5620]],\n",
            "\n",
            "         [[ -2.0262]],\n",
            "\n",
            "         [[ -6.7132]]]], grad_fn=<UnsafeViewBackward0>)\n",
            "ssfter shift tensor([[[[ -6.8774]],\n",
            "\n",
            "         [[  5.2993]],\n",
            "\n",
            "         [[  1.3874]],\n",
            "\n",
            "         [[  1.1443]],\n",
            "\n",
            "         [[ -2.1393]],\n",
            "\n",
            "         [[-10.9844]],\n",
            "\n",
            "         [[ -2.0635]],\n",
            "\n",
            "         [[ -6.6558]]],\n",
            "\n",
            "\n",
            "        [[[  9.9595]],\n",
            "\n",
            "         [[  4.4842]],\n",
            "\n",
            "         [[-11.1895]],\n",
            "\n",
            "         [[  1.3789]],\n",
            "\n",
            "         [[  2.6699]],\n",
            "\n",
            "         [[ -5.4400]],\n",
            "\n",
            "         [[ -5.3260]],\n",
            "\n",
            "         [[  9.6217]]],\n",
            "\n",
            "\n",
            "        [[[ -8.7554]],\n",
            "\n",
            "         [[  7.3349]],\n",
            "\n",
            "         [[  3.2868]],\n",
            "\n",
            "         [[  5.7028]],\n",
            "\n",
            "         [[  7.9129]],\n",
            "\n",
            "         [[  2.2560]],\n",
            "\n",
            "         [[  3.7541]],\n",
            "\n",
            "         [[ -0.0340]]],\n",
            "\n",
            "\n",
            "        [[[ 10.8703]],\n",
            "\n",
            "         [[ -4.2542]],\n",
            "\n",
            "         [[-11.8009]],\n",
            "\n",
            "         [[  0.9556]],\n",
            "\n",
            "         [[  2.3281]],\n",
            "\n",
            "         [[  2.4055]],\n",
            "\n",
            "         [[ -0.8505]],\n",
            "\n",
            "         [[ -1.2476]]],\n",
            "\n",
            "\n",
            "        [[[  6.5278]],\n",
            "\n",
            "         [[  9.9870]],\n",
            "\n",
            "         [[ -2.6303]],\n",
            "\n",
            "         [[ -2.5706]],\n",
            "\n",
            "         [[ -1.3290]],\n",
            "\n",
            "         [[ -3.5620]],\n",
            "\n",
            "         [[ -2.0262]],\n",
            "\n",
            "         [[ -6.7132]]]], grad_fn=<ViewBackward0>)\n",
            "before shift tensor([[[[ 12.3803]],\n",
            "\n",
            "         [[ -0.8474]],\n",
            "\n",
            "         [[  5.5897]],\n",
            "\n",
            "         [[  4.5475]],\n",
            "\n",
            "         [[  3.0570]],\n",
            "\n",
            "         [[  8.9929]],\n",
            "\n",
            "         [[  1.0596]],\n",
            "\n",
            "         [[-10.7750]]],\n",
            "\n",
            "\n",
            "        [[[  6.1229]],\n",
            "\n",
            "         [[ 12.9989]],\n",
            "\n",
            "         [[  2.6411]],\n",
            "\n",
            "         [[ -9.5028]],\n",
            "\n",
            "         [[ -5.6822]],\n",
            "\n",
            "         [[  1.9381]],\n",
            "\n",
            "         [[ -1.7521]],\n",
            "\n",
            "         [[ -1.3517]]],\n",
            "\n",
            "\n",
            "        [[[  4.6180]],\n",
            "\n",
            "         [[ -0.1143]],\n",
            "\n",
            "         [[  6.4853]],\n",
            "\n",
            "         [[ -2.3901]],\n",
            "\n",
            "         [[  4.4065]],\n",
            "\n",
            "         [[  5.2722]],\n",
            "\n",
            "         [[  6.0518]],\n",
            "\n",
            "         [[ -8.4908]]],\n",
            "\n",
            "\n",
            "        [[[ 11.0185]],\n",
            "\n",
            "         [[  8.1834]],\n",
            "\n",
            "         [[ -0.4314]],\n",
            "\n",
            "         [[ -8.4032]],\n",
            "\n",
            "         [[  0.0996]],\n",
            "\n",
            "         [[  5.2753]],\n",
            "\n",
            "         [[  6.2339]],\n",
            "\n",
            "         [[  6.0181]]],\n",
            "\n",
            "\n",
            "        [[[  0.3338]],\n",
            "\n",
            "         [[-10.0581]],\n",
            "\n",
            "         [[ 13.3349]],\n",
            "\n",
            "         [[  2.1911]],\n",
            "\n",
            "         [[ 11.0094]],\n",
            "\n",
            "         [[  8.4406]],\n",
            "\n",
            "         [[  2.7514]],\n",
            "\n",
            "         [[  0.3599]]]], grad_fn=<UnsafeViewBackward0>)\n",
            "ssfter shift tensor([[[[ 12.3803]],\n",
            "\n",
            "         [[ -0.8474]],\n",
            "\n",
            "         [[  5.5897]],\n",
            "\n",
            "         [[  4.5475]],\n",
            "\n",
            "         [[  3.0570]],\n",
            "\n",
            "         [[  8.9929]],\n",
            "\n",
            "         [[  1.0596]],\n",
            "\n",
            "         [[-10.7750]]],\n",
            "\n",
            "\n",
            "        [[[  6.1229]],\n",
            "\n",
            "         [[ 12.9989]],\n",
            "\n",
            "         [[  2.6411]],\n",
            "\n",
            "         [[ -9.5028]],\n",
            "\n",
            "         [[ -5.6822]],\n",
            "\n",
            "         [[  1.9381]],\n",
            "\n",
            "         [[ -1.7521]],\n",
            "\n",
            "         [[ -1.3517]]],\n",
            "\n",
            "\n",
            "        [[[  4.6180]],\n",
            "\n",
            "         [[ -0.1143]],\n",
            "\n",
            "         [[  6.4853]],\n",
            "\n",
            "         [[ -2.3901]],\n",
            "\n",
            "         [[  4.4065]],\n",
            "\n",
            "         [[  5.2722]],\n",
            "\n",
            "         [[  6.0518]],\n",
            "\n",
            "         [[ -8.4908]]],\n",
            "\n",
            "\n",
            "        [[[ 11.0185]],\n",
            "\n",
            "         [[  8.1834]],\n",
            "\n",
            "         [[ -0.4314]],\n",
            "\n",
            "         [[ -8.4032]],\n",
            "\n",
            "         [[  0.0996]],\n",
            "\n",
            "         [[  5.2753]],\n",
            "\n",
            "         [[  6.2339]],\n",
            "\n",
            "         [[  6.0181]]],\n",
            "\n",
            "\n",
            "        [[[  0.3338]],\n",
            "\n",
            "         [[-10.0581]],\n",
            "\n",
            "         [[ 13.3349]],\n",
            "\n",
            "         [[  2.1911]],\n",
            "\n",
            "         [[ 11.0094]],\n",
            "\n",
            "         [[  8.4406]],\n",
            "\n",
            "         [[  2.7514]],\n",
            "\n",
            "         [[  0.3599]]]], grad_fn=<ViewBackward0>)\n",
            "before shift tensor([[[[  9.3586]],\n",
            "\n",
            "         [[ -1.6313]],\n",
            "\n",
            "         [[ -3.6786]],\n",
            "\n",
            "         [[ -5.8411]],\n",
            "\n",
            "         [[ -1.7797]],\n",
            "\n",
            "         [[  1.0062]],\n",
            "\n",
            "         [[  1.0138]],\n",
            "\n",
            "         [[  0.5006]]],\n",
            "\n",
            "\n",
            "        [[[ -1.6336]],\n",
            "\n",
            "         [[  3.4703]],\n",
            "\n",
            "         [[  1.0933]],\n",
            "\n",
            "         [[ -3.7765]],\n",
            "\n",
            "         [[ -1.0135]],\n",
            "\n",
            "         [[  1.0613]],\n",
            "\n",
            "         [[  4.9810]],\n",
            "\n",
            "         [[ -1.9166]]],\n",
            "\n",
            "\n",
            "        [[[  4.5984]],\n",
            "\n",
            "         [[  1.9985]],\n",
            "\n",
            "         [[  3.8632]],\n",
            "\n",
            "         [[ -4.1569]],\n",
            "\n",
            "         [[-10.2007]],\n",
            "\n",
            "         [[ -6.6775]],\n",
            "\n",
            "         [[ -8.3087]],\n",
            "\n",
            "         [[  4.0241]]],\n",
            "\n",
            "\n",
            "        [[[ -5.6382]],\n",
            "\n",
            "         [[-10.3158]],\n",
            "\n",
            "         [[  2.9090]],\n",
            "\n",
            "         [[ -3.4991]],\n",
            "\n",
            "         [[  0.8849]],\n",
            "\n",
            "         [[ -4.8681]],\n",
            "\n",
            "         [[  0.7721]],\n",
            "\n",
            "         [[  0.8063]]],\n",
            "\n",
            "\n",
            "        [[[ -5.3823]],\n",
            "\n",
            "         [[ 12.5901]],\n",
            "\n",
            "         [[-11.3714]],\n",
            "\n",
            "         [[  1.2904]],\n",
            "\n",
            "         [[-11.2857]],\n",
            "\n",
            "         [[ -4.3889]],\n",
            "\n",
            "         [[  3.8678]],\n",
            "\n",
            "         [[ -1.1820]]]], grad_fn=<UnsafeViewBackward0>)\n",
            "ssfter shift tensor([[[[  9.3586]],\n",
            "\n",
            "         [[ -1.6313]],\n",
            "\n",
            "         [[ -3.6786]],\n",
            "\n",
            "         [[ -5.8411]],\n",
            "\n",
            "         [[ -1.7797]],\n",
            "\n",
            "         [[  1.0062]],\n",
            "\n",
            "         [[  1.0138]],\n",
            "\n",
            "         [[  0.5006]]],\n",
            "\n",
            "\n",
            "        [[[ -1.6336]],\n",
            "\n",
            "         [[  3.4703]],\n",
            "\n",
            "         [[  1.0933]],\n",
            "\n",
            "         [[ -3.7765]],\n",
            "\n",
            "         [[ -1.0135]],\n",
            "\n",
            "         [[  1.0613]],\n",
            "\n",
            "         [[  4.9810]],\n",
            "\n",
            "         [[ -1.9166]]],\n",
            "\n",
            "\n",
            "        [[[  4.5984]],\n",
            "\n",
            "         [[  1.9985]],\n",
            "\n",
            "         [[  3.8632]],\n",
            "\n",
            "         [[ -4.1569]],\n",
            "\n",
            "         [[-10.2007]],\n",
            "\n",
            "         [[ -6.6775]],\n",
            "\n",
            "         [[ -8.3087]],\n",
            "\n",
            "         [[  4.0241]]],\n",
            "\n",
            "\n",
            "        [[[ -5.6382]],\n",
            "\n",
            "         [[-10.3158]],\n",
            "\n",
            "         [[  2.9090]],\n",
            "\n",
            "         [[ -3.4991]],\n",
            "\n",
            "         [[  0.8849]],\n",
            "\n",
            "         [[ -4.8681]],\n",
            "\n",
            "         [[  0.7721]],\n",
            "\n",
            "         [[  0.8063]]],\n",
            "\n",
            "\n",
            "        [[[ -5.3823]],\n",
            "\n",
            "         [[ 12.5901]],\n",
            "\n",
            "         [[-11.3714]],\n",
            "\n",
            "         [[  1.2904]],\n",
            "\n",
            "         [[-11.2857]],\n",
            "\n",
            "         [[ -4.3889]],\n",
            "\n",
            "         [[  3.8678]],\n",
            "\n",
            "         [[ -1.1820]]]], grad_fn=<ViewBackward0>)\n",
            "before shift tensor([[[[ 3.1285]],\n",
            "\n",
            "         [[-4.3677]],\n",
            "\n",
            "         [[-2.1323]],\n",
            "\n",
            "         [[17.5205]],\n",
            "\n",
            "         [[-0.5715]],\n",
            "\n",
            "         [[10.5569]],\n",
            "\n",
            "         [[-1.2800]],\n",
            "\n",
            "         [[ 6.3333]]],\n",
            "\n",
            "\n",
            "        [[[ 3.8725]],\n",
            "\n",
            "         [[ 4.0563]],\n",
            "\n",
            "         [[ 2.6456]],\n",
            "\n",
            "         [[-1.2151]],\n",
            "\n",
            "         [[-9.2242]],\n",
            "\n",
            "         [[ 1.8323]],\n",
            "\n",
            "         [[-2.5606]],\n",
            "\n",
            "         [[-0.4737]]],\n",
            "\n",
            "\n",
            "        [[[ 3.4494]],\n",
            "\n",
            "         [[-3.5538]],\n",
            "\n",
            "         [[-5.2586]],\n",
            "\n",
            "         [[ 2.4118]],\n",
            "\n",
            "         [[-3.7598]],\n",
            "\n",
            "         [[-7.6711]],\n",
            "\n",
            "         [[ 5.5023]],\n",
            "\n",
            "         [[ 6.3098]]],\n",
            "\n",
            "\n",
            "        [[[ 3.6518]],\n",
            "\n",
            "         [[ 8.4445]],\n",
            "\n",
            "         [[14.9418]],\n",
            "\n",
            "         [[ 0.6367]],\n",
            "\n",
            "         [[ 3.8849]],\n",
            "\n",
            "         [[-1.4572]],\n",
            "\n",
            "         [[-6.3148]],\n",
            "\n",
            "         [[-8.3179]]],\n",
            "\n",
            "\n",
            "        [[[-3.3885]],\n",
            "\n",
            "         [[ 0.9841]],\n",
            "\n",
            "         [[-5.3650]],\n",
            "\n",
            "         [[ 0.9505]],\n",
            "\n",
            "         [[ 8.1903]],\n",
            "\n",
            "         [[-3.1529]],\n",
            "\n",
            "         [[-3.2704]],\n",
            "\n",
            "         [[-0.5080]]]], grad_fn=<UnsafeViewBackward0>)\n",
            "ssfter shift tensor([[[[ 3.1285]],\n",
            "\n",
            "         [[-4.3677]],\n",
            "\n",
            "         [[-2.1323]],\n",
            "\n",
            "         [[17.5205]],\n",
            "\n",
            "         [[-0.5715]],\n",
            "\n",
            "         [[10.5569]],\n",
            "\n",
            "         [[-1.2800]],\n",
            "\n",
            "         [[ 6.3333]]],\n",
            "\n",
            "\n",
            "        [[[ 3.8725]],\n",
            "\n",
            "         [[ 4.0563]],\n",
            "\n",
            "         [[ 2.6456]],\n",
            "\n",
            "         [[-1.2151]],\n",
            "\n",
            "         [[-9.2242]],\n",
            "\n",
            "         [[ 1.8323]],\n",
            "\n",
            "         [[-2.5606]],\n",
            "\n",
            "         [[-0.4737]]],\n",
            "\n",
            "\n",
            "        [[[ 3.4494]],\n",
            "\n",
            "         [[-3.5538]],\n",
            "\n",
            "         [[-5.2586]],\n",
            "\n",
            "         [[ 2.4118]],\n",
            "\n",
            "         [[-3.7598]],\n",
            "\n",
            "         [[-7.6711]],\n",
            "\n",
            "         [[ 5.5023]],\n",
            "\n",
            "         [[ 6.3098]]],\n",
            "\n",
            "\n",
            "        [[[ 3.6518]],\n",
            "\n",
            "         [[ 8.4445]],\n",
            "\n",
            "         [[14.9418]],\n",
            "\n",
            "         [[ 0.6367]],\n",
            "\n",
            "         [[ 3.8849]],\n",
            "\n",
            "         [[-1.4572]],\n",
            "\n",
            "         [[-6.3148]],\n",
            "\n",
            "         [[-8.3179]]],\n",
            "\n",
            "\n",
            "        [[[-3.3885]],\n",
            "\n",
            "         [[ 0.9841]],\n",
            "\n",
            "         [[-5.3650]],\n",
            "\n",
            "         [[ 0.9505]],\n",
            "\n",
            "         [[ 8.1903]],\n",
            "\n",
            "         [[-3.1529]],\n",
            "\n",
            "         [[-3.2704]],\n",
            "\n",
            "         [[-0.5080]]]], grad_fn=<ViewBackward0>)\n",
            "before shift tensor([[[[ -0.4847]],\n",
            "\n",
            "         [[  6.9147]],\n",
            "\n",
            "         [[ -0.0246]],\n",
            "\n",
            "         [[ -1.2095]],\n",
            "\n",
            "         [[ -0.5535]],\n",
            "\n",
            "         [[ -0.9284]],\n",
            "\n",
            "         [[ 12.6218]],\n",
            "\n",
            "         [[  3.1113]]],\n",
            "\n",
            "\n",
            "        [[[ -4.7982]],\n",
            "\n",
            "         [[ -4.1405]],\n",
            "\n",
            "         [[ -0.0181]],\n",
            "\n",
            "         [[ -5.3322]],\n",
            "\n",
            "         [[ -5.1066]],\n",
            "\n",
            "         [[  2.0162]],\n",
            "\n",
            "         [[  5.4342]],\n",
            "\n",
            "         [[  3.2150]]],\n",
            "\n",
            "\n",
            "        [[[  3.4865]],\n",
            "\n",
            "         [[-10.5506]],\n",
            "\n",
            "         [[  3.6502]],\n",
            "\n",
            "         [[  1.5870]],\n",
            "\n",
            "         [[ 11.8791]],\n",
            "\n",
            "         [[ -2.2520]],\n",
            "\n",
            "         [[ -8.2261]],\n",
            "\n",
            "         [[ -0.3708]]],\n",
            "\n",
            "\n",
            "        [[[  6.8673]],\n",
            "\n",
            "         [[ -4.8382]],\n",
            "\n",
            "         [[  0.8014]],\n",
            "\n",
            "         [[  1.9953]],\n",
            "\n",
            "         [[ -0.1288]],\n",
            "\n",
            "         [[  0.9377]],\n",
            "\n",
            "         [[  1.4032]],\n",
            "\n",
            "         [[ -4.1988]]],\n",
            "\n",
            "\n",
            "        [[[ -2.4135]],\n",
            "\n",
            "         [[  0.2087]],\n",
            "\n",
            "         [[  1.4178]],\n",
            "\n",
            "         [[ -3.6937]],\n",
            "\n",
            "         [[  1.8196]],\n",
            "\n",
            "         [[ -1.0219]],\n",
            "\n",
            "         [[ -2.1035]],\n",
            "\n",
            "         [[  1.6099]]]], grad_fn=<UnsafeViewBackward0>)\n",
            "ssfter shift tensor([[[[ -0.4847]],\n",
            "\n",
            "         [[  6.9147]],\n",
            "\n",
            "         [[ -0.0246]],\n",
            "\n",
            "         [[ -1.2095]],\n",
            "\n",
            "         [[ -0.5535]],\n",
            "\n",
            "         [[ -0.9284]],\n",
            "\n",
            "         [[ 12.6218]],\n",
            "\n",
            "         [[  3.1113]]],\n",
            "\n",
            "\n",
            "        [[[ -4.7982]],\n",
            "\n",
            "         [[ -4.1405]],\n",
            "\n",
            "         [[ -0.0181]],\n",
            "\n",
            "         [[ -5.3322]],\n",
            "\n",
            "         [[ -5.1066]],\n",
            "\n",
            "         [[  2.0162]],\n",
            "\n",
            "         [[  5.4342]],\n",
            "\n",
            "         [[  3.2150]]],\n",
            "\n",
            "\n",
            "        [[[  3.4865]],\n",
            "\n",
            "         [[-10.5506]],\n",
            "\n",
            "         [[  3.6502]],\n",
            "\n",
            "         [[  1.5870]],\n",
            "\n",
            "         [[ 11.8791]],\n",
            "\n",
            "         [[ -2.2520]],\n",
            "\n",
            "         [[ -8.2261]],\n",
            "\n",
            "         [[ -0.3708]]],\n",
            "\n",
            "\n",
            "        [[[  6.8673]],\n",
            "\n",
            "         [[ -4.8382]],\n",
            "\n",
            "         [[  0.8014]],\n",
            "\n",
            "         [[  1.9953]],\n",
            "\n",
            "         [[ -0.1288]],\n",
            "\n",
            "         [[  0.9377]],\n",
            "\n",
            "         [[  1.4032]],\n",
            "\n",
            "         [[ -4.1988]]],\n",
            "\n",
            "\n",
            "        [[[ -2.4135]],\n",
            "\n",
            "         [[  0.2087]],\n",
            "\n",
            "         [[  1.4178]],\n",
            "\n",
            "         [[ -3.6937]],\n",
            "\n",
            "         [[  1.8196]],\n",
            "\n",
            "         [[ -1.0219]],\n",
            "\n",
            "         [[ -2.1035]],\n",
            "\n",
            "         [[  1.6099]]]], grad_fn=<ViewBackward0>)\n",
            "before shift tensor([[[[-1.7227]],\n",
            "\n",
            "         [[ 1.6251]],\n",
            "\n",
            "         [[ 4.2285]],\n",
            "\n",
            "         [[-4.8772]],\n",
            "\n",
            "         [[-4.8844]],\n",
            "\n",
            "         [[ 6.9492]],\n",
            "\n",
            "         [[ 9.6134]],\n",
            "\n",
            "         [[ 6.4739]]],\n",
            "\n",
            "\n",
            "        [[[-0.5981]],\n",
            "\n",
            "         [[-4.6198]],\n",
            "\n",
            "         [[ 0.2208]],\n",
            "\n",
            "         [[ 7.9368]],\n",
            "\n",
            "         [[ 0.2955]],\n",
            "\n",
            "         [[ 0.6448]],\n",
            "\n",
            "         [[-1.6591]],\n",
            "\n",
            "         [[ 2.9297]]],\n",
            "\n",
            "\n",
            "        [[[-5.8388]],\n",
            "\n",
            "         [[ 2.8337]],\n",
            "\n",
            "         [[11.8809]],\n",
            "\n",
            "         [[-1.0712]],\n",
            "\n",
            "         [[ 2.3737]],\n",
            "\n",
            "         [[-8.8487]],\n",
            "\n",
            "         [[ 8.0796]],\n",
            "\n",
            "         [[-1.3884]]],\n",
            "\n",
            "\n",
            "        [[[-0.5867]],\n",
            "\n",
            "         [[-0.4755]],\n",
            "\n",
            "         [[ 2.9471]],\n",
            "\n",
            "         [[ 2.8153]],\n",
            "\n",
            "         [[-1.1981]],\n",
            "\n",
            "         [[ 0.1608]],\n",
            "\n",
            "         [[-5.3913]],\n",
            "\n",
            "         [[ 2.1861]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9719]],\n",
            "\n",
            "         [[-0.3178]],\n",
            "\n",
            "         [[ 2.2141]],\n",
            "\n",
            "         [[-4.5189]],\n",
            "\n",
            "         [[-6.0431]],\n",
            "\n",
            "         [[-3.0682]],\n",
            "\n",
            "         [[ 3.6347]],\n",
            "\n",
            "         [[ 9.8336]]]], grad_fn=<UnsafeViewBackward0>)\n",
            "ssfter shift tensor([[[[-1.7227]],\n",
            "\n",
            "         [[ 1.6251]],\n",
            "\n",
            "         [[ 4.2285]],\n",
            "\n",
            "         [[-4.8772]],\n",
            "\n",
            "         [[-4.8844]],\n",
            "\n",
            "         [[ 6.9492]],\n",
            "\n",
            "         [[ 9.6134]],\n",
            "\n",
            "         [[ 6.4739]]],\n",
            "\n",
            "\n",
            "        [[[-0.5981]],\n",
            "\n",
            "         [[-4.6198]],\n",
            "\n",
            "         [[ 0.2208]],\n",
            "\n",
            "         [[ 7.9368]],\n",
            "\n",
            "         [[ 0.2955]],\n",
            "\n",
            "         [[ 0.6448]],\n",
            "\n",
            "         [[-1.6591]],\n",
            "\n",
            "         [[ 2.9297]]],\n",
            "\n",
            "\n",
            "        [[[-5.8388]],\n",
            "\n",
            "         [[ 2.8337]],\n",
            "\n",
            "         [[11.8809]],\n",
            "\n",
            "         [[-1.0712]],\n",
            "\n",
            "         [[ 2.3737]],\n",
            "\n",
            "         [[-8.8487]],\n",
            "\n",
            "         [[ 8.0796]],\n",
            "\n",
            "         [[-1.3884]]],\n",
            "\n",
            "\n",
            "        [[[-0.5867]],\n",
            "\n",
            "         [[-0.4755]],\n",
            "\n",
            "         [[ 2.9471]],\n",
            "\n",
            "         [[ 2.8153]],\n",
            "\n",
            "         [[-1.1981]],\n",
            "\n",
            "         [[ 0.1608]],\n",
            "\n",
            "         [[-5.3913]],\n",
            "\n",
            "         [[ 2.1861]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9719]],\n",
            "\n",
            "         [[-0.3178]],\n",
            "\n",
            "         [[ 2.2141]],\n",
            "\n",
            "         [[-4.5189]],\n",
            "\n",
            "         [[-6.0431]],\n",
            "\n",
            "         [[-3.0682]],\n",
            "\n",
            "         [[ 3.6347]],\n",
            "\n",
            "         [[ 9.8336]]]], grad_fn=<ViewBackward0>)\n",
            "before shift tensor([[[[11.5909]],\n",
            "\n",
            "         [[ 2.0611]],\n",
            "\n",
            "         [[ 2.7270]],\n",
            "\n",
            "         [[ 1.5129]],\n",
            "\n",
            "         [[ 8.9682]],\n",
            "\n",
            "         [[ 8.0498]],\n",
            "\n",
            "         [[-1.8181]],\n",
            "\n",
            "         [[ 7.4384]]],\n",
            "\n",
            "\n",
            "        [[[ 6.1522]],\n",
            "\n",
            "         [[-2.6521]],\n",
            "\n",
            "         [[-0.5594]],\n",
            "\n",
            "         [[-7.4063]],\n",
            "\n",
            "         [[-6.3469]],\n",
            "\n",
            "         [[-8.2439]],\n",
            "\n",
            "         [[ 0.4855]],\n",
            "\n",
            "         [[-2.1127]]],\n",
            "\n",
            "\n",
            "        [[[ 2.1011]],\n",
            "\n",
            "         [[-1.8819]],\n",
            "\n",
            "         [[11.3779]],\n",
            "\n",
            "         [[-4.3598]],\n",
            "\n",
            "         [[14.6621]],\n",
            "\n",
            "         [[-7.8214]],\n",
            "\n",
            "         [[10.7822]],\n",
            "\n",
            "         [[ 0.4102]]],\n",
            "\n",
            "\n",
            "        [[[ 2.6714]],\n",
            "\n",
            "         [[ 2.7373]],\n",
            "\n",
            "         [[ 8.8180]],\n",
            "\n",
            "         [[-4.7238]],\n",
            "\n",
            "         [[ 4.1687]],\n",
            "\n",
            "         [[ 5.8949]],\n",
            "\n",
            "         [[ 7.1671]],\n",
            "\n",
            "         [[ 1.0466]]],\n",
            "\n",
            "\n",
            "        [[[ 9.7179]],\n",
            "\n",
            "         [[ 5.2999]],\n",
            "\n",
            "         [[ 4.9232]],\n",
            "\n",
            "         [[ 8.3470]],\n",
            "\n",
            "         [[ 8.0679]],\n",
            "\n",
            "         [[ 1.0458]],\n",
            "\n",
            "         [[ 6.2702]],\n",
            "\n",
            "         [[ 2.9074]]]], grad_fn=<UnsafeViewBackward0>)\n",
            "ssfter shift tensor([[[[11.5909]],\n",
            "\n",
            "         [[ 2.0611]],\n",
            "\n",
            "         [[ 2.7270]],\n",
            "\n",
            "         [[ 1.5129]],\n",
            "\n",
            "         [[ 8.9682]],\n",
            "\n",
            "         [[ 8.0498]],\n",
            "\n",
            "         [[-1.8181]],\n",
            "\n",
            "         [[ 7.4384]]],\n",
            "\n",
            "\n",
            "        [[[ 6.1522]],\n",
            "\n",
            "         [[-2.6521]],\n",
            "\n",
            "         [[-0.5594]],\n",
            "\n",
            "         [[-7.4063]],\n",
            "\n",
            "         [[-6.3469]],\n",
            "\n",
            "         [[-8.2439]],\n",
            "\n",
            "         [[ 0.4855]],\n",
            "\n",
            "         [[-2.1127]]],\n",
            "\n",
            "\n",
            "        [[[ 2.1011]],\n",
            "\n",
            "         [[-1.8819]],\n",
            "\n",
            "         [[11.3779]],\n",
            "\n",
            "         [[-4.3598]],\n",
            "\n",
            "         [[14.6621]],\n",
            "\n",
            "         [[-7.8214]],\n",
            "\n",
            "         [[10.7822]],\n",
            "\n",
            "         [[ 0.4102]]],\n",
            "\n",
            "\n",
            "        [[[ 2.6714]],\n",
            "\n",
            "         [[ 2.7373]],\n",
            "\n",
            "         [[ 8.8180]],\n",
            "\n",
            "         [[-4.7238]],\n",
            "\n",
            "         [[ 4.1687]],\n",
            "\n",
            "         [[ 5.8949]],\n",
            "\n",
            "         [[ 7.1671]],\n",
            "\n",
            "         [[ 1.0466]]],\n",
            "\n",
            "\n",
            "        [[[ 9.7179]],\n",
            "\n",
            "         [[ 5.2999]],\n",
            "\n",
            "         [[ 4.9232]],\n",
            "\n",
            "         [[ 8.3470]],\n",
            "\n",
            "         [[ 8.0679]],\n",
            "\n",
            "         [[ 1.0458]],\n",
            "\n",
            "         [[ 6.2702]],\n",
            "\n",
            "         [[ 2.9074]]]], grad_fn=<ViewBackward0>)\n",
            "before shift tensor([[[[-3.5899e+00]],\n",
            "\n",
            "         [[ 4.9940e+00]],\n",
            "\n",
            "         [[-1.4946e+01]],\n",
            "\n",
            "         [[ 6.6519e+00]],\n",
            "\n",
            "         [[ 8.4307e+00]],\n",
            "\n",
            "         [[-3.8893e-01]],\n",
            "\n",
            "         [[ 1.4416e+01]],\n",
            "\n",
            "         [[ 3.3622e+00]]],\n",
            "\n",
            "\n",
            "        [[[-4.4576e+00]],\n",
            "\n",
            "         [[ 5.7840e+00]],\n",
            "\n",
            "         [[ 3.0443e+00]],\n",
            "\n",
            "         [[-1.8544e+00]],\n",
            "\n",
            "         [[-3.0142e+00]],\n",
            "\n",
            "         [[-1.8816e+00]],\n",
            "\n",
            "         [[-1.6756e+00]],\n",
            "\n",
            "         [[ 1.5919e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1623e+01]],\n",
            "\n",
            "         [[ 7.5194e-01]],\n",
            "\n",
            "         [[-4.0455e+00]],\n",
            "\n",
            "         [[-1.7830e+00]],\n",
            "\n",
            "         [[ 4.9348e-01]],\n",
            "\n",
            "         [[ 3.9479e+00]],\n",
            "\n",
            "         [[ 9.6134e+00]],\n",
            "\n",
            "         [[ 1.5337e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.1017e+00]],\n",
            "\n",
            "         [[ 8.5287e+00]],\n",
            "\n",
            "         [[-2.8503e+00]],\n",
            "\n",
            "         [[-8.6571e+00]],\n",
            "\n",
            "         [[ 4.0232e+00]],\n",
            "\n",
            "         [[-3.5848e-01]],\n",
            "\n",
            "         [[-9.0151e-01]],\n",
            "\n",
            "         [[ 2.0277e-01]]],\n",
            "\n",
            "\n",
            "        [[[-8.3264e+00]],\n",
            "\n",
            "         [[ 3.8959e+00]],\n",
            "\n",
            "         [[-7.3323e+00]],\n",
            "\n",
            "         [[ 1.4615e+00]],\n",
            "\n",
            "         [[-1.4943e+01]],\n",
            "\n",
            "         [[-1.0536e+00]],\n",
            "\n",
            "         [[ 1.1905e+01]],\n",
            "\n",
            "         [[-2.0696e+00]]]], grad_fn=<UnsafeViewBackward0>)\n",
            "ssfter shift tensor([[[[-3.5899e+00]],\n",
            "\n",
            "         [[ 4.9940e+00]],\n",
            "\n",
            "         [[-1.4946e+01]],\n",
            "\n",
            "         [[ 6.6519e+00]],\n",
            "\n",
            "         [[ 8.4307e+00]],\n",
            "\n",
            "         [[-3.8893e-01]],\n",
            "\n",
            "         [[ 1.4416e+01]],\n",
            "\n",
            "         [[ 3.3622e+00]]],\n",
            "\n",
            "\n",
            "        [[[-4.4576e+00]],\n",
            "\n",
            "         [[ 5.7840e+00]],\n",
            "\n",
            "         [[ 3.0443e+00]],\n",
            "\n",
            "         [[-1.8544e+00]],\n",
            "\n",
            "         [[-3.0142e+00]],\n",
            "\n",
            "         [[-1.8816e+00]],\n",
            "\n",
            "         [[-1.6756e+00]],\n",
            "\n",
            "         [[ 1.5919e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1623e+01]],\n",
            "\n",
            "         [[ 7.5194e-01]],\n",
            "\n",
            "         [[-4.0455e+00]],\n",
            "\n",
            "         [[-1.7830e+00]],\n",
            "\n",
            "         [[ 4.9348e-01]],\n",
            "\n",
            "         [[ 3.9479e+00]],\n",
            "\n",
            "         [[ 9.6134e+00]],\n",
            "\n",
            "         [[ 1.5337e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.1017e+00]],\n",
            "\n",
            "         [[ 8.5287e+00]],\n",
            "\n",
            "         [[-2.8503e+00]],\n",
            "\n",
            "         [[-8.6571e+00]],\n",
            "\n",
            "         [[ 4.0232e+00]],\n",
            "\n",
            "         [[-3.5848e-01]],\n",
            "\n",
            "         [[-9.0151e-01]],\n",
            "\n",
            "         [[ 2.0277e-01]]],\n",
            "\n",
            "\n",
            "        [[[-8.3264e+00]],\n",
            "\n",
            "         [[ 3.8959e+00]],\n",
            "\n",
            "         [[-7.3323e+00]],\n",
            "\n",
            "         [[ 1.4615e+00]],\n",
            "\n",
            "         [[-1.4943e+01]],\n",
            "\n",
            "         [[-1.0536e+00]],\n",
            "\n",
            "         [[ 1.1905e+01]],\n",
            "\n",
            "         [[-2.0696e+00]]]], grad_fn=<ViewBackward0>)\n",
            "before shift tensor([[[[-11.0207]],\n",
            "\n",
            "         [[ -1.3811]],\n",
            "\n",
            "         [[ -6.1759]],\n",
            "\n",
            "         [[ -0.7358]],\n",
            "\n",
            "         [[ 13.2213]],\n",
            "\n",
            "         [[  2.3857]],\n",
            "\n",
            "         [[  5.2964]],\n",
            "\n",
            "         [[ 10.4917]]],\n",
            "\n",
            "\n",
            "        [[[ -2.9354]],\n",
            "\n",
            "         [[  3.1791]],\n",
            "\n",
            "         [[  4.5887]],\n",
            "\n",
            "         [[ -4.3256]],\n",
            "\n",
            "         [[ -6.0293]],\n",
            "\n",
            "         [[ -0.6389]],\n",
            "\n",
            "         [[ -1.5754]],\n",
            "\n",
            "         [[ 12.2724]]],\n",
            "\n",
            "\n",
            "        [[[-14.2845]],\n",
            "\n",
            "         [[  3.8096]],\n",
            "\n",
            "         [[ -5.0206]],\n",
            "\n",
            "         [[ -0.0854]],\n",
            "\n",
            "         [[ -3.4916]],\n",
            "\n",
            "         [[  6.6050]],\n",
            "\n",
            "         [[  4.6472]],\n",
            "\n",
            "         [[ -5.8681]]],\n",
            "\n",
            "\n",
            "        [[[ -7.3514]],\n",
            "\n",
            "         [[  0.8690]],\n",
            "\n",
            "         [[ -4.1222]],\n",
            "\n",
            "         [[  0.7447]],\n",
            "\n",
            "         [[ -1.0194]],\n",
            "\n",
            "         [[ -3.1509]],\n",
            "\n",
            "         [[  0.5080]],\n",
            "\n",
            "         [[  4.6585]]],\n",
            "\n",
            "\n",
            "        [[[-15.4953]],\n",
            "\n",
            "         [[  3.0490]],\n",
            "\n",
            "         [[  2.4840]],\n",
            "\n",
            "         [[ -1.7767]],\n",
            "\n",
            "         [[ 12.6354]],\n",
            "\n",
            "         [[  2.7185]],\n",
            "\n",
            "         [[ -4.4431]],\n",
            "\n",
            "         [[  2.1925]]]], grad_fn=<UnsafeViewBackward0>)\n",
            "ssfter shift tensor([[[[-11.0207]],\n",
            "\n",
            "         [[ -1.3811]],\n",
            "\n",
            "         [[ -6.1759]],\n",
            "\n",
            "         [[ -0.7358]],\n",
            "\n",
            "         [[ 13.2213]],\n",
            "\n",
            "         [[  2.3857]],\n",
            "\n",
            "         [[  5.2964]],\n",
            "\n",
            "         [[ 10.4917]]],\n",
            "\n",
            "\n",
            "        [[[ -2.9354]],\n",
            "\n",
            "         [[  3.1791]],\n",
            "\n",
            "         [[  4.5887]],\n",
            "\n",
            "         [[ -4.3256]],\n",
            "\n",
            "         [[ -6.0293]],\n",
            "\n",
            "         [[ -0.6389]],\n",
            "\n",
            "         [[ -1.5754]],\n",
            "\n",
            "         [[ 12.2724]]],\n",
            "\n",
            "\n",
            "        [[[-14.2845]],\n",
            "\n",
            "         [[  3.8096]],\n",
            "\n",
            "         [[ -5.0206]],\n",
            "\n",
            "         [[ -0.0854]],\n",
            "\n",
            "         [[ -3.4916]],\n",
            "\n",
            "         [[  6.6050]],\n",
            "\n",
            "         [[  4.6472]],\n",
            "\n",
            "         [[ -5.8681]]],\n",
            "\n",
            "\n",
            "        [[[ -7.3514]],\n",
            "\n",
            "         [[  0.8690]],\n",
            "\n",
            "         [[ -4.1222]],\n",
            "\n",
            "         [[  0.7447]],\n",
            "\n",
            "         [[ -1.0194]],\n",
            "\n",
            "         [[ -3.1509]],\n",
            "\n",
            "         [[  0.5080]],\n",
            "\n",
            "         [[  4.6585]]],\n",
            "\n",
            "\n",
            "        [[[-15.4953]],\n",
            "\n",
            "         [[  3.0490]],\n",
            "\n",
            "         [[  2.4840]],\n",
            "\n",
            "         [[ -1.7767]],\n",
            "\n",
            "         [[ 12.6354]],\n",
            "\n",
            "         [[  2.7185]],\n",
            "\n",
            "         [[ -4.4431]],\n",
            "\n",
            "         [[  2.1925]]]], grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 1, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}